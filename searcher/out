doc_id: 2901weight: 3
tittle: Change Log
url :https://www.boost.org/doc/libs/1_53_0/doc/html/quickbook/change_log.html
content:    Change Log           Home Libraries People FAQ More        Change Log         Version       1.1 - Boost 1.33.0                 First version to be included in boost.                  Version       1.3 - Boost 1.34.0 to 1.34.1                  Quickbook file inclusion [include].                     Better xml output (pretty layout). Check out the generated XML.                     Regression testing facility: to make sure your document will always be           compatible (full backward compatibility) regardless of changes to QuickBook.                     Code cleanup and refactoring.                     Allow phrase markup in the doc-info.                     Preformatted code blocks via ``code`` (double ticks) allows code in tables           and lists, for example.                     Quickbook versioning; allows full backward compatibility. You have to add           [quickbook 1.3] to the doc-info header to enable the new features. Without           this, QuickBook will assume that the document is a pre-1.3 document.                                  Better (intuitive) paragraph termination. Some markups may terminate             a paragraph. Example:            [section x] blah... [endsect]                     Fully qualified section and headers. Subsection names are concatenated           to the ID to avoid clashing. Example: doc_name.sect_name.sub_sect_name.sub_sub_sect_name                     Better &amp;nbsp; and whitespace handling in code snippets.                     [xinclude] fixes up the relative path to the target XML file when input_directory           is not the same as the output_directory.                     Allow untitled tables.                     Allow phrase markups in section titles.                     Allow escaping back to QuickBook from code, code blocks and inline code.                     Footnotes, with the [footnote This is the footnote] syntax.                     Post-processor bug fix for escaped XML code that it does not recognize.                     Replaceable, with the [~replacement] syntax.                   Version       1.4 - Boost 1.35.0 to 1.40.0                  Generic Headers                     Code changes to allow full recursion (i.e. Collectors and push/pop functions)                     Various code cleanup/maintenance                     Templates!                     [conceptref] for referencing BoostBook &lt;concept&gt; entities.                     Allow escape of spaces. The escaped space is removed from the output. Syntax:           \ .                     Nested comments are now allowed.                     Quickbook blocks can nest inside comments.                     Import facility.                     Callouts on imported code                     Simple markups can now span a whole block.                     Blurbs, Admonitions           and table cells (see Tables)           may now contain paragraphs.                     \n and [br] are now deprecated.                     Conditional Generation. Ala C++           #ifdef.                     Searching of included and imported files in an extensible search path with           --include-path (-I) option.                   Version       1.5 - Boost 1.41.0 to 1.42.0                  Support multiple copyright entrys in document info.                     Improved SVG support.                     [globalref] for referencing BoostBook &lt;global&gt; entities.                     Fail on error.                     Fix crash for templates with too many arguments or trailing space.                     Improved handling of unexpected characters in code blocks.                     Improved handling of unmatched escape in code blocks.                     Support for python snippets.                     teletype source mode.                     Use static scoping in templates, should be a lot more intuitive.                     Accept a space between section: and the section id.                     Support table ids.                   Version       1.5.1 - Boost 1.43.0                  Improve the post processor's list of block elements. table,           entry and varlistentry are treated as blocks.           replaceable is treated as an inline element.                     Check that [section] and [endsect] tags are balanced           in templates.                     Add unicode escape characters, eg. \u03B1 for &#945;.                     Support UTF-8 files with a unicode byte order mark.                     Disallow [ in simple markup. Fixes some errors with mismatched           punctuation.                     Add command line flag to define macros at the command line, e.g. quickbook           "-D__italic_foo__=/foo/".                   Version       1.5.2 - Boost 1.44.0                  Use the cygwin 1.7 API for better path handling.                     Improved boostbook generation:                             XML encode the documentation info correctly.                                 Avoid generating empty paragraphs.                                 No longer wraps block templates in paragraphs.                                 Warns if you use invalid doc_info members for docbook document types.                                 Fixes some other causes of invalid boostbook, although it still generates                 invalid boostbook in places.                                     Improved grammar:                             Supports multiple categories in library doc_info.                                 No longer requires commas between authors in docinfo.                                 Allows empty document bodies.                                 A line containing only a comment is no longer interpreted as a paragraph                 break.                                 If a line starts with a comment, interpret it as a paragraph even                 if it's followed by whitespace or a list character.                                 Doesn't treat several consecutive blank lines as multiple paragraph                 breaks.                                     Fixes duplicate image attribute detection.                     Fixes using code snippets more than once.                     Early work on quickbook 1.6, available using the [quickbook 1.6]           version switch, but liable to change in future versions.                             When automatically generating ids for headers, use the quickbook                 source, rather than the generated docbook.                                 Fix id generation in included files. It wasn't correctly using the                 main document's documentation id.                                 Correctly restore the quickbook version switch after including a                 file with a different version.                                   Version       1.5.3 - Boost 1.45.0                  Fix command line flag for defining macros.                     Fix a couple of issues with the code block parser:                             A comment with no indentation will now end a code block.                                 Code blocks no longer have to be followed by a blank line.                                     Improved tracking of file position in templates and imported code blocks.                     Better generated markup for callout lists.                     In docbook, variable list entries can only have one listitem,           so if an entry has multiple values, merge them into one listitem.                     Support nested code snippets.                     Support nested blocks in document info comments.                     Revert xml escaping document info, it broke some documentation files (now           a 1.6 feature).                     Further work on quickbook 1.6, still not stable.                             Allow heading to have ids, using the syntax: [heading:id title].                                 XML escape documentation fields, with escapes to allow encoding unicode                 in ASCII.                                   Version       1.5.4 - Boost 1.46.1             Boost 1.46.0:                  Add support for lang attribute in documentation info.                     Improved anchor implementation. Especially for using an anchor before a           section or heading.                     Fixed some more issues where lines containing comments were treated as           blank lines.                     Allow import, include and xinclude in conditional phrases. Will allow more           block elements in a future version.                     Rearrange the structure of the grammar.                     Use filesystem 3. Remove cygwin 1.5 support.                  Boost 1.46.1:                 Work around optimization bug in g++ 4.4 on 64 bit linux.                  Version       1.5.5 - Boost 1.47                  Tweak anchor placement for titles.                     Hard code the quickbook path into the quickbook testing tools. This means           that they can be used from multiple locations.                     Generate an id for boostbook bridgehead elements. This results           in more consistent html, since docbook generates a random id if they don't           have one.                     Improved unicode support on windows. Unicode can now be used from the command           line, and unicode filenames are supported. Unicode output is a bit weak.                     Check for windows paths, and warn about them.                     Fix relative path detection on windows.                     Reverse deprecation of [br], printing a single warning about           generating invalid boostbook.                     Fix handling empty category attributes.                     Store data from the parser in a dynamic data structure. This simplifies           the implementation and makes it easier to parse more complicated data structures.                     Improved error messages for unknown doc info attributes.                     Richer copyright syntax. Now understands: [copyright 2001-2006, 2010           One person, 2008 Another person].                     Fix delimeter checking for simple markup.                     Allow more block elements to be nested.                     Go back to using invalid markup for lists. It generates better html.                     Better anchor placement for lists.                     Pass-thru comments in code snippets.                     Use relative paths for __FILENAME__ macro.                     Rewrite xinclude path generator so that it doesn't use deprecated filesystem           functions.                     Allow quickbook escapes inside comments in syntax highlighted code.                     Quickbook 1.6:                             Scope source mode changes to the file they're made in.                                 Explicit markup for lists. e.g. [ordered_list [item1][item2]]                 or [itemized_list [item1][item2]].                                   Version       1.5.6 - Boost 1.48                  Xml encode escaped punctuation (eg. \&lt; is correctly encodes           to &lt;).                     Rename duplicate generated ids.                     Close open sections at end of document (still warns about them).                     New anchor markup for headers, will hopefully generate better pdfs.                     Remove some whitespace around code from post processed output.                   Version       1.5.7 - Boost 1.49                  Several internal changes.                     Some improved error messages.                     Better handling of block templates expanded in a phrase context.                     Avoids empty simple markup (i.e. // is not treated as an italic empty space.                     Better anchor markup for headers, which should be better for printing -           suggested by John Maddock.                     Further improvements to the id generator.                     If sections are left unopened at the end of a document, then close them           in the generated markup.                     Try to handle whitespace better at the beginning and end of code blocks.                     Handle lists that come immediately after an anchor.                     Make horizontal rules followed by multi-line comments a little more sensible.                     Better support for empty ids and titles in docinfo.                     Fix some minor regressions in SVG handling.                     Better handling of invalid command line macros.                     When auto-building quickbook, build the release version.                     Lots of changes for 1.6:                             Scope templates in included files.                                 Support import of templates and macros.                                 Including top level quickbook blocks from source files.                                 Use doc info blocks in included quickbook files.                                 Better handling of macros with the same name.                                 block element.                                 Better handling of significant punctuation (e.g. escapes, square                 brackets).                                 Support escapes in links, anchors, images, includes etc.                                 Improved table title syntax.                                 Paragraphs nested in lists.                                 New docinfo attributes:                                         compatibility-mode to make it possible to upgrade                       documents without breaking ids.                                             xmlbase for escaped xi:includes.                                                       Allow some docinfo attributes to be used before, or without, a doc                 info block (quickbook, compatibility-mode,                 source-mode).                                 Only add explicit alt text to images.                                 Don't put 'inline' code blocks inside paragraphs.                                   Version       1.5.8 - Boost 1.50                  Write dependencies to a file, using --output-deps (#6691).                     Fix handling of section tags in lists.                     Fix indented code blocks in lists.                     Fix handling UTF-8 code points in the syntax highlighter. Was treating           each individual byte as a character. Still doesn't deal with combining           code points.                     Internal changes:                             A lot of restructuring.                                 Stop using 'v3' filesystem paths and namespaces, it's now the default                 version.                                 Remove awkward intrusive reference counting implementation, avoids                 a gcc internal compiler error (#6794),                 but is also a cleaner implementation.                                     1.6 changes:                             Better handling of brackets in link values.                                 Improved handling of escaped characters in include paths.                                     Starting to develop 1.7:                             Source mode for single entities.                                 Callouts in code blocks.                                 Escaped docbook in docinfo blocks.                                 Starting to implement calling templates from link values.                              Copyright &#169; 2002, 2004, 2006 Joel de Guzman,       Eric NieblerCopyright &#169; 2010, 2011 Daniel James         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3141weight: 1
tittle: Overview
url :https://www.boost.org/doc/libs/1_53_0/doc/html/bbv2/overview.html
content:    Overview           Home Libraries People FAQ More        Overview  Concepts Boost.Jam Language Configuration Invocation Declaring Targets Projects The Build Process         This section will provide the information necessary to create your own       projects using Boost.Build. The information provided here is relatively       high-level, and the section called &#8220;Reference&#8221; as well as the on-line       help system must be used to obtain low-level documentation (see --help).             Boost.Build actually consists of two parts - Boost.Jam, a build engine       with its own interpreted language, and Boost.Build itself, implemented in       Boost.Jam's language. The chain of events when you type       b2 on the command line is as follows:                      The Boost.Build executable tries to find Boost.Build modules and              loads the top-level module. The exact process is described in the section called &#8220;Initialization&#8221;                         The top-level module loads user-defined configuration files,             user-config.jam and             site-config.jam, which define available toolsets.                         The Jamfile in the current directory is read. That in turn might             cause reading of further Jamfiles. As a result, a tree of projects             is created, with targets inside projects.                         Finally, using the build request specified on the command line,             Boost.Build decides which targets should be built and how. That             information is passed back to Boost.Jam, which takes care of             actually running the scheduled build action commands.                          So, to be able to successfully use Boost.Build, you need to know only four       things:                      How to configure             Boost.Build                         How to declare targets in               Jamfiles                         How the build process               works                         Some Basics about the Boost.Jam language. See the section called &#8220;Boost.Jam Language&#8221;.                     Concepts Boost.Build has a few unique concepts that are introduced in this section. The best       way to explain the concepts is by comparison with more classical build tools.          When using any flavour of make, you directly specify targets         and commands that are used to create them from other target. The below example         creates a.o from a.c using a hardcoded         compiler invocation command.   a.o: a.c     g++ -o a.o -g a.c           This is a rather low-level description mechanism and it's hard to adjust commands, options,         and sets of created targets depending on the compiler and operating system used.                         To improve portability, most modern build system provide a set of higher-level          functions that can be used in build description files. Consider this example:   add_program ("a", "a.c")           This is a function call that creates the targets necessary to create a executable file         from the source file a.c. Depending on configured properties,         different command lines may be used. However, add_program is higher-level,         but rather thin level. All targets are created immediately when the build description         is parsed, which makes it impossible to perform multi-variant builds. Often, change         in any build property requires a complete reconfiguration of the build tree.                         In order to support true multivariant builds, Boost.Build introduces the concept of a                           metatarget&#8212;an object that is created when the build description         is parsed and can be called later with specific build properties to generate         actual targets.                  Consider an example:   exe a : a.cpp ;           When this declaration is parsed, Boost.Build creates a metatarget, but does not         yet decide what files must be created, or what commands must be used. After         all build files are parsed, Boost.Build considers the properties requested on the         command line. Supposed you have invoked Boost.Build with:   b2 toolset=gcc toolset=msvc           In that case, the metatarget will be called twice, once with toolset=gcc         and once with toolset=msvc. Both invocations will produce concrete         targets, that will have different extensions and use different command lines.                 Another key concept is                  build property. A build property is a variable         that affects the build process. It can be specified on the command line, and is         passed when calling a metatarget. While all build tools have a similar mechanism,         Boost.Build differs by requiring that all build properties are declared in advance,         and providing a large set of properties with portable semantics.                 The final concept is          property propagation. Boost.Build does not require that every         metatarget is called with the same properties. Instead, the          "top-level" metatargets are called with the properties specified on the command line.         Each metatarget can elect to augment or override some properties (in particular,         using the requirements mechanism, see the section called &#8220;Requirements&#8221;).         Then, the dependency metatargets are called with the modified properties and produce         concrete targets that are then used in the build process. Of course, dependency metatargets         maybe in turn modify build properties and have dependencies of their own.        For a more in-depth treatment of the requirements and concepts, you may refer        to SYRCoSE 2009 Boost.Build article.           Boost.Jam Language          This section will describe the basics of the Boost.Jam language&#8212;just         enough for writing Jamfiles. For more information, please see the         Boost.Jam documentation.                 Boost.Jam has an interpreted, procedural         language. On the lowest level, a Boost.Jam          program consists of variables and  rules (the Jam term for         functions). They are grouped into modules&#8212;there is one global         module and a number of named modules. Besides that, a Boost.Jam program contains classes and class         instances.                 Syntantically, a Boost.Jam program         consists of two kind of elements&#8212;keywords (which have a special         meaning to Boost.Jam) and literals.         Consider this code:   a = b ;           which assigns the value b to the variable a         . Here, = and ; are         keywords, while a and b are         literals.             Warning               All syntax elements, even keywords, must be separated by spaces. For             example, omitting the space character before ;             will lead to a syntax error.                      If you want to use a literal value that is the same as some keyword, the         value can be quoted:   a = "=" ;                   All variables in Boost.Jam have the same         type&#8212;list of strings. To define a variable one assigns a value to         it, like in the previous example. An undefined variable is the same as a         variable with an empty value. Variables can be accessed using the         $(variable) syntax. For example:   a = $(b) $(c) ;                   Rules are defined by specifying the rule name, the parameter names, and         the allowed value list size for each parameter.   rule example  (      parameter1 :      parameter2 ? :      parameter3 + :      parameter4 *  )  {     # rule body  }            When this rule is called, the list passed as the first argument must         have exactly one value. The list passed as the second argument can         either have one value of be empty. The two remaining arguments can be         arbitrarily long, but the third argument may not be empty.                 The overview of Boost.Jam language         statements is given below:   helper 1 : 2 : 3 ; x = [ helper 1 : 2 : 3 ] ;           This code calls the named rule with the specified arguments. When the         result of the call must be used inside some expression, you need to add         brackets around the call, like shown on the second line.   if cond { statements } [ else { statements } ]           This is a regular if-statement. The condition is composed of:                          Literals (true if at least one string is not empty)                             Comparisons: a operator b               where operator is one of               =, !=, &lt;,               &gt;, &lt;= or &gt;=. The               comparison is done pairwise between each string in the left and               the right arguments.                             Logical operations: ! a, a &amp;&amp; b,               a || b                             Grouping: ( cond )                  for var in list { statements }           Executes statements for each element in list, setting the variable         var to the element value.   while cond { statements }           Repeatedly execute statements while cond remains true upon entry.   return values ;           This statement should be used only inside a rule and assigns         values to the return value of the rule.             Warning                The return statement does not exit the rule. For             example:   rule test ( ) {    if 1 = 1    {       return "reasonable" ;    }    return "strange" ; }               will return strange, not             reasonable.                 import module ; import module : rule ;           The first form imports the specified module. All rules from that         module are made available using the qualified name:          module.rule. The second         form imports the specified rules only, and they can be called using         unqualified names.                 Sometimes, you need to specify the actual command lines to be used         when creating targets. In the jam language, you use named actions to do         this. For example:   actions create-file-from-another {     create-file-from-another $(&lt;) $(&gt;) }           This specifies a named action called          create-file-from-another. The text inside braces is the         command to invoke. The $(&lt;) variable will be         expanded to a list of generated files, and the $(&gt;)          variable will be expanded to a list of source files.                 To adjust the command line flexibly, you can define a rule with the same         name as the action and taking three parameters&#8212;targets, sources and         properties. For example:   rule create-file-from-another ( targets * : sources * : properties * ) {    if &lt;variant&gt;debug in $(properties)    {        OPTIONS on $(targets) = --debug ;    } } actions create-file-from-another {     create-file-from-another $(OPTIONS) $(&lt;) $(&gt;) }           In this example, the rule checks if a certain build property is specified.         If so, it sets the variable OPIONS that is then used         inside the action. Note that the variables set "on a target" will be         visible only inside actions building that target, not globally. Were         they set globally, using variable named OPTIONS in         two unrelated actions would be impossible.                 More details can be found in the Jam reference, the section called &#8220;Rules&#8221;.           Configuration        On startup, Boost.Build searches and reads two configuration files:        site-config.jam and user-config.jam.       The first one is usually installed and maintained by a system administrator, and       the second is for the user to modify.  You can edit the one in the top-level       directory of your Boost.Build installation or create a copy in your home       directory and edit the copy.  The following table explains where both files       are searched.       Table&#160;41.1.&#160;Search paths for configuration files        &#160; site-config.jam user-config.jam    Linux                /etc               $HOME               $BOOST_BUILD_PATH                             $HOME               $BOOST_BUILD_PATH                Windows                %SystemRoot%               %HOMEDRIVE%%HOMEPATH%               %HOME%               %BOOST_BUILD_PATH%                             %HOMEDRIVE%%HOMEPATH%               %HOME%               %BOOST_BUILD_PATH%                     Tip           You can use the --debug-configuration option to         find which configuration files are actually loaded.                Usually, user-config.jam just defines the available compilers       and other tools (see the section called &#8220;Targets in site-config.jam&#8221; for more advanced       usage). A tool is configured using the following syntax:       using tool-name : ... ;         The using rule is given the name of tool, and       will make that tool available to Boost.Build. For example,   using gcc ;   will make the GCC compiler available.             All the supported tools are documented in the section called &#8220;Builtin tools&#8221;,       including the specific options they take. Some general notes that apply to most       C++ compilers are below.             For all the C++ compiler toolsets that Boost.Build supports       out-of-the-box, the list of parameters to       using is the same: toolset-name, version, invocation-command, and options.      If you have a single compiler, and the compiler executable         has its &#8220;usual name&#8221; and is in the       PATH, or was installed in a standard &#8220;installation       directory&#8221;, or can be found using a global system like the Windows       registry.       it can be configured by simply:  using tool-name ;  If the compiler is installed in a custom directory, you should provide the     command that invokes the compiler, for example:  using gcc : : g++-3.2 ; using msvc : : "Z:/Programs/Microsoft Visual Studio/vc98/bin/cl" ;         Some Boost.Build toolsets will use that path to take additional actions       required before invoking the compiler, such as calling vendor-supplied       scripts to set up its required environment variables. When the compiler       executables for C and C++ are different, the path to the C++ compiler       executable must be specified. The command can       be any command allowed by the operating system. For example:   using msvc : : echo Compiling &amp;&amp; foo/bar/baz/cl ;         will work.             To configure several versions of a toolset, simply invoke the       using rule multiple times:   using gcc : 3.3 ; using gcc : 3.4 : g++-3.4 ; using gcc : 3.2 : g++-3.2 ;         Note that in the first call to using, the       compiler found in the PATH will be used, and there is no       need to explicitly specify the command.             Many of toolsets have an options       parameter to fine-tune the configuration. All of       Boost.Build's standard compiler toolsets accept four options       cflags, cxxflags,        compileflags and linkflags as options specifying flags that will be       always passed to the corresponding tools. Values of the       cflags feature are passed directly to the C       compiler, values of the cxxflags feature are       passed directly to the C++ compiler, and values of the       compileflags feature are passed to both. For       example, to configure a gcc toolset so that it       always generates 64-bit code you could write:           using gcc : 3.4 : : &lt;compileflags&gt;-m64 &lt;linkflags&gt;-m64 ;           Warning           Although the syntax used to specify toolset options is very similar         to syntax used to specify requirements in Jamfiles, the toolset options         are not the same as features. Don't try to specify a feature value         in toolset initialization.            Invocation  Examples Options Properties Targets  To invoke Boost.Build, type b2 on the command line. Three kinds       of command-line tokens are accepted, in any order:  options Options start with either one or two dashes.  The standard options           are listed below, and each project may add additional options properties Properties specify details of what you want to build (e.g. debug           or release variant).  Syntactically, all command line tokens with an equal sign in them           are considered to specify properties.  In the simplest form, a property looks like           feature=value            target All tokens that are neither options nor properties specify            what targets to build.  The available targets entirely depend on the project           you are building.    Examples To build all targets defined in the Jamfile in the current directory with the default properties, run:   b2            To build specific targets, specify them on the command line:   b2 lib1 subproject//lib2            To request a certain value for some property, add          property=value to the command line:   b2 toolset=gcc variant=debug optimization=space               Options Boost.Build recognizes the following command line options.   --help  Invokes the online help system. This prints general               information on how to use the help system with additional               --help* options.                --clean Cleans all targets in the current directory and               in any subprojects. Note that unlike the clean               target in make, you can use --clean               together with target names to clean specific targets. --clean-all Cleans all targets,               no matter where they are defined. In particular, it will clean targets               in parent Jamfiles, and targets defined under other project roots.                --build-dir  Changes the build directories for all project roots being built. When               this option is specified, all Jamroot files must declare a project name.               The build directory for the project root will be computed by concatanating               the value of the --build-dir option, the project name               specified in Jamroot, and the build dir specified in Jamroot               (or bin, if none is specified).                The option is primarily useful when building from read-only               media, when you can't modify Jamroot.                 --version Prints information on the Boost.Build and Boost.Jam               versions.                -a Causes all files to be rebuilt. -n Do no execute the commands, only print them. -q Stop at the first error, as opposed to continuing to build targets               that don't depend on the failed ones. -j N Run up to N commands in parallel. --debug-configuration Produces debug information about the loading of Boost.Build               and toolset files. --debug-building Prints what targets are being built and with what properties.                --debug-generators Produces debug output from the generator search process.               Useful for debugging custom generators.                --ignore-config Do not load site-config.jam or               user-config.jam.                -d0 Supress all informational messages. -d N  Enable cummulative debugging levels from 1 to n. Values are:                  Show the actions taken for building targets, as they are executed (the default). Show "quiet" actions and display all action text, as they are executed. Show dependency analysis, and target/source timestamps/paths. Show arguments and timming of shell invocations. Show rule invocations and variable expansions. Show directory/header file/archive scans, and attempts at binding to targets. Show variable settings. Show variable fetches, variable expansions, and evaluation of '"if"' expressions. Show variable manipulation, scanner tokens, and memory usage. Show profile information for rules, both timing and memory. Show parsing progress of Jamfiles. Show graph of target dependencies. Show change target status (fate).                   -d +N Enable debugging level N. -o file Write the updating actions to the specified file instead of running them.                -s var=value Set the variable var to               value in the global scope of the jam               language interpreter, overriding variables imported from the               environment.                    Properties In the simplest case, the build is performed with a single set of properties,         that you specify on the command line with elements in the form         feature=value.         The complete list of features can be found in the section called &#8220;Builtin features&#8221;.          The most common features are summarized below.  Table&#160;41.2.&#160;        Feature Allowed values Notes    variant debug,release &#160;   link shared,static Determines if Boost.Build creates shared or static libraries   threading single,multi Cause the produced binaries to be thread-safe.  This requires proper support in the source code itself.   address-model 32,64 Explicitly request either 32-bit or 64-bit code generation. This typically                 requires that your compiler is appropriately configured. Please refer to                 the section called &#8220;C++ Compilers&#8221; and your compiler documentation                 in case of problems.   toolset (Depends on configuration) The C++ compiler to use. See the section called &#8220;C++ Compilers&#8221; for a detailed list.   include (Arbitrary string) Additional include paths for C and C++ compilers.   define (Arbitrary string) Additional macro definitions for C and C++ compilers. The string should be either                 SYMBOL or SYMBOL=VALUE    cxxflags (Arbitrary string) Custom options to pass to the C++ compiler.   cflags (Arbitrary string) Custom options to pass to the C compiler.   linkflags (Arbitrary string) Custom options to pass to the C++ linker.   runtime-link shared,static Determines if shared or static version of C and C++ runtimes should be used.     If you have more than one version of a given C++ toolset (e.g. configured in         user-config.jam, or autodetected, as happens with msvc), you can         request the specific version by passing          toolset-version as         the value of the toolset feature, for example toolset=msvc-8.0.                     If a feature has a fixed set of values it can be specified more than            once on the command line.            In which case, everything will be built several times --           once for each specified value of a feature.  For example, if you use           b2 link=static link=shared threading=single threading=multi             Then a total of 4 builds will be performed.  For convenience,            instead of specifying all requested values of a feature in separate command line elements,           you can separate the values with commas, for example:           b2 link=static,shared threading=single,multi             The comma has this special meaning only if the feature has a fixed set of values, so           b2 include=static,shared  is not treated specially.    Targets All command line elements that are neither options nor properties are the names of the         targets to build. See the section called &#8220;Target identifiers and references&#8221;. If no target is specified,         the project in the current directory is built.     Declaring Targets  Name Sources Requirements Default Build Additional Information           A Main target is a user-defined named         entity that can be built, for example an executable file.         Declaring a main target is usually done using one of the main         target rules described in the section called &#8220;Builtin rules&#8221;.  The user can also declare         custom main target rules as shown in the section called &#8220;Main target rules&#8221;.        Most main target rules in Boost.Build have the same common       signature:  rule rule-name (      main-target-name :      sources + :      requirements * :      default-build * :      usage-requirements * )                main-target-name is the name used             to request the target on command line and to use it from             other main targets. A main target name may contain             alphanumeric characters, dashes             (&#8216;-&#8217;), and underscores             (&#8216;_&#8217;).                         sources is the list of source files and other main             targets that must be combined.                         requirements is the list of properties that must always             be present when this main target is built.                         default-build is the list of properties that will be used             unless some other value of the same feature is already             specified, e.g. on the command line or by propagation from a dependent target.                         usage-requirements is the list of properties that will be             propagated to all main targets that use this one, i.e. to all its             dependents.                      Some main target rules have a different list of parameters as explicitly         stated in their documentation.        The actual requirements for a target are obtained by refining       the requirements of the project where the target is declared with the       explicitly specified requirements. The same is true for       usage-requirements. More details can be found in       the section called &#8220;Property refinement&#8221;          Name The name of main target has two purposes. First, it's used to refer to this target from         other targets and from command line. Second, it's used to compute the names of the generated files.         Typically, filenames are obtained from main target name by appending system-dependent suffixes and         prefixes.          The name of a main target can contain alphanumeric characters,         dashes, undescores and dots. The entire         name is significant when resolving references from other targets. For determining filenames, only the         part before the first dot is taken. For example:  obj test.release : test.cpp : &lt;variant&gt;release ; obj test.debug : test.cpp : &lt;variant&gt;debug ;  will generate two files named test.obj (in two different directories), not         two files named test.release.obj and test.debug.obj.             Sources The list of sources specifies what should be processed to         get the resulting targets. Most of the time, it's just a list of         files. Sometimes, you'll want to automatically construct the         list of source files rather than having to spell it out         manually, in which case you can use the         glob rule.         Here are two examples:  exe a : a.cpp ;           # a.cpp is the only source file exe b : [ glob *.cpp ] ;  # all .cpp files in this directory are sources           Unless you specify a file with an absolute path, the name is         considered relative to the source directory&#8202;&#8212;&#8202;which is typically         the directory where the Jamfile is located, but can be changed as         described in the section called &#8220;Projects&#8221;.                                The list of sources can also refer to other main targets. Targets in           the same project can be referred to by name, while targets in other           projects must be qualified with a directory or a symbolic project           name. The directory/project name is separated from the target name by           a double forward slash. There is no special syntax to distinguish the           directory name from the project name&#8212;the part before the double           slash is first looked up as project name, and then as directory name.           For example:           lib helper : helper.cpp ; exe a : a.cpp helper ; # Since all project ids start with slash, ".." is a directory name. exe b : b.cpp ..//utils ; exe c : c.cpp /boost/program_options//program_options ;             The first exe uses the library defined in the same project. The second           one uses some target (most likely a library) defined by a Jamfile one           level higher. Finally, the third target uses a C++ Boost library, referring to it using           its absolute symbolic name. More information about target references           can be found in the section called &#8220;Dependent Targets&#8221; and the section called &#8220;Target identifiers and references&#8221;.             Requirements Requirements are the properties that should always be present when         building a target. Typically, they are includes and defines:   exe hello : hello.cpp : &lt;include&gt;/opt/boost &lt;define&gt;MY_DEBUG ;           There are a number of other features, listed in         the section called &#8220;Builtin features&#8221;. For example if         a library can only be built statically, or a file can't be compiled         with optimization due to a compiler bug, one can use   lib util : util.cpp : &lt;link&gt;static ; obj main : main.cpp : &lt;optimization&gt;off ;            Sometimes, particular relationships need to be maintained         among a target's build properties. This can be achieved with         conditional         requirements. For example, you might want to set         specific #defines when a library is built as shared,         or when a target's release variant is built in         release mode.   lib network : network.cpp     : &lt;link&gt;shared:&lt;define&gt;NEWORK_LIB_SHARED      &lt;variant&gt;release:&lt;define&gt;EXTRA_FAST     ;            In the example above, whenever network is         built with &lt;link&gt;shared,         &lt;define&gt;NEWORK_LIB_SHARED will be in its         properties, too.          You can use several properties in the condition, for example:   lib network : network.cpp     : &lt;toolset&gt;gcc,&lt;optimization&gt;speed:&lt;define&gt;USE_INLINE_ASSEMBLER     ;                       A more powerful variant of conditional requirements           is indirect conditional requirements.           You can provide a rule that will be called with the current build properties and can compute additional properties           to be added. For example:   lib network : network.cpp     : &lt;conditional&gt;@my-rule     ; rule my-rule ( properties * ) {     local result ;     if &lt;toolset&gt;gcc &lt;optimization&gt;speed in $(properties)     {         result += &lt;define&gt;USE_INLINE_ASSEMBLER ;     }     return $(result) ; }           This example is equivalent to the previous one, but for complex cases, indirect conditional         requirements can be easier to write and understand.          Requirements explicitly specified for a target are usually         combined with the requirements specified for the containing project. You         can cause a target to completely ignore a specific project requirement         using the syntax by adding a minus sign before the property, for example:   exe main : main.cpp : -&lt;define&gt;UNNECESSARY_DEFINE ;           This syntax is the only way to ignore free properties, such as defines,         from a parent. It can be also useful for ordinary properties. Consider         this example:   project test : requirements &lt;threading&gt;multi ; exe test1 : test1.cpp ; exe test2 : test2.cpp : &lt;threading&gt;single ; exe test3 : test3.cpp : -&lt;threading&gt;multi ;           Here, test1 inherits the project requirements and will always         be built in multi-threaded mode. The test2 target         overrides the project's requirements and will         always be built in single-threaded mode. In contrast, the         test3 target removes a property         from the project requirements and will be built either in single-threaded or         multi-threaded mode depending on which variant is requested by the         user. Note that the removal of requirements is completely textual:         you need to specify exactly the same property to remove it.    Default Build The default-build parameter         is a set of properties to be used if the build request does         not otherwise specify a value for features in the set. For example:   exe hello : hello.cpp : : &lt;threading&gt;multi ;           would build a multi-threaded target unless the user         explicitly requests a single-threaded version. The difference between         the requirements and the default-build is that the requirements cannot be         overridden in any way.             Additional Information            The ways a target is built can be so different that           describing them using conditional requirements would be           hard. For example, imagine that a library actually uses           different source files depending on the toolset used to build           it. We can express this situation using target           alternatives:   lib demangler : dummy_demangler.cpp ;                # alternative 1 lib demangler : demangler_gcc.cpp : &lt;toolset&gt;gcc ;   # alternative 2 lib demangler : demangler_msvc.cpp : &lt;toolset&gt;msvc ; # alternative 3             In the example above, when built with gcc           or msvc, demangler           will use a source file specific to the toolset.  Otherwise, it           will use a generic source file,           dummy_demangler.cpp.          It is possible to declare a target inline, i.e. the "sources"         parameter may include calls to other main rules. For example:  exe hello : hello.cpp     [ obj helpers : helpers.cpp : &lt;optimization&gt;off ] ;             Will cause "helpers.cpp" to be always compiled without            optimization. When referring to an inline main target, its declared            name must be prefixed by its parent target's name and two dots. In            the example above, to build only helpers, one should run            b2 hello..helpers.           When no target is requested on the command line, all targets in the          current project will be built. If a target should be built only by          explicit request, this can be expressed by the          explicit rule:            explicit install_programs ;                Projects As mentioned before, targets are grouped into projects,       and each Jamfile is a separate project. Projects are useful       because they allow us to group related targets together, define       properties common to all those targets, and assign a symbolic       name to the project that can be used in referring to its       targets.        Projects are named using the       project rule, which has the       following syntax:   project id : attributes ;           Here, attributes is a sequence of         rule arguments, each of which begins with an attribute-name         and is followed by any number of build properties. The list         of attribute names along with its handling is also shown in         the table below. For example, it is possible to write:   project tennis     : requirements &lt;threading&gt;multi     : default-build release     ;          The possible attributes are listed below. Project id is a short way to denote a project, as         opposed to the Jamfile's pathname. It is a hierarchical path,         unrelated to filesystem, such as "boost/thread". Target references make use of project ids to         specify a target. Source location specifies the directory where sources         for the project are located. Project requirements are requirements that apply to         all the targets in the projects as well as all subprojects. Default build is the build request that should be         used when no build request is specified explicitly.          The default values for those attributes are         given in the table below.            Table&#160;41.3.&#160;         Attribute Name Default value Handling by the project                 rule    Project id none none Assigned from the first parameter of the 'project' rule.                   It is assumed to denote absolute project id.   Source location source-location The location of jamfile for the project Sets to the passed value   Requirements requirements The parent's requirements The parent's requirements are refined with the passed                   requirement and the result is used as the project                   requirements.   Default build default-build none Sets to the passed value   Build directory build-dir Empty if the parent has no build directory set.                 Otherwise, the parent's build directory with the                 relative path from parent to the current project                 appended to it.                  Sets to the passed value, interpreted as relative to the                   project's location.               Besides defining projects and main targets, Jamfiles       often invoke various utility rules. For the full list of rules       that can be directly used in Jamfile see       the section called &#8220;Builtin rules&#8221;.        Each subproject inherits attributes, constants and rules       from its parent project, which is defined by the nearest       Jamfile in an ancestor directory above       the subproject.  The top-level project is declared in a file       called Jamroot rather than       Jamfile.  When loading a project,       Boost.Build looks for either Jamroot or       Jamfile.  They are handled identically, except       that if the file is called Jamroot, the       search for a parent project is not performed.        Even when building in a subproject directory, parent       project files are always loaded before those of their       subprojects, so that every definition made in a parent project       is always available to its children. The loading order of any       other projects is unspecified.  Even if one project refers to       another via the use-project or a target reference,       no specific order should be assumed.           Note  Giving the root project the special name         &#8220;Jamroot&#8221; ensures that         Boost.Build won't misinterpret a directory above it as the         project root just because the directory contains a Jamfile.                       The Build Process  Build Request Building a main target Building a Project  When you've described your targets, you want Boost.Build to run the       right tools and create the needed targets.              This section will describe       two things: how you specify what to build, and how the main targets are       actually constructed.      The most important thing to note is that in Boost.Build, unlike       other build tools, the targets you declare do not correspond to specific       files. What you declare in a Jamfile is more like a &#8220;metatarget.&#8221;              Depending on the properties you specify on the command line,       each metatarget will produce a set of real targets corresponding       to the requested properties. It is quite possible that the same       metatarget is built several times with different properties,       producing different files.         Tip           This means that for Boost.Build, you cannot directly obtain a build         variant from a Jamfile. There could be several variants requested by the         user, and each target can be built with different properties.           Build Request          The command line specifies which targets to build and with which         properties. For example:   b2 app1 lib1//lib1 toolset=gcc variant=debug optimization=full           would build two targets, "app1" and "lib1//lib1" with the specified         properties. You can refer to any targets, using         target id and specify arbitrary         properties. Some of the properties are very common, and for them the name         of the property can be omitted. For example, the above can be written as:   b2 app1 lib1//lib1 gcc debug optimization=full           The complete syntax, which has some additional shortcuts, is         described in the section called &#8220;Invocation&#8221;.           Building a main target When you request, directly or indirectly, a build of a main target         with specific requirements, the following steps are done. Some brief         explanation is provided, and more details are given in the section called &#8220;Build process&#8221;.           Applying default build. If the default-build           property of a target specifies a value of a feature that is not           present in the build request, that value is added. Selecting the main target alternative to use. For               each alternative we look how many properties are present both in               alternative's requirements, and in build request. The               alternative with large number of matching properties is selected.              Determining "common" properties.                          The build request               is refined               with target's requirements.                              The conditional properties in               requirements are handled as well. Finally, default values of               features are added.              Building targets referred by the sources list and               dependency properties. The list of sources and the properties               can refer to other target using target references. For each               reference, we take all propagated               properties, refine them by explicit properties specified in the               target reference, and pass the resulting properties as build               request to the other target.              Adding the usage requirements produced when building               dependencies to the "common" properties. When dependencies are               built in the previous step, they return                              both the set of created               "real" targets, and usage requirements. The usage requirements               are added to the common properties and the resulting property               set will be used for building the current target.              Building the target using generators. To convert the               sources to the desired type, Boost.Build uses "generators" ---               objects that correspond to tools like compilers and linkers. Each               generator declares what type of targets it can produce and what               type of sources it requires. Using this information, Boost.Build               determines which generators must be run to produce a specific               target from specific sources. When generators are run, they return               the "real" targets.              Computing the usage requirements to be returned. The           conditional properties in usage requirements are expanded                      and the result is returned.             Building a Project Often, a user builds a complete project, not just one main       target. In fact, invoking b2 without       arguments              builds the project defined in the current       directory. When a project is built, the build request is passed without         modification to all main targets in that project.                  It's is possible to         prevent implicit building of a target in a project with the         explicit rule:   explicit hello_test ;           would cause the hello_test target to be built only if         explicitly requested by the user or by some other target.        The Jamfile for a project can include a number of       build-project rule calls that specify additional projects to       be built.             Copyright &#169; 2006-2009 Vladimir PrusDistributed under the Boost Software License, Version 1.0.       (See accompanying file LICENSE_1_0.txt or copy at        http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3144weight: 3
tittle: Reference
url :https://www.boost.org/doc/libs/1_53_0/doc/html/bbv2/reference.html
content:    Reference           Home Libraries People FAQ More        Reference  General information Builtin rules Builtin features Builtin tools Builtin modules Builtin classes Build process Definitions    General information Initialization   Initialization bjam's first job upon startup is to load the Jam code that         implements the build system. To do this, it searches for a file         called boost-build.jam, first in the invocation directory, then         in its parent and so forth up to the filesystem root, and finally         in the directories specified by the environment variable         BOOST_BUILD_PATH. When found, the file is interpreted, and should         specify the build system location by calling the boost-build         rule:  rule boost-build ( location ? )           If location is a relative path, it is treated as relative to         the directory of boost-build.jam. The directory specified by         that location and the directories in BOOST_BUILD_PATH are then searched for         a file called bootstrap.jam, which is expected to         bootstrap the build system. This arrangement allows the build         system to work without any command-line or environment variable         settings. For example, if the build system files were located in a         directory "build-system/" at your project root, you might place a         boost-build.jam at the project root containing:    boost-build build-system ;            In this case, running b2 anywhere in the project tree will         automatically find the build system. The default bootstrap.jam, after loading some standard         definitions, loads two site-config.jam and user-config.jam.     Builtin rules This section contains the list of all rules that     can be used in Jamfile&#8212;both rules that define new     targets and auxiliary rules.  exe Creates an executable file. See         the section called &#8220;Programs&#8221;. lib Creates an library file. See         the section called &#8220;Libraries&#8221;. install Installs built targets and other files. See         the section called &#8220;Installing&#8221;. alias Creates an alias for other targets. See         the section called &#8220;Alias&#8221;. unit-test Creates an executable that will be automatically run. See         the section called &#8220;Testing&#8221;.  compile, compile-fail, link, link-fail, run, run-fail  Specialized rules for testing. See         the section called &#8220;Testing&#8221;. obj Creates an object file. Useful when a single source         file must be compiled with special properties. preprocessed Creates an preprocessed source file. The arguments follow the         common syntax.  glob   The glob rule takes a list shell pattern         and returns the list of files in the project's source directory that         match the pattern. For example:           lib tools : [ glob *.cpp ] ;                   It is possible to also pass a second argument&#8212;the list of         exclude patterns. The result will then include the list of         files patching any of include patterns, and not matching any         of the exclude patterns. For example:           lib tools : [ glob *.cpp : file_to_exclude.cpp bad*.cpp ] ;                      glob-tree   The glob-tree is similar to the         glob except that it operates recursively from         the directory of the containing Jamfile. For example:           ECHO [ glob-tree *.cpp : .svn ] ;                   will print the names of all C++ files in your project. The         .svn exclude pattern prevents the         glob-tree rule from entering administrative         directories of the Subversion version control system.           project Declares project id and attributes, including         project requirements. See the section called &#8220;Projects&#8221;.          use-project Assigns a symbolic project ID to a project at         a given path. This rule must be better documented!           explicit  The explicit rule takes a single         parameter&#8212;a list of target names. The named targets will         be marked explicit, and will be built only if they are explicitly         requested on the command line, or if their dependents are built.         Compare this to ordinary targets, that are built implicitly when         their containing project is built. always  The always funciton takes a single         parameter&#8212;a list of metatarget names. The top-level targets produced         by the named metatargets will be always considered out of date. Consider this example:           exe hello : hello.cpp ; exe bye : bye.cpp ; always hello ;  If a build of hello is requested, then the binary will         always be relinked. The object files will not be recompiled, though. Note that if         a build of hello is not requested, for example you specify just         bye on the command line, hello will not         be relinked.  constant  Sets project-wide constant. Takes two         parameters: variable name and a value and makes the specified         variable name accessible in this Jamfile and any child Jamfiles.         For example:           constant VERSION : 1.34.0 ;                     path-constant  Same as constant except that         the value is treated as path relative to Jamfile location. For example,         if b2 is invoked in the current directory,         and Jamfile in helper subdirectory has:           path-constant DATA : data/a.txt ;                   then the variable DATA will be set to         helper/data/a.txt, and if b2         is invoked from the helper directory, then         the variable DATA will be set to         data/a.txt.           build-project Cause some other project to be built. This rule         takes a single parameter&#8212;a directory name relative to         the containing Jamfile. When the containing Jamfile is built,         the project located at that directory will be built as well.         At the moment, the parameter to this rule should be a directory         name. Project ID or general target references are not allowed.          test-suite This rule is deprecated and equivalent to         alias.     Builtin features This section documents the features that are built-in into     Boost.Build. For features with a fixed set of values, that set is     provided, with the default value listed first.  variant               A feature combining several low-level features, making it easy to             request common build configurations.                         Allowed values:             debug, release,             profile.                         The value debug expands to             &lt;optimization&gt;off &lt;debug-symbols&gt;on &lt;inlining&gt;off &lt;runtime-debugging&gt;on               The value release expands to             &lt;optimization&gt;speed &lt;debug-symbols&gt;off &lt;inlining&gt;full &lt;runtime-debugging&gt;off               The value profile expands to the same as             release, plus:             &lt;profiling&gt;on &lt;debug-symbols&gt;on               Users can define their own build variants using the             variant rule from the common module.                         Note: Runtime debugging is on in             debug builds to suit the expectations of people used to various             IDEs.                           link   Allowed values: shared,             static              A feature controling how libraries are built.              runtime-link   Allowed values: shared,             static              Controls if a static or shared C/C++ runtime should be used. There             are some restrictions how this feature can be used, for example             on some compilers an application using static runtime should             not use shared libraries at all, and on some compilers,             mixing static and shared runtime requires extreme care.  Check             your compiler documentation for more details.             threading  Allowed values: single,             multi              Controls if the project should be built in multi-threaded mode.  This feature does not             necessary change code generation in the compiler, but it causes the compiler to link             to additional or different runtime libraries, and define additional preprocessor              symbols (for example, _MT on Windows and _REENTRANT on Linux).              How those symbols affect the compiled code depends on the code itself.             source              The &lt;source&gt;X feature has the same effect on             building a target as putting X in the list of sources. It is useful             when you want to add the same source to all targets in the project             (you can put &lt;source&gt; in requirements) or to conditionally             include a source (using conditional requirements, see the section called &#8220;Conditions and alternatives&#8221;). See also the &lt;library&gt;              feature.            library              This feature is almost equivalent to the &lt;source&gt;             feature, except that it takes effect only for linking. When you want             to link all targets in a Jamfile to certain library, the             &lt;library&gt; feature is preferred over             &lt;source&gt;X&#8212;the latter will add the library to             all targets, even those that have nothing to do with libraries.                       dependency              Introduces a dependency on the target named by the value of this             feature (so it will be brought up-to-date whenever the target being             declared is). The dependency is not used in any other way.                                   implicit-dependency              Indicates that the target named by the value of this feature             may produce files that are included by the sources of the             target being declared.  See the section called &#8220;Generated headers&#8221;             for more information.                       use              Introduces a dependency on the target named by the value of this             feature (so it will be brought up-to-date whenever the target being             declared is), and adds its usage requirements to the build             properties                          of the target being declared. The dependency is not used in any             other way. The primary use case is when you want the usage             requirements (such as #include paths) of some library             to be applied, but do not want to link to it.                                  dll-path              Specify an additional directory where the system should             look for shared libraries when the executable or shared             library is run. This feature only affects Unix             compilers. Plase see the section called &#8220;       Why are the dll-path and hardcode-dll-paths        properties useful?     &#8221;             in the section called &#8220;Frequently Asked Questions&#8221; for details.            hardcode-dll-paths               Controls automatic generation of dll-path properties.            Allowed values:             true, false.  This property is             specific to Unix systems. If an executable is built with             &lt;hardcode-dll-paths&gt;true, the generated binary             will contain the list of all the paths to the used shared libraries.             As the result, the executable can be run without changing system             paths to shared libraries or installing the libraries to system             paths. This  is very             convenient during development. Plase see the FAQ entry for details. Note that on Mac             OSX, the paths are unconditionally hardcoded by the linker, and it             is not possible to disable that behaviour.   cflags, cxxflags, linkflags               The value of those features is passed without modification to the             corresponding tools. For cflags that is both the C and             C++ compilers, for cxxflags that is the C++ compiler             and for linkflags that is the linker. The features are             handy when you are trying to do something special that cannot be             achieved by a higher-level feature in Boost.Build.            include              Specifies an additional include path that is to be passed to C and             C++ compilers.            define              Specifies an preprocessor symbol that should be defined on the command             line. You may either specify just the symbol, which will be defined             without any value, or both the symbol and the value, separated by             equal sign.            warnings              The &lt;warnings&gt; feature controls the warning level             of compilers. It has the following values:              off - disables all warnings. on - enables default warning level for the tool. all - enables all warnings.              Default value is all.            warnings-as-errors              The &lt;warnings-as-errors&gt; makes it possible to             treat warnings as errors and abort compilation on a warning. The             value on enables this behaviour. The default value is             off.            build  Allowed values: no              The build feature is used to conditionally disable             build of a target. If &lt;build&gt;no is in properties             when building a target, build of that target is skipped. Combined             with conditional requirements this allows you to skip building some             target in configurations where the build is known to fail.             tag  The tag feature is used to customize         the name of the generated files. The value should have the form:  @rulename  where         rulename should be a name of a rule with the         following signature:  rule tag ( name : type ? : property-set )          The rule will be called for each target with the default name computed         by Boost.Build, the type of the target, and property set. The rule can         either return a string that must be used as the name of the target, or         an empty string, in which case the default name will be used.          Most typical use of the tag feature is to         encode build properties, or library version in library target names. You         should take care to return non-empty string from the tag rule only for         types you care about &#8212; otherwise, you might end up modifying         names of object files, generated header file and other targets for which         changing names does not make sense.  debug-symbols  Allowed values: on, off. The debug-symbols feature specifies if           produced object files, executables and libraries should include           debug information.           Typically, the value of this feature is implicitly set by the           variant feature, but it can be explicitly           specified by the user. The most common usage is to build           release variant with debugging information.  target-os               The operating system for which the code is to be generated. The             compiler you used should be the compiler for that operating             system. This option causes Boost.Build to use naming conventions             suitable for that operating system, and adjust build process             accordingly. For example, with gcc, it controls if import             libraries are produced for shared libraries or not.                                   The complete list of possible values for this feature is:              aix, bsd, cygwin, darwin, freebsd, hpux, iphone, linux, netbsd,             openbsd, osf, qnx, qnxnto, sgi, solaris, unix, unixware, windows.            See the section called &#8220;Cross-compilation&#8221; for details of           crosscompilation  architecture The architecture features specifies           the general processor familty to generate code for. instruction-set               Allowed values: depend on the used             toolset.            The instruction-set specifies for which           specific instruction set the code should be generated.  The           code in general might not run on processors with older/different           instruction sets. While Boost.Build allows a large set of possible values           for this features, whether a given value works depends on which           compiler you use. Please see           the section called &#8220;C++ Compilers&#8221; for details.             address-model  Allowed values: 32, 64. The address-model specifies if 32-bit or           64-bit code should be generated by the compiler. Whether this feature           works depends on the used compiler, its version, how the compiler is           configured, and the values of the architecture           instruction-set           features. Please see the section called &#8220;C++ Compilers&#8221;           for details.  c++-template-depth               Allowed values: Any positive             integer.                         This feature allows configuring a C++ compiler with the maximal             template instantiation depth parameter. Specific toolsets may or may             not provide support for this feature depending on whether their             compilers provide a corresponding command-line option.                         Note: Due to some internal details             in the current Boost Build implementation it is not possible to have             features whose valid values are all positive integer. As a             workaround a large set of allowed values has been defined for this             feature and, if a different one is needed, user can easily add it by             calling the feature.extend rule.             embed-manifest               Allowed values: on, off.            This feature is specific to the msvc toolset (see           the section called &#8220;Microsoft Visual C++&#8221;),           and controls whether the manifest files should be embedded inside           executables and shared libraries, or placed alongside them.  This           feature corresponds to the IDE option found in the project settings dialog,           under Configuration Properties &#8594; Manifest Tool &#8594; Input and Output &#8594; Embed manifest.                 Builtin tools  C++ Compilers Third-party libraries Documentation tools  Boost.Build comes with support for a large number of C++ compilers,       and other tools. This section documents how to use those tools. Before using any tool, you must declare your intention, and possibly       specify additional information about the tool's configuration. This is       done by calling the using rule, typically in your       user-config.jam, for example:  using gcc ;  additional parameters can be passed just like for other rules, for example:  using gcc : 4.0 : g++-4.0 ;  The options that can be passed to each tool are documented in the       subsequent sections.   C++ Compilers  GNU C++ Apple Darwin gcc Microsoft Visual C++ Intel C++ HP aC++ compiler Borland C++ Compiler Comeau C/C++ Compiler Code Warrior Digital Mars C/C++ Compiler HP C++ Compiler for Tru64 Unix Sun Studio IBM Visual Age  This section lists all Boost.Build modules that support C++           compilers and documents how each one can be initialized.  The name           of support module for compiler is also the value for           the toolset feature that can be used to explicitly           request that compiler.    GNU C++ The gcc module supports the           GNU C++ compiler           on Linux, a number of Unix-like system including SunOS and on Windows            (either Cygwin or            MinGW). On Mac OSX, it is recommended           to use system gcc, see the section called &#8220;Apple Darwin gcc&#8221;.            The gcc module is initialized using the following           syntax:  using gcc : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler.            If the version is not explicitly specified, it will be           automatically detected by running the compiler with the -v           option. If the command is not specified, the g++           binary will be searched in PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker. root Specifies root directory of the compiler installation.       This option is necessary only if it is not possible to detect this       information from the compiler command&#8212;for example if the specified       compiler command is a user script. rc Specifies the resource compiler command                 that will be used with the version of gcc that is being                 configured. This setting makes sense only for Windows and only                 if you plan to use resource files. By                 default windres will be used. rc-type Specifies the type of resource compiler. The value can                 be either windres for msvc resource compiler,                 or rc for borland's resource compiler.              In order to compile 64-bit applications, you have to specify           address-model=64, and the instruction-set           feature should refer to a 64 bit processor. Currently, those           include nocona, opteron,           athlon64 and athlon-fx.             Apple Darwin gcc The darwin module supports the version of gcc that is           modified and provided by Apple. The configuration is essentially identical           to that of the gcc module.                                  The darwin toolset can generate so called "fat"           binaries&#8212;binaries that can run support more than one           architecture, or address mode. To build a binary that can run both           on Intel and PowerPC processors, specify           architecture=combined. To build a binary that can run           both in 32-bit and 64-bit modes, specify           address-model=32_64. If you specify both of those           properties, a "4-way" fat binary will be generated.               Microsoft Visual C++ The msvc module supports the           Microsoft Visual           C++ command-line tools on Microsoft Windows. The supported           products and versions of command line tools are listed below:  Visual Studio 2010&#8212;10.0 Visual Studio 2008&#8212;9.0 Visual Studio 2005&#8212;8.0 Visual Studio .NET 2003&#8212;7.1 Visual Studio .NET&#8212;7.0 Visual Studio 6.0, Service Pack 5&#8212;6.5  The msvc module is initialized using the following           syntax:  using msvc : [version] : [c++-compile-command] : [compiler options] ;            This statement may be repeated several times, if you want to configure several versions of the compiler. If the version is not explicitly specified, the most recent           version found in the registry will be used instead. If the special           value all is passed as the version, all versions found in           the registry will be configured. If a version is specified, but the           command is not, the compiler binary will be searched in standard           installation paths for that version, followed by PATH.            The compiler command should be specified using forward slashes,           and quoted. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker. assembler The command that compiles assembler sources. If               not specified, ml will be used. The command               will be invoked after the setup script was executed and adjusted               the PATH variable. compiler The command that compiles C and C++ sources. If               not specified, cl will be used. The command               will be invoked after the setup script was executed and adjusted               the PATH variable. compiler-filter Command through which to pipe the output of               running the compiler. For example to pass the output to STLfilt.                idl-compiler The command that compiles Microsoft COM interface               definition files. If not specified, midl will               be used. The command will be invoked after the setup script was               executed and adjusted the PATH variable. linker The command that links executables and dynamic               libraries. If not specified, link will be used.               The command will be invoked after the setup script was executed               and adjusted the PATH variable. mc-compiler The command that compiles Microsoft message               catalog files. If not specified, mc will be               used. The command will be invoked after the setup script was               executed and adjusted the PATH variable. resource-compiler The command that compiles resource files. If not               specified, rc will be used. The command will be               invoked after the setup script was executed and adjusted the               PATH variable. setup The filename of the global environment setup               script to run before invoking any of the tools defined in this               toolset. Will not be used in case a target platform specific               script has been explicitly specified for the current target               platform. Used setup script will be passed the target platform               identifier (x86, x86_amd64, x86_ia64, amd64 or ia64) as a               arameter. If not specified a default script is chosen based on the               used compiler binary, e.g. vcvars32.bat or               vsvars32.bat.  setup-amd64, setup-i386, setup-ia64  The filename of the target platform specific               environment setup script to run before invoking any of the tools               defined in this toolset. If not specified the global environment               setup script is used.    64-bit support Starting with version 8.0, Microsoft Visual Studio can             generate binaries for 64-bit processor, both 64-bit flavours of x86             (codenamed AMD64/EM64T), and Itanium (codenamed IA64). In addition,             compilers that are itself run in 64-bit mode, for better             performance, are provided. The complete list of compiler             configurations are as follows (we abbreviate AMD64/EM64T to just             AMD64):  32-bit x86 host, 32-bit x86 target 32-bit x86 host, 64-bit AMD64 target 32-bit x86 host, 64-bit IA64 target 64-bit AMD64 host, 64-bit AMD64 target 64-bit IA64 host, 64-bit IA64 target               The 32-bit host compilers can be always used, even on 64-bit             Windows. On the contrary, 64-bit host compilers require both 64-bit             host processor and 64-bit Windows, but can be faster. By default,             only 32-bit host, 32-bit target compiler is installed, and             additional compilers need to be installed explicitly.              To use 64-bit compilation you should:  Configure you compiler as usual. If you provide a               path to the compiler explicitly, provide the path to the 32-bit               compiler. If you try to specify the path to any of 64-bit               compilers, configuration will not work. When compiling, use address-model=64,               to generate AMD64 code. To generate IA64 code, use               architecture=ia64  The (AMD64 host, AMD64 target) compiler will be used             automatically when you are generating AMD64 code and are running             64-bit Windows on AMD64. The (IA64 host, IA64 target) compiler will             never be used, since nobody has an IA64 machine to test. It is believed that AMD64 and EM64T targets are essentially             compatible. The compiler options /favor:AMD64 and             /favor:EM64T, which are accepted only by AMD64             targeting compilers, cause the generated code to be tuned to a             specific flavor of 64-bit x86. Boost.Build will make use of those             options depending on the value of theinstruction-set             feature.     Intel C++ The intel-linux and intel-win modules           support the Intel C++ command-line compiler&#8212;the Linux           and            Windows versions respectively. The module is initialized using the following syntax:  using intel-linux : [version] : [c++-compile-command] : [compiler options] ; or  using intel-win : [version] : [c++-compile-command] : [compiler options] ; respectively. This statement may be repeated several times, if you want to configure several versions of the compiler.            If compiler command is not specified, then Boost.Build will           look in PATH for an executable icpc           (on Linux), or icc.exe (on Windows).            The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.  The Linux version supports the following additional options:  root Specifies root directory of the compiler installation.       This option is necessary only if it is not possible to detect this       information from the compiler command&#8212;for example if the specified       compiler command is a user script.     HP aC++ compiler The acc module supports the HP aC++ compiler           for the HP-UX operating system. The module is initialized using the following           syntax:  using acc : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler.              If the command is not specified, the aCC           binary will be searched in PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.     Borland C++ Compiler The borland module supports the command line           C++ compiler included in           C++ Builder 2006           product and earlier version of it, running on Microsoft Windows. The supported products are listed below. The version reported           by the command lines tools is also listed for reference.:  C++ Builder 2006&#8212;5.8.2 CBuilderX&#8212;5.6.5, 5.6.4 (depending on release) CBuilder6&#8212;5.6.4 Free command line tools&#8212;5.5.1  The module is initialized using the following syntax:  using borland : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler. If the command is not specified, Boost.Build will search for           a binary named bcc32 in PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.     Comeau C/C++ Compiler The como-linux and the como-win           modules supports the           Comeau C/C++ Compiler           on Linux and Windows respectively. The module is initialized using the following syntax:  using como-linux : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler. If the command is not specified, Boost.Build will search for           a binary named como in           PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.  Before using the Windows version of the compiler, you need to           setup necessary environment variables per compiler's documentation. In           particular, the COMO_XXX_INCLUDE variable should be           set, where XXX corresponds to the used backend C           compiler.    Code Warrior The cw module support CodeWarrior compiler,           originally produced by Metrowerks and presently developed by           Freescale. Boost.Build supports only the versions of the compiler that           target x86 processors. All such versions were released by Metrowerks           before aquisition and are not sold any longer. The last version known           to work is 9.4. The module is initialized using the following syntax:  using cw : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler. If the command is not specified, Boost.Build will search for a           binary named mwcc in default installation paths and           in PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker. root Specifies root directory of the compiler installation.       This option is necessary only if it is not possible to detect this       information from the compiler command&#8212;for example if the specified       compiler command is a user script. setup The command that sets up environment variables               prior to invoking the compiler. If not specified,               cwenv.bat alongside the compiler binary               will be used. compiler The command that compiles C and C++ sources.               If not specified, mwcc will be used. The               command will be invoked after the setup script was               executed and adjusted the PATH variable. linker The command that links executables and dynamic               libraries.               If not specified, mwld will be used. The               command will be invoked after the setup script was               executed and adjusted the PATH variable.     Digital Mars C/C++ Compiler The dmc module supports the           Digital Mars C++ compiler.            The module is initialized using the following syntax:  using dmc : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler. If the command is not specified, Boost.Build will search for           a binary named dmc in           PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.     HP C++ Compiler for Tru64 Unix The hp_cxx modules supports the                        HP C++ Compiler for Tru64 Unix. The module is initialized using the following syntax:  using hp_cxx : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler. If the command is not specified, Boost.Build will search for           a binary named hp_cxx in PATH. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.     Sun Studio The sun module supports the                      Sun Studio C++ compilers for the Solaris OS. The module is initialized using the following syntax:  using sun : [version] : [c++-compile-command] : [compiler options] ; This statement may be repeated several times, if you want to configure several versions of the compiler. If the command is not specified, Boost.Build will search for           a binary named CC           in /opt/SUNWspro/bin and in           PATH. When using this compiler on complex C++ code, such as the           Boost C++ library, it is           recommended to specify the following options when intializing the           sun module:             -library=stlport4 -features=tmplife -features=tmplrefstatic             See the            Sun C++ Frontend Tales for details. The following options can be provided, using &lt;option-name&gt;option-value syntax:  cflags Specifies additional compiler flags that will be used when       compiling C sources. cxxflags Specifies additional compiler flags that will be used when       compiling C++ sources. compileflags Specifies additional compiler flags that will be used when       compiling both C and C++ sources. linkflags Specifies additional command line options that will be       passed to the linker.             Starting with Sun Studio 12, you can create 64-bit applications           by using the address-model=64 property.             IBM Visual Age The vacpp module supports the           IBM Visual           Age C++ Compiler, for the AIX operating system. Versions           7.1 and 8.0 are known to work. The module is initialized using the following           syntax:  using vacpp ; The module does not accept any initialization options. The           compiler should be installed in the /usr/vacpp/bin           directory. Later versions of Visual Age are known as XL C/C++. They           were not tested with the the vacpp module.     Third-party libraries STLport library Boost.Build provides special support for some         third-party C++ libraries, documented below.   STLport library The STLport library           is an alternative implementation of C++ runtime library. Boost.Build           supports using that library on Windows platfrom.  Linux is           hampered by different naming of libraries in each STLport           version and is not officially supported. Before using STLport, you need to configure it in           user-config.jam using the following syntax:             using stlport : [version] : header-path : [library-path] ;             Where version is the version of           STLport, for example 5.1.4,           headers is the location where           STLport headers can be found, and libraries           is the location where STLport libraries can be found.           The version should always be provided, and the library path should           be provided if you're using STLport's implementation of           iostreams. Note that STLport 5.* always uses its own iostream           implementation, so the library path is required.            When STLport is configured, you can build with STLport by           requesting stdlib=stlport on the command line.                Documentation tools  xsltproc boostbook doxygen quickbook fop  Boost.Build support for the Boost documentation tools is         documented below.            xsltproc To use xsltproc, you first need to configure it using the following syntax:  using xsltproc : [xsltproc] ;             Where xsltproc is the xsltproc executable.           If xsltproc is not specified, and the           variable XSLTPROC is set, the value of XSLTPROC will be used.           Otherwise, xsltproc will be searched for in PATH.            The following options can be provided, using &lt;option-name&gt;option-value syntax:  xsl:param Values should have the form                 name=value xsl:path Sets an additional search path for xi:include elements. catalog A catalog file used to rewrite remote URL's to a local copy.  The xsltproc module provides the following rules.  Note that           these operate on jam targets and are intended to be used by another           toolset, such as boostbook, rather than directly by users.             xslt   rule xslt ( target : source stylesheet : properties * )  Runs xsltproc to create a single output file.  xslt-dir   rule xslt-dir ( target : source stylesheet : properties * : dirname )  Runs xsltproc to create multiple outputs in a directory.                 dirname is unused, but exists for                 historical reasons.  The output directory is determined from the                 target.                       boostbook To use boostbook, you first need to configure it using the following syntax:  using boostbook : [docbook-xsl-dir] : [docbook-dtd-dir] : [boostbook-dir] ;             docbook-xsl-dir is the DocBook XSL stylesheet           directory. If not provided, we use DOCBOOK_XSL_DIR from the environment           (if available) or look in standard locations.  Otherwise, we let the           XML processor load the stylesheets remotely.                       docbook-dtd-dir is the DocBook DTD directory.           If not provided, we use DOCBOOK_DTD_DIR From the environment (if           available) or look in standard locations.  Otherwise, we let the XML           processor load the DTD remotely.                       boostbook-dir is the BoostBook directory           with the DTD and XSL subdirs.            The boostbook module depends on xsltproc.  For pdf or ps output,           it also depends on fop.            The following options can be provided, using &lt;option-name&gt;option-value syntax:  format                     Allowed values:                   html, xhtml,                   htmlhelp, onehtml,                   man, pdf,                   ps, docbook,                   fo, tests.                  The format feature determines the type                 of output produced by the boostbook rule.   The boostbook module defines a rule for creating a target           following the common syntax.  boostbook   rule boostbook ( target-name : sources * : requirements * : default-build * )  Creates a boostbook target.      doxygen To use doxygen, you first need to configure it using the following syntax:  using doxygen : [name] ;             name is the doxygen command.           If it is not specified, it will be found in the PATH.            The doxygen module depends on the boostbook module when           generating BoostBook XML.            The following options can be provided, using &lt;option-name&gt;option-value syntax:  doxygen:param All the values of doxygen:param                  are added to the doxyfile. prefix Specifies the common prefix of all headers                 when generating BoostBook XML.  Everything before                 this will be stripped off.                  reftitle Specifies the title of the library-reference section,                 when generating BoostBook XML. doxygen:xml-imagedir  When generating BoostBook XML, specifies the                 directory in which to place the images generated                 from LaTex formulae.    Warning  The path is interpreted relative to the                 current working directory, not relative to the Jamfile.                 This is necessary to match the behavior of BoostBook.                     The doxygen module defines a rule for creating a target           following the common syntax.  doxygen   rule doxygen ( target : sources * : requirements * : default-build * : usage-requirements * )  Creates a doxygen target.  If the target name                 ends with .html, then this will generate an html                 directory.  Otherwise it will generate BoostBook XML.                       quickbook The quickbook module provides a generator to convert from           Quickbook to BoostBook XML. To use quickbook, you first need to configure it using the following syntax:  using quickbook : [command] ;             command is the quickbook executable.           If it is not specified, Boost.Build will compile it from source.           If it is unable to find the source it will search for a quickbook           executable in PATH.               fop The fop module provides generators to convert from           XSL formatting objects to Postscript and PDF. To use fop, you first need to configure it using the following syntax:  using fop : [fop-command] : [java-home] : [java] ;             fop-command is the command to run fop.           If it is not specified, Boost.Build will search for it in PATH and           FOP_HOME.                       Either java-home or           java           can be used to specify where to find java.                 Builtin modules  modules path type         This section describes the modules that are provided       by Boost.Build.  The import rule allows rules from       one module to be used in another module or Jamfile.        modules          The modules module defines basic functionality         for handling modules.                 A module defines a number of rules that can be used in other         modules.  Modules can contain code at the top level to initialize         the module.  This code is executed the first time the         module is loaded.             Note               A Jamfile is a special kind of module which is managed by             the build system.  Although they cannot be loaded directly             by users, the other features of modules are still useful             for Jamfiles.                              Each module has its own namespaces for variables and rules.  If two         modules A and B both use a variable named X, each one gets its own         copy of X.  They won't interfere with each other in any way.         Similarly, importing rules into one module has no effect on any other         module.                 Every module has two special variables.         $(__file__) contains the name of the file that         the module was loaded from and $(__name__)         contains the name of the module.             Note  $(__file__) does not contain         the full path to the file.  If you need this, use         modules.binding.            rule binding ( module-name )Returns the filesystem binding of the given module. For example, a module can get its own location with:            me = [ modules.binding $(__name__) ] ;               rule poke ( module-name ? : variables + : value * )Sets the module-local value of a variable. For example, to set a variable in the global module:            modules.poke : ZLIB_INCLUDE : /usr/local/include ;               rule peek ( module-name ? : variables + )Returns the module-local value of a variable.              For example, to read a variable from the global module:              local ZLIB_INCLUDE = [ modules.peek : ZLIB_INCLUDE ] ;               rule call-in ( module-name ? : rule-name args * : * ) Call the given rule locally in the given module. Use           this for rules accepting rule names as arguments, so that           the passed rule may be invoked in the context of the rule's           caller (for example, if the rule accesses module globals or           is a local rule).               Note  rules called this way may accept at most           8 parameters.  Example:   rule filter ( f : values * ) {     local m = [ CALLER_MODULE ] ;     local result ;     for v in $(values)     {         if [ modules.call-in $(m) : $(f) $(v) ]         {             result += $(v) ;         }     }     return result ; }                rule load ( module-name : filename ? : search * )Load the indicated module if it is not already loaded.  module-name Name of module to load.   filename (partial) path to file; Defaults to $(module-name).jam   search Directories in which to search for filename.                   Defaults to $(BOOST_BUILD_PATH).    rule import ( module-names + : rules-opt * : rename-opt * )Load the indicated module and import rule names into the           current module. Any members of rules-opt will be           available without qualification in the caller's module. Any           members of rename-opt will be taken as the names           of the rules in the caller's module, in place of the names they           have in the imported module.  If rules-opt = '*',           all rules from the indicated module are imported into the           caller's module. If rename-opt is supplied, it must have the           same number of elements as rules-opt.    Note  The import rule is available           without qualification in all modules.  Examples:   import path ; import path : * ; import path : join ; import path : native make : native-path make-path ;                rule clone-rules ( source-module target-module )Define exported copies in $(target-module)           of all rules exported from $(source-module). Also           make them available in the global module with qualification,           so that it is just as though the rules were defined originally           in $(target-module).      path      Performs various path manipulations. Paths are always in a 'normalized'     representation. In it, a path may be either:            '.', or            ['/'] [ ( '..' '/' )* (token '/')* token ]                     In plain english, a path can be rooted, '..'     elements are allowed only at the beginning, and it never     ends in slash, except for the path consisting of slash only.      rule make ( native )Converts the native path into normalized form.   rule native ( path )Builds the native representation of the path.   rule is-rooted ( path )Tests if a path is rooted.   rule has-parent ( path )Tests if a path has a parent.   rule basename ( path )Returns the path without any directory components.   rule parent ( path )Returns the parent directory of the path. If no parent exists, an error is issued.   rule reverse ( path )         Returns path2 such that         [ join path path2 ] = ".".         The path may not contain ".."         element or be rooted.          rule join ( elements + )         Concatenates the passed path elements. Generates an error if any         element other than the first one is rooted. Skips any empty or         undefined path elements.          rule root ( path root )         If path is relative, it is rooted at         root. Otherwise, it is unchanged.          rule pwd ( )Returns the current working directory.   rule glob ( dirs * : patterns + : exclude-patterns * )         Returns the list of files matching the given pattern in the specified         directory. Both directories and patterns are supplied as portable paths. Each         pattern should be a non-absolute path, and can't contain "." or ".." elements.         Each slash separated element of a pattern can contain the following special         characters:           '?' matches any character '*' matches an arbitrary number of characters           A file $(d)/e1/e2/e3 (where 'd' is in $(dirs)) matches the pattern p1/p2/p3 if and         only if e1 matches p1, e2 matches p2 and so on.                  For example:   [ glob . : *.cpp ] [ glob . : */build/Jamfile ]            rule glob-tree ( roots * : patterns + : exclude-patterns * )         Recursive version of glob.         Builds the glob of files while also searching in         the subdirectories of the given roots. An optional set of exclusion patterns         will filter out the matching entries from the result. The exclusions also         apply to the subdirectory scanning, such that directories that match the         exclusion patterns will not be searched.          rule exists ( file )Returns true if the specified file exists.   rule all-parents ( path : upper_limit ? : cwd ? )         Find out the absolute name of path and return the list of all the parents,         starting with the immediate one. Parents are returned as relative names. If         upper_limit is specified, directories above it         will be pruned.          rule glob-in-parents ( dir : patterns + : upper-limit ? )         Search for patterns in parent directories         of dir, up to and including         upper_limit, if it is specified, or         till the filesystem root otherwise.          rule relative ( child parent : no-error ? )         Assuming child is a subdirectory of         parent, return the relative path from         parent to child.          rule relative-to ( path1 path2 )Returns the minimal path to path2 that is relative path1.   rule programs-path ( )         Returns the list of paths which are used by the operating system for         looking up programs.          rule makedirs ( path )         Creates a directory and all parent directories that do not         already exist.             type      Deals with target type declaration and defines target class which supports     typed targets.      rule register ( type : suffixes * : base-type ? )         Registers a target type, possible derived from a         base-type.  Providing a list         of suffixes here is a shortcut for separately calling the         register-suffixes         rule with the given suffixes and the         set-generated-target-suffix         rule with the first given suffix.          rule register-suffixes ( suffixes + : type )         Specifies that files with suffix from suffixes         be recognized as targets of  type type.         Issues an error if a different type is already specified for any         of the suffixes.          rule registered ( type )Returns true iff type has been registered.   rule validate ( type )Issues an error if type is unknown.   rule set-scanner ( type : scanner )Sets a scanner class that will be used for this type.   rule get-scanner ( type : property-set )         Returns a scanner instance appropriate to type         and property-set.          rule base ( type )         Returns a base type for the given type or nothing in case the given         type is not derived.          rule all-bases ( type )         Returns the given type and all of its base types in order of         their distance from type.          rule all-derived ( type )         Returns the given type and all of its derived types in order         of their distance from type.          rule is-derived ( type base )         Returns true if type is equal to         base or has base         as its direct or indirect base.          rule set-generated-target-suffix ( type : properties * : suffix )         Sets a file suffix to be used when generating a target of type with the         specified properties. Can be called with no properties if no suffix has         already been specified for the type. The suffix parameter can be an empty         string ("") to indicate that no suffix should be used.                 Note that this does not cause files with suffix         to be automatically recognized as being of type.         Two different types can use the same suffix for their generated files         but only one type can be auto-detected for a file with that suffix.         User should explicitly specify which one using the         register-suffixes         rule.          rule change-generated-target-suffix ( type : properties * : suffix )         Change the suffix previously registered for this type/properties         combination. If suffix is not yet specified, sets it.          rule generated-target-suffix ( type : property-set )         Returns the suffix used when generating a file of         type with the given properties.          rule set-generated-target-prefix ( type : properties * : prefix )         Sets a target prefix that should be used when generating targets of         type with the specified properties. Can         be called with empty properties if no prefix for         type has been specified yet.                 The prefix parameter can be empty string         ("") to indicate that no prefix         should be used.                 Usage example: library names use the "lib"         prefix on unix.          rule change-generated-target-prefix ( type : properties * : prefix )         Change the prefix previously registered for this type/properties         combination. If prefix is not yet specified, sets it.          rule generated-target-prefix ( type : property-set )         Returns the prefix used when generating a file of         type with the given properties.          rule type ( filename )         Returns file type given its name. If there are several         dots in filename, tries each suffix. E.g. for name of         "file.so.1.2" suffixes "2", "1", and "so" will be tried.              Builtin classes  Class abstract-target Class project-target Class main-target Class basic-target Class typed-target Class property-set    Class abstract-target      Base class for all abstract targets.     class abstract-target {     rule __init__ ( name : project )     rule name ( )     rule project ( )     rule location ( )     rule full-name ( )     rule generate ( property-set ) }       Classes derived from abstract-target:       project-target main-target basic-target        rule __init__ ( name : project )           name The name of the target in the Jamfile. project The project to which this target belongs.            rule name ( )Returns the name of this target.   rule project ( )Returns the project for this target.   rule location ( )Returns the location where the target was declared.   rule full-name ( )Returns a user-readable name for this target.   rule generate ( property-set )         Generates virtual targets for this abstract target using the specified         properties, unless a different value of some feature is required by the         target.  This is an abstract method which must be overriden by derived         classes.                 On success, returns:           a property-set with the usage requirements to be applied to dependents a list of produced virtual targets, which may be empty.           If property-set is empty, performs the         default build of this target, in a way specific to the derived class.             Class project-target  class project-target : abstract-target {     rule generate ( property-set )     rule build-dir ( )     rule main-target ( name )     rule has-main-target ( name )     rule find ( id : no-error ? )      # Methods inherited from abstract-target     rule name ( )     rule project ( )     rule location ( )     rule full-name ( ) }       This class has the following responsibilities:                 Maintaining a list of main targets in this project and building them.                rule generate ( property-set )         Overrides         abstract-target.generate.          Generates virtual targets for all the targets contained in this project.                 On success, returns:           a property-set with the usage requirements to be applied to dependents a list of produced virtual targets, which may be empty.            rule build-dir ( )         Returns the root build directory of the project.          rule main-target ( name )         Returns a main-target         class instance corresponding to name.         Can only be called after the project has been fully loaded.          rule has-main-target ( name )         Returns whether a main-target         with the specified name exists.         Can only be called after the project has been fully loaded.          rule find ( id : no-error ? )         Find and return the target with the specified id, treated relative to         self. Id may specify either a target or a file name with the target taking         priority. May report an error or return nothing if the target is not found         depending on the no-error parameter.             Class main-target  class main-target : abstract-target {     rule generate ( property-set )      # Methods inherited from abstract-target     rule name ( )     rule project ( )     rule location ( )     rule full-name ( ) }       A main-target     represents a named top-level target in a Jamfile.     rule generate ( property-set )         Overrides         abstract-target.generate.                  Select an alternative for this main target, by finding all alternatives         whose requirements are satisfied by property-set and         picking the one with the longest requirements set. Returns the result         of calling generate         on that alternative.                 On success, returns:           a property-set with the usage requirements to be applied to dependents a list of produced virtual targets, which may be empty.              Class basic-target  class basic-target : abstract-target {     rule __init__ ( name : project : sources * : requirements * : default-build * : usage-requirements * )       rule generate ( property-set )     rule construct ( name : source-targets * : property-set )      # Methods inherited from abstract-target     rule name ( )     rule project ( )     rule location ( )     rule full-name ( ) }       Implements the most standard way of constructing main target alternative from     sources. Allows sources to be either files or other main targets and handles     generation of those dependency targets.            rule __init__ ( name : project : sources * : requirements * : default-build * : usage-requirements * )           name The name of the target project                  The project                 in which the target is declared.                           rule generate ( property-set )         Overrides         abstract-target.generate.          Determines final build properties, generates sources, and calls         construct.         This method should not be overridden.                 On success, returns:           a property-set with the usage requirements to be applied to dependents a list of produced virtual targets, which may be empty.            rule construct ( name : source-targets * : property-set )         Constructs virtual targets for this abstract target. Returns a         usage-requirements property-set and a list of virtual         targets. Should be overriden in derived classes.             Class typed-target  class typed-target : basic-target {     rule __init__ ( name : project : type : sources * : requirements * : default-build * : usage-requirements * )      rule type ( )     rule construct ( name : source-targets * : property-set )      # Methods inherited from abstract-target     rule name ( )     rule project ( )     rule location ( )     rule full-name ( )          # Methods inherited from basic-target     rule generate ( property-set )   }       typed-target     is the most common kind of target alternative.  Rules for creating     typed targets are defined automatically for each type.      rule __init__ ( name : project : type : sources * : requirements * : default-build * : usage-requirements * )           name The name of the target project                  The project                 in which the target is declared.                type                  The type                 of the target.                           rule type ( )         Returns the type         of the target.          rule construct ( name : source-targets * : property-set )         Implements          basic-target.construct.  Attempts to create a target of         the correct type using generators appropriate for the given         property-set.         Returns a          property-set containing the usage requirements         and a list of virtual targets.                      Note               This function is invoked automatically by             basic-target.generate             and should not be called directly by users.                          Class property-set Class for storing a set of properties.  class property-set {     rule raw ( )     rule str ( )     rule propagated ( )     rule add ( ps )     rule add-raw ( properties * )     rule refine ( ps )     rule get ( feature ) }       There is 1&lt;-&gt;1 correspondence between identity and value. No two instances     of the class are equal. To maintain this property, the 'property-set.create'     rule should be used to create new instances. Instances are immutable.      rule raw ( )Returns a Jam list of the stored properties.   rule str ( )Returns the string repesentation of the stored properties.   rule propagated ( )         Returns a property-set         containing all the propagated         properties in this property-set.          rule add ( ps )         Returns a new          property-set containing the union of the properties         in this          property-set and in ps.             Note               If ps contains non-free properties             that should override the values in this object, use                          refine instead.                       rule add-raw ( properties * )         Link          add, except that it takes a list of properties         instead of a          property-set.          rule refine ( ps )         Refines properties by overriding any non-free and non-conditional         properties for which a different value is specified in         ps. Returns the resulting         property-set.          rule get ( feature )         Returns all the values of feature.              Build process  Alternative selection Determining common properties Target Paths  The general overview of the build process was given in the       user documentation.       This section provides additional details, and some specific rules.      To recap, building a target with specific properties includes the       following steps:         applying default build, selecting the main target alternative to use,            determining "common" properties, building targets referred by the sources list and             dependency properties, adding the usage requirements produces when building             dependencies to the "common" properties, building the target using generators, computing the usage requirements to be returned.          Alternative selection When there are several alternatives, one of them must be         selected. The process is as follows:               For each alternative condition is defined as             the set of base properties in requirements. [Note: it might be             better to specify the condition explicitly, as in conditional             requirements].                         An alternative is viable only if all properties in condition             are present in build request.                         If there's one viable alternative, it's choosen. Otherwise,             an attempt is made to find one best alternative. An alternative             a is better than another alternative b, iff the set of properties             in b's condition is a strict subset of the set of properities of             'a's condition. If there's one viable alternative, which is             better than all others, it's selected. Otherwise, an error is             reported.                Determining common properties The "common" properties is a somewhat artificial term. Those are         the intermediate property set from which both the build request for         dependencies and properties for building the target are derived.        Since default build and alternatives are already handled, we have         only two inputs: build requests and requirements. Here are the rules         about common properties.         Non-free feature can have only one             value A non-conditional property in requirement in always             present in common properties. A property in build request is present in             common properties, unless (2) tells otherwise. If either build request, or requirements (non-conditional             or conditional) include an expandable property (either composite,             or property with specified subfeature value), the behaviour is             equivalent to explicitly adding all expanded properties to build             request or requirements. If requirements include a conditional property, and             condiiton of this property is true in context of common             properties, then the conditional property should be in common             properties as well. If no value for a feature is given by other rules             here, it has default value in common properties.  Those rules are declarative, they don't specify how to compute the         common properties. However, they provide enough information for the         user. The important point is the handling of conditional         requirements. The condition can be satisfied either by property in         build request, by non-conditional requirements, or even by another         conditional property. For example, the following example works as         expected:   exe a : a.cpp       : &lt;toolset&gt;gcc:&lt;variant&gt;release         &lt;variant&gt;release:&lt;define&gt;FOO ;             Target Paths Several factors determine the location of a concrete       file target.  All files in a project are built under       the directory bin unless this is overriden by the build-dir project       attribute.  Under bin is a path that depends on the properties       used to build each target.  This path is uniquely determined by       all non-free, non-incidental properties.  For example,       given a property set containing:       &lt;toolset&gt;gcc &lt;toolset-gcc:version&gt;4.6.1 &lt;variant&gt;debug       &lt;warnings&gt;all &lt;define&gt;_DEBUG &lt;include&gt;/usr/local/include       &lt;link&gt;static,       the path will be gcc-4.6.1/debug/link-static.  &lt;warnings&gt; is an       incidental feature and &lt;define&gt; and &lt;include&gt; are       free features, so they do not affect the path. Sometimes the paths produced by Boost.Build can become excessively       long.  There are a couple of command line options that can help with this.       --abbreviate-paths reduces each element to no more than five characters.       For example, link-static becomes lnk-sttc.  The --hash option reduces the       path to a single directory using an MD5 hash. There are two features that affect the build       directory.  The &lt;location&gt; feature completely       overrides the default build directory.  For example,        exe a : a.cpp : &lt;location&gt;. ;        builds all the files produced by a       in the directory of the Jamfile.  This is generally       discouraged, as it precludes variant builds. The &lt;location-prefix&gt; feature adds a       prefix to the path, under the project's build       directory.  For example,        exe a : a.cpp : &lt;location-prefix&gt;subdir ;        will create the files for a in bin/subdir/gcc-4.6.1/debug     Definitions  Features and properties Property refinement Conditional properties Target identifiers and references    Features and properties  Property Validity Feature Attributes Feature Declaration  A feature is a normalized (toolset-independent)         aspect of a build configuration, such as whether inlining is         enabled. Feature names may not contain the '&gt;'         character. Each feature in a build configuration has one or more         associated values. Feature values for non-free features         may not contain the '&lt;', ':', or         '=' characters. Feature values for free features may not         contain the '&lt;' character. A property is a (feature,value) pair, expressed as         &lt;feature&gt;value. A subfeature is a feature that only exists in the         presence of its parent feature, and whose identity can be derived         (in the context of its parent) from its value. A subfeature's         parent can never be another subfeature. Thus, features and their         subfeatures form a two-level hierarchy. A value-string for a feature F is a string of         the form         value-subvalue1-subvalue2...-subvalueN, where         value is a legal value for F and         subvalue1...subvalueN are legal values of some         of F's subfeatures. For example, the properties         &lt;toolset&gt;gcc &lt;toolset-version&gt;3.0.1 can be         expressed more conscisely using a value-string, as         &lt;toolset&gt;gcc-3.0.1. A property set is a set of properties (i.e. a         collection without duplicates), for instance:         &lt;toolset&gt;gcc &lt;runtime-link&gt;static. A property path is a property set whose elements have         been joined into a single string separated by slashes. A property         path representation of the previous example would be         &lt;toolset&gt;gcc/&lt;runtime-link&gt;static. A build specification is a property set that fully         describes the set of features used to build a target.   Property Validity            For free             features, all values are valid. For all other features,           the valid values are explicitly specified, and the build           system will report an error for the use of an invalid           feature-value. Subproperty validity may be restricted so           that certain values are valid only in the presence of           certain other subproperties. For example, it is possible           to specify that the &lt;gcc-target&gt;mingw           property is only valid in the presence of           &lt;gcc-version&gt;2.95.2.             Feature Attributes Each feature has a collection of zero or more of the following           attributes. Feature attributes are low-level descriptions of how the           build system should interpret a feature's values when they appear in           a build request. We also refer to the attributes of properties, so           that an incidental property, for example, is           one whose feature has the incidental           attribute.   incidental Incidental features are assumed not to affect build               products at all. As a consequence, the build system may use               the same file for targets whose build specification differs               only in incidental features. A feature that controls a               compiler's warning level is one example of a likely               incidental feature. Non-incidental features are assumed to affect build               products, so the files for targets whose build specification               differs in non-incidental features are placed in different               directories as described in the section called &#8220;Target Paths&#8221;.                                              propagated              Features of this kind are               propagated to dependencies. That is, if a main target is built using a               propagated               property, the build systems attempts to use the same property               when building any of its dependencies as part of that main               target. For instance, when an optimized exectuable is               requested, one usually wants it to be linked with optimized               libraries. Thus, the &lt;optimization&gt; feature is               propagated.                                 free              Most features have a finite set of allowed values, and can               only take on a single value from that set in a given build               specification. Free features, on the other hand, can have               several values at a time and each value can be an arbitrary               string. For example, it is possible to have several               preprocessor symbols defined simultaneously:  &lt;define&gt;NDEBUG=1 &lt;define&gt;HAS_CONFIG_H=1    optional An optional feature is a feature that is not required to               appear in a build specification. Every non-optional non-free               feature has a default value that is used when a value for               the feature is not otherwise specified, either in a target's               requirements or in the user's build request. [A feature's               default value is given by the first value listed in the               feature's declaration. -- move this elsewhere - dwa]   symmetric Normally a feature only generates a subvariant directory               when its value differs from its default value,               leading to an assymmetric subvariant directory structure for               certain values of the feature. A symmetric feature               always generates a corresponding               subvariant directory.   path The value of a path feature specifies a path. The path is               treated as relative to the directory of Jamfile where path               feature is used and is translated appropriately by the build               system when the build is invoked from a different               directory   implicit Values of implicit features alone identify the feature.               For example, a user is not required to write               "&lt;toolset&gt;gcc", but can simply write "gcc". Implicit               feature names also don't appear in variant paths, although               the values do. Thus: bin/gcc/... as opposed to               bin/toolset-gcc/.... There should typically be only a few               such features, to avoid possible name clashes.   composite Composite features actually correspond to groups of               properties. For example, a build variant is a composite               feature. When generating targets from a set of build               properties, composite features are recursively expanded and               added to the build property set, so rules can find               them if necessary. Non-composite non-free features override               components of composite features in a build property set.   dependency The value of a dependency feature is a target reference.               When used for building of a main target, the value of               dependency feature is treated as additional dependency. For example, dependency features allow to state that               library A depends on library B. As the result, whenever an               application will link to A, it will also link to B.               Specifying B as dependency of A is different from adding B to               the sources of A.    Features that are neither free nor incidental are called           base features.    Feature Declaration The low-level feature declaration interface is the           feature rule from the           feature module:    rule feature ( name : allowed-values * : attributes * )              A feature's allowed-values may be extended with the           feature.extend rule.              Property refinement When a target with certain properties is requested, and that         target requires some set of properties, it is needed to find the         set of properties to use for building. This process is called         property refinement and is performed by these rules               Each property in the required set is added to the original             property set                         If the original property set includes property with a different             value of non free feature, that property is removed.                Conditional properties Sometime it's desirable to apply certain requirements only for         a specific combination of other properties. For example, one of         compilers that you use issues a pointless warning that you want to         suppress by passing a command line option to it. You would not         want to pass that option to other compilers. Conditional         properties allow you to do just that. Their syntax is:          property ( "," property ) * ":" property                 For example, the problem above would be solved by:    exe hello : hello.cpp : &lt;toolset&gt;yfc:&lt;cxxflags&gt;-disable-pointless-warning ;          The syntax also allows several properties in the condition, for         example:   exe hello : hello.cpp : &lt;os&gt;NT,&lt;toolset&gt;gcc:&lt;link&gt;static ;             Target identifiers and references Target identifier is used to denote a         target. The syntax is:  target-id -&gt; (project-id | target-name | file-name )               | (project-id | directory-name) "//" target-name project-id -&gt; path target-name -&gt; path file-name -&gt; path directory-name -&gt; path           This grammar allows some elements to be recognized as either                           project id (at this point, all project ids start with slash).                             name of target declared in current Jamfile (note that target               names may include slash).                             a regular file, denoted by absolute name or name relative to               project's sources location.                         To determine the real meaning a check is made if project-id         by the specified name exists, and then if main target of that         name exists. For example, valid target ids might be:    a                                    -- target in current project lib/b.cpp                            -- regular file /boost/thread                        -- project "/boost/thread" /home/ghost/build/lr_library//parser -- target in specific project           Rationale:Target is separated from project by special         separator (not just slash), because:               It emphasises that projects and targets are different things.                         It allows to have main target names with slashes.                                    Target reference is used to         specify a source target, and may additionally specify desired         properties for that target. It has this syntax:  target-reference -&gt; target-id [ "/" requested-properties ] requested-properties -&gt; property-path           For example,                      exe compiler : compiler.cpp libs/cmdline/&lt;optimization&gt;space ;                    would cause the version of cmdline library,         optimized for space, to be linked in even if the         compiler executable is build with optimization for         speed.             Copyright &#169; 2006-2009 Vladimir PrusDistributed under the Boost Software License, Version 1.0.       (See accompanying file LICENSE_1_0.txt or copy at        http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3145weight: 4
tittle: Tutorial
url :https://www.boost.org/doc/libs/1_53_0/doc/html/bbv2/tutorial.html
content:    Tutorial           Home Libraries People FAQ More        Tutorial  Hello, world Properties Project Hierarchies Dependent Targets Static and shared libaries Conditions and alternatives Prebuilt targets       This section will guide you though the most basic features of Boost.Build     V2. We will start with the &#8220;Hello, world&#8221; example, learn how     to use libraries, and finish with testing and installing features.      Hello, world        The simplest project that Boost.Build can construct is stored in       example/hello/ directory. The project is described by       a file called Jamroot that contains:    exe hello : hello.cpp ;          Even with this simple setup, you can do some interesting things. First of       all, just invoking b2 will build the hello        executable by compiling and linking hello.cpp       . By default, the debug variant is built. Now, to build the release       variant of hello, invoke    b2 release          Note that the debug and release variants are created in different directories,       so you can switch between variants or even build multiple variants at       once, without any unnecessary recompilation. Let us extend the example by       adding another line to our project's Jamroot:    exe hello2 : hello.cpp ;          Now let us build both the debug and release variants of our project again:    b2 debug release          Note that two variants of hello2 are linked. Since we       have already built both variants of hello, hello.cpp       will not be recompiled; instead the existing object files will just be       linked into the corresponding variants of hello2. Now       let us remove all the built products:    b2 --clean debug release          It is also possible to build or clean specific targets. The following two       commands, respectively, build or clean only the debug version of       hello2.    b2 hello2 b2 --clean hello2           Properties  Build Requests and Target Requirements Project Attributes         To represent aspects of target configuration such as       debug and release variants, or single- and multi-threaded       builds portably, Boost.Build uses features with       associated values.  For       example, the debug-symbols feature can have a value of on or       off.  A property is just a (feature,       value) pair.  When a user initiates a build, Boost.Build       automatically translates the requested properties into appropriate       command-line flags for invoking toolset components like compilers       and linkers.             There are many built-in features that can be combined to       produce arbitrary build configurations.  The following command       builds the project's release variant with inlining       disabled and debug symbols enabled:   b2 release inlining=off debug-symbols=on               Properties on the command-line are specified with the syntax:    feature-name=feature-value               The release and debug that we have seen       in b2 invocations are just a shorthand way to specify       values of the variant feature.  For example, the       command above could also have been written this way:          b2 variant=release inlining=off debug-symbols=on                     variant is so commonly-used that it has been given       special status as an implicit feature&#8212;       Boost.Build will deduce its identity just from the name of one of its       values.             A complete description of features can be found in the section called &#8220;Features and properties&#8221;.        Build Requests and Target Requirements          The set of properties specified on the command line constitutes         a build request&#8212;a description of         the desired properties for building the requested targets (or,         if no targets were explicitly requested, the project in the         current directory). The actual         properties used for building targets are typically a         combination of the build request and properties derived from         the project's Jamroot (and its other         Jamfiles, as described in the section called &#8220;Project Hierarchies&#8221;). For example, the         locations of #included header files are normally         not specified on the command-line, but described in         Jamfiles as target         requirements and automatically combined with the         build request for those targets. Multithread-enabled         compilation is another example of a typical target         requirement. The Jamfile fragment below         illustrates how these requirements might be specified.         exe hello     : hello.cpp     : &lt;include&gt;boost &lt;threading&gt;multi     ;           When hello is built, the two requirements specified         above will always be present. If the build request given on the         b2 command-line explictly contradicts a target's         requirements, the target requirements usually override (or, in the case         of &#8220;free&#8221;&#8221; features like         &lt;include&gt;,         [13]         augments) the build request.           Tip             The value of the &lt;include&gt; feature is           relative to the location of Jamroot where it is           used.              Project Attributes          If we want the same requirements for our other target,         hello2, we could simply duplicate them. However,         as projects grow, that approach leads to a great deal of repeated         boilerplate in Jamfiles.          Fortunately, there's a better way. Each project can specify a set of         attributes, including requirements:    project     : requirements &lt;include&gt;/home/ghost/Work/boost &lt;threading&gt;multi     ;  exe hello : hello.cpp ; exe hello2 : hello.cpp ;           The effect would be as if we specified the same requirement for both         hello and hello2.            Project Hierarchies        So far we have only considered examples with one project, with       one user-written Boost.Jam file, Jamroot. A typical       large codebase would be composed of many projects organized into a tree.       The top of the tree is called the project root.       Every subproject is defined by a file called Jamfile       in a descendant directory of the project root. The parent project of a       subproject is defined by the nearest Jamfile or       Jamroot file in an ancestor directory. For example,       in the following directory layout:    top/   |   +-- Jamroot   |   +-- app/   |    |   |    +-- Jamfile   |    `-- app.cpp   |   `-- util/        |        +-- foo/        .    |        .    +-- Jamfile        .    `-- bar.cpp          the project root is top/. The projects in       top/app/ and top/util/foo/ are       immediate children of the root project.            Note             When we refer to a &#8220;Jamfile,&#8221; set in normal           type, we mean a file called either           Jamfile or           Jamroot.  When we need to be more           specific, the filename will be set as           &#8220;Jamfile&#8221; or           &#8220;Jamroot.&#8221;                        Projects inherit all attributes (such as requirements)       from their parents.  Inherited requirements are combined with       any requirements specified by the subproject.       For example, if top/Jamroot has    &lt;include&gt;/home/ghost/local          in its requirements, then all of its subprojects will have it       in their requirements, too.  Of course, any project can add       include paths to those specified by its parents. [14]     More details can be found in       the section called &#8220;Projects&#8221;.             Invoking b2 without explicitly specifying       any targets on the command line builds the project rooted in the       current directory.  Building a project does not automatically       cause its subprojects to be built unless the parent project's       Jamfile explicitly requests it. In our example,       top/Jamroot might contain:    build-project app ;          which would cause the project in top/app/       to be built whenever the project in top/ is       built. However, targets in top/util/foo/       will be built only if they are needed by targets in       top/ or top/app/.         Dependent Targets        When building a target X that depends on first       building another target Y (such as a       library that must be linked with X),       Y is called a       dependency of X and       X is termed a       dependent of Y.      To get a feeling of target dependencies, let's continue the       above example and see how top/app/Jamfile can       use libraries from top/util/foo.  If       top/util/foo/Jamfile contains    lib bar : bar.cpp ;          then to use this library in top/app/Jamfile, we can       write:    exe app : app.cpp ../util/foo//bar ;          While app.cpp refers to a regular source file,       ../util/foo//bar is a reference to another target:       a library bar declared in the Jamfile at       ../util/foo.         Tip  Some other build system have special syntax for listing dependent       libraries, for example LIBS variable. In Boost.Build,       you just add the library to the list of sources.         Suppose we build app with:       b2 app optimization=full define=USE_ASM           Which properties will be used to build foo? The answer is     that some features are     propagated&#8212;Boost.Build attempts to use     dependencies with the same value of propagated features. The     &lt;optimization&gt; feature is propagated, so both     app and foo will be compiled     with full optimization. But &lt;define&gt; is not     propagated: its value will be added as-is to the compiler flags for     a.cpp, but won't affect foo.             Let's improve this project further. The library probably has some headers       that must be used when compiling app.cpp. We could       manually add the necessary #include paths to       app's requirements as values of the       &lt;include&gt;   feature, but then this work will be       repeated for all programs that use foo. A better       solution is to modify util/foo/Jamfile in this way:          project     : usage-requirements &lt;include&gt;.     ;  lib foo : foo.cpp ;         Usage requirements are applied not to the target being declared but to its       dependants. In this case, &lt;include&gt;. will be       applied to all targets that directly depend on foo.             Another improvement is using symbolic identifiers to refer to the library,       as opposed to Jamfile location. In a large project, a       library can be used by many targets, and if they all use Jamfile        location, a change in directory organization entails much       work. The solution is to use project ids&#8212;symbolic names not tied to       directory layout. First, we need to assign a project id by adding this       code to Jamroot:       use-project /library-example/foo : util/foo ;        Second, we modify app/Jamfile to use the project id:         exe app : app.cpp /library-example/foo//bar ;         The /library-example/foo//bar syntax is used to refer       to the target bar in the project with id        /library-example/foo. We've achieved our goal&#8212;if the       library is moved to a different directory, only Jamroot        must be modified. Note that project ids are global&#8212;two       Jamfiles are not allowed to assign the same project id to different       directories.         Tip   If you want all applications in some project to link to a certain         library, you can avoid having to specify it directly the sources of         every target by using the &lt;library&gt; property.         For example, if /boost/filesystem//fs should be         linked to all applications in your project, you can add         &lt;library&gt;/boost/filesystem//fs to the project's         requirements, like this:         project    : requirements &lt;library&gt;/boost/filesystem//fs    ;      Static and shared libaries        Libraries can be either static, which means they are       included in executable files that use them, or shared       (a.k.a. dynamic), which are only referred to from       executables, and must be available at run time. Boost.Build can create and       use both kinds.             The kind of library produced from a lib target is determined       by the value of the link feature. Default value is       shared, and to build a static library, the value should       be static. You can request a static build either on the       command line:        b2 link=static        or in the library's requirements:        lib l : l.cpp : &lt;link&gt;static ;              We can also use the &lt;link&gt; property to express       linking requirements on a per-target basis. For example, if a particular       executable can be correctly built only with the static version of a       library, we can qualify the executable's target reference to the       library as follows:            exe important : main.cpp helpers/&lt;link&gt;static ;         No matter what arguments are specified on the b2       command line, important will only be linked with the       static version of helpers.             Specifying properties in target references is especially useful if you use       a library defined in some other project (one you can't change) but you       still want static (or dynamic) linking to that library in all cases. If       that library is used by many targets, you could use       target references everywhere:          exe e1 : e1.cpp /other_project//bar/&lt;link&gt;static ; exe e10 : e10.cpp /other_project//bar/&lt;link&gt;static ;         but that's far from being convenient. A better approach is to introduce a       level of indirection. Create a local alias target that refers       to the static (or dynamic) version of foo:          alias foo : /other_project//bar/&lt;link&gt;static ; exe e1 : e1.cpp foo ; exe e10 : e10.cpp foo ;         The alias rule is specifically       used to rename a reference to a target and possibly change the       properties.                 Tip            When one library uses another, you put the second library in the source         list of the first. For example:           lib utils : utils.cpp /boost/filesystem//fs ; lib core : core.cpp utils ; exe app : app.cpp core ;          This works no matter what kind of linking is used. When core          is built as a shared library, it is linked directly into         utils. Static libraries can't link to other         libraries, so when core is built as a static         library, its dependency on utils is passed along to         core's dependents, causing app         to be linked with both core and utils         .             Note           (Note for non-UNIX system). Typically, shared libraries must be         installed to a directory in the dynamic linker's search path. Otherwise,         applications that use shared libraries can't be started. On Windows, the         dynamic linker's search path is given by the PATH         environment variable. This restriction is lifted when you use         Boost.Build testing facilities&#8212;the PATH variable         will be automatically adjusted before running the executable.                     Conditions and alternatives        Sometimes, particular relationships need to be maintained among a target's       build properties. For example, you might want to set specific        #define when a library is built as shared, or when a target's       release variant is built. This can be achieved using       conditional requirements.          lib network : network.cpp     : &lt;link&gt;shared:&lt;define&gt;NEWORK_LIB_SHARED      &lt;variant&gt;release:&lt;define&gt;EXTRA_FAST     ;         In the example above, whenever network is built with       &lt;link&gt;shared, &lt;define&gt;NEWORK_LIB_SHARED        will be in its properties, too. Also, whenever its release variant       is built, &lt;define&gt;EXTRA_FAST will appear in its       properties.             Sometimes the ways a target is built are so different that describing them       using conditional requirements would be hard. For example, imagine that a       library actually uses different source files depending on the toolset used       to build it. We can express this situation using target       alternatives:         lib demangler : dummy_demangler.cpp ;                      # alternative 1 lib demangler : demangler_gcc.cpp : &lt;toolset&gt;gcc ;   # alternative 2 lib demangler : demangler_msvc.cpp : &lt;toolset&gt;msvc ; # alternative 3        When building demangler, Boost.Build will compare       requirements for each alternative with build properties to find the best       match. For example, when building with &lt;toolset&gt;gcc       alternative 2, will be selected, and when building with       &lt;toolset&gt;msvc alternative 3 will be selected. In all       other cases, the most generic alternative 1 will be built.         Prebuilt targets        To link to libraries whose build instructions aren't given in a Jamfile,       you need to create lib targets with an appropriate       file property.  Target alternatives can be used to       associate multiple library files with a single conceptual target. For       example:         # util/lib2/Jamfile lib lib2     :     : &lt;file&gt;lib2_release.a &lt;variant&gt;release     ;  lib lib2     :     : &lt;file&gt;lib2_debug.a &lt;variant&gt;debug     ;         This example defines two alternatives for lib2, and       for each one names a prebuilt file.  Naturally, there are no sources.       Instead, the &lt;file&gt; feature is used to specify       the file name.             Once a prebuilt target has been declared, it can be used just like any       other target:          exe app : app.cpp ../util/lib2//lib2 ;         As with any target, the alternative selected depends on the properties       propagated from lib2's dependants. If we build the       release and debug versions of app will be linked       with lib2_release.a and lib2_debug.a       , respectively.             System libraries&#8212;those that are automatically found by the toolset       by searching through some set of predetermined paths&#8212;should be       declared almost like regular ones:          lib pythonlib : : &lt;name&gt;python22 ;         We again don't specify any sources, but give a name       that should be passed to the compiler. If the gcc toolset were used to       link an executable target to pythonlib,       -lpython22 would appear in the command line (other       compilers may use different options).             We can also specify where the toolset should look for the library:          lib pythonlib : : &lt;name&gt;python22 &lt;search&gt;/opt/lib ;         And, of course, target alternatives can be used in the usual way:          lib pythonlib : : &lt;name&gt;python22 &lt;variant&gt;release ; lib pythonlib : : &lt;name&gt;python22_d &lt;variant&gt;debug ;              A more advanced use of prebuilt targets is described in the section called &#8220;Targets in site-config.jam&#8221;.         [13]               See the section called &#8220;Feature Attributes&#8221;            [14] Many       features will be overridden,       rather than added-to, in subprojects.  See the section called &#8220;Feature Attributes&#8221; for more       information     Copyright &#169; 2006-2009 Vladimir PrusDistributed under the Boost Software License, Version 1.0.       (See accompanying file LICENSE_1_0.txt or copy at        http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3211weight: 12
tittle: Some basic explanations
url :https://www.boost.org/doc/libs/1_53_0/doc/html/interprocess/some_basic_explanations.html
content:    Some basic explanations           Home Libraries People FAQ More        Some basic explanations   Processes       And Threads Sharing       information between processes Persistence       Of Interprocess Mechanisms Names Of       Interprocess Mechanisms Constructors,       destructors and lifetime of Interprocess named resources Permissions    Processes       And Threads           Boost.Interprocess does not work only with         processes but also with threads. Boost.Interprocess         synchronization mechanisms can synchronize threads from different processes,         but also threads from the same process.           Sharing       information between processes           In the traditional programming model an operating system has multiple processes         running and each process has its own address space. To share information         between processes we have several alternatives:                      Two processes share information using a file.             To access to the data, each process uses the usual file read/write mechanisms.             When updating/reading a file shared between processes, we need some sort             of synchronization, to protect readers from writers.                         Two processes share information that resides in the kernel             of the operating system. This is the case, for example, of traditional             message queues. The synchronization is guaranteed by the operating system             kernel.                         Two processes can share a memory region.             This is the case of classical shared memory or memory mapped files. Once             the processes set up the memory region, the processes can read/write             the data like any other memory segment without calling the operating             system's kernel. This also requires some kind of manual synchronization             between processes.                Persistence       Of Interprocess Mechanisms           One of the biggest issues with interprocess communication mechanisms is the         lifetime of the interprocess communication mechanism. It's important to know         when an interprocess communication mechanism disappears from the system.         In Boost.Interprocess, we can have 3 types         of persistence:                      Process-persistence: The mechanism lasts             until all the processes that have opened the mechanism close it, exit             or crash.                         Kernel-persistence: The mechanism exists             until the kernel of the operating system reboots or the mechanism is             explicitly deleted.                         Filesystem-persistence: The mechanism             exists until the mechanism is explicitly deleted.                      Some native POSIX and Windows IPC mechanisms have different persistence so         it's difficult to achieve portability between Windows and POSIX native mechanisms.         Boost.Interprocess classes have the following         persistence:         Table&#160;13.1.&#160;Boost.Interprocess Persistence Table                                           Mechanism                                                                     Persistence                                                                        Shared memory                                                                     Kernel or Filesystem                                                                       Memory mapped file                                                                     Filesystem                                                                       Process-shared mutex types                                                                     Process                                                                       Process-shared semaphore                                                                     Process                                                                       Process-shared condition                                                                     Process                                                                       File lock                                                                     Process                                                                       Message queue                                                                     Kernel or Filesystem                                                                       Named mutex                                                                     Kernel or Filesystem                                                                       Named semaphore                                                                     Kernel or Filesystem                                                                       Named condition                                                                     Kernel or Filesystem                                              As you can see, Boost.Interprocess defines         some mechanisms with "Kernel or Filesystem" persistence. This is         because POSIX allows this possibility to native interprocess communication         implementations. One could, for example, implement shared memory using memory         mapped files and obtain filesystem persistence (for example, there is no         proper known way to emulate kernel persistence with a user library for Windows         shared memory using native shared memory, or process persistence for POSIX         shared memory, so the only portable way is to define "Kernel or Filesystem"         persistence).           Names Of       Interprocess Mechanisms           Some interprocess mechanisms are anonymous objects created in shared memory         or memory-mapped files but other interprocess mechanisms need a name or identifier         so that two unrelated processes can use the same interprocess mechanism object.         Examples of this are shared memory, named mutexes and named semaphores (for         example, native windows CreateMutex/CreateSemaphore API family).                 The name used to identify an interprocess mechanism is not portable, even         between UNIX systems. For this reason, Boost.Interprocess         limits this name to a C++ variable identifier or keyword:                      Starts with a letter, lowercase or uppercase, such as a letter from a             to z or from A to Z. Examples: Sharedmemory, sharedmemory,             sHaReDmEmOrY...                         Can include letters, underscore, or digits. Examples: shm1,             shm2and3, ShM3plus4...                Constructors,       destructors and lifetime of Interprocess named resources           Named Boost.Interprocess resources (shared         memory, memory mapped files, named mutexes/conditions/semaphores) have kernel         or filesystem persistency. This means that even if all processes that have         opened those resources end, the resource will still be accessible to be opened         again and the resource can only be destructed via an explicit to their static         member remove function. This         behavior can be easily understood, since it's the same mechanism used by         functions controlling file opening/creation/erasure:         Table&#160;13.2.&#160;Boost.Interprocess-Filesystem Analogy                                            Named Interprocess resource                                                                     Corresponding std file                                                                     Corresponding POSIX operation                                                                        Constructor                                                                     std::fstream constructor                                                                     open                                                                       Destructor                                                                     std::fstream destructor                                                                     close                                                                       Member remove                                                                     None. std::remove                                                                     unlink                                              Now the correspondence between POSIX and Boost.Interprocess regarding shared         memory and named semaphores:         Table&#160;13.3.&#160;Boost.Interprocess-POSIX shared memory                                           shared_memory_object                   operation                                                                     POSIX operation                                                                        Constructor                                                                     shm_open                                                                       Destructor                                                                     close                                                                       Member remove                                                                     shm_unlink                                      Table&#160;13.4.&#160;Boost.Interprocess-POSIX named semaphore                                           named_semaphore                   operation                                                                     POSIX operation                                                                        Constructor                                                                     sem_open                                                                       Destructor                                                                     close                                                                       Member remove                                                                     sem_unlink                                              The most important property is that destructors of         named resources don't remove the resource from the system, they         only liberate resources allocated by the system for use by the process for         the named resource. To remove the resource from the         system the programmer must use remove.           Permissions           Named resources offered by Boost.Interprocess         must cope with platform-dependant permission issues also present when creating         files. If a programmer wants to shared shared memory, memory mapped files         or named synchronization mechanisms (mutexes, semaphores, etc...) between         users, it's necessary to specify those permissions. Sadly, traditional UNIX         and Windows permissions are very different and Boost.Interprocess         does not try to standardize permissions, but does not ignore them.                 All named resource creation functions take an optional permissions         object that can be configured with platform-dependant permissions.                 Since each mechanism can be emulated through diferent mechanisms (a semaphore         might be implement using mapped files or native semaphores) permissions types         could vary when the implementation of a named resource changes (eg.: in Windows         mutexes require synchronize permissions, but that's not the case of         files). To avoid this, Boost.Interprocess         relies on file-like permissions, requiring file read-write-delete permissions         to open named synchronization mechanisms (mutex, semaphores, etc.) and appropiate         read or read-write-delete permissions for shared memory. This approach has         two advantages: it's similar to the UNIX philosophy and the programmer does         not need to know how the named resource is implemented.            Copyright &#169; 2005-2012 Ion Gaztanaga         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3212weight: 6
tittle: Sharing memory between processes
url :https://www.boost.org/doc/libs/1_53_0/doc/html/interprocess/sharedmemorybetweenprocesses.html
content:    Sharing memory between processes           Home Libraries People FAQ More        Sharing memory     between processes   Shared       memory Memory       Mapped Files More       About Mapped Regions Limitations       When Constructing Objects In Mapped Regions    Shared       memory   What         is shared memory? Creating         memory segments that can be shared between processes Header Creating         shared memory segments Mapping         Shared Memory Segments A         Simple Example Emulation         for systems without shared memory objects Removing         shared memory Anonymous         shared memory for UNIX systems Native         windows shared memory XSI         shared memory    What         is shared memory?             Shared memory is the fastest interprocess communication mechanism. The           operating system maps a memory segment in the address space of several           processes, so that several processes can read and write in that memory           segment without calling operating system functions. However, we need some           kind of synchronization between processes that read and write shared memory.                     Consider what happens when a server process wants to send an HTML file           to a client process that resides in the same machine using network mechanisms:                          The server must read the file to memory and pass it to the network               functions, that copy that memory to the OS's internal memory.                             The client uses the network functions to copy the data from the OS's               internal memory to its own memory.                          As we can see, there are two copies, one from memory to the network and           another one from the network to memory. And those copies are made using           operating system calls that normally are expensive. Shared memory avoids           this overhead, but we need to synchronize both processes:                          The server maps a shared memory in its address space and also gets               access to a synchronization mechanism. The server obtains exclusive               access to the memory using the synchronization mechanism and copies               the file to memory.                             The client maps the shared memory in its address space. Waits until               the server releases the exclusive access and uses the data.                          Using shared memory, we can avoid two data copies, but we have to synchronize           the access to the shared memory segment.             Creating         memory segments that can be shared between processes             To use shared memory, we have to perform 2 basic steps:                          Request to the operating system a memory segment that can be shared               between processes. The user can create/destroy/open this memory using               a shared memory object: An               object that represents memory that can be mapped concurrently into               the address space of more than one process..                             Associate a part of that memory or the whole memory with the address               space of the calling process. The operating system looks for a big               enough memory address range in the calling process' address space and               marks that address range as an special range. Changes in that address               range are automatically seen by other process that also have mapped               the same shared memory object.                          Once the two steps have been successfully completed, the process can start           writing to and reading from the address space to send to and receive data           from other processes. Now, let's see how can we do this using Boost.Interprocess:             Header             To manage shared memory, you just need to include the following header:          #include &lt;boost/interprocess/shared_memory_object.hpp&gt;     Creating         shared memory segments             As we've mentioned we have to use the shared_memory_object           class to create, open and destroy shared memory segments that can be mapped           by several processes. We can specify the access mode of that shared memory           object (read only or read-write), just as if it was a file:                         Create a shared memory segment. Throws if already created:              using boost::interprocess; shared_memory_object shm_obj    (create_only                  //only create    ,"shared_memory"              //name    ,read_write                   //read-write mode    );                 To open or create a shared memory segment:              using boost::interprocess; shared_memory_object shm_obj    (open_or_create               //open or create    ,"shared_memory"              //name    ,read_only                    //read-only mode    );                 To only open a shared memory segment. Throws if does not exist:              using boost::interprocess; shared_memory_object shm_obj    (open_only                    //only open    ,"shared_memory"              //name    ,read_write                   //read-write mode    );             When a shared memory object is created, its size is 0. To set the size           of the shared memory, the user must use the truncate           function call, in a shared memory that has been opened with read-write           attributes:          shm_obj.truncate(10000);             As shared memory has kernel or filesystem persistence, the user must explicitly           destroy it. The remove           operation might fail returning false if the shared memory does not exist,           the file is open or the file is still memory mapped by other processes:          using boost::interprocess; shared_memory_object::remove("shared_memory");             For more details regarding shared_memory_object           see the boost::interprocess::shared_memory_object           class reference.             Mapping         Shared Memory Segments             Once created or opened, a process just has to map the shared memory object           in the process' address space. The user can map the whole shared memory           or just part of it. The mapping process is done using the mapped_region class. The class represents           a memory region that has been mapped from a shared memory or from other           devices that have also mapping capabilities (for example, files). A mapped_region can be created from any           memory_mappable object           and as you might imagine, shared_memory_object           is a memory_mappable object:          using boost::interprocess; std::size_t ShmSize = ...  //Map the second half of the memory mapped_region region    ( shm                      //Memory-mappable object    , read_write               //Access mode    , ShmSize/2                //Offset from the beginning of shm    , ShmSize-ShmSize/2        //Length of the region    );  //Get the address of the region region.get_address();  //Get the size of the region region.get_size();             The user can specify the offset from the mappable object where the mapped           region should start and the size of the mapped region. If no offset or           size is specified, the whole mappable object (in this case, shared memory)           is mapped. If the offset is specified, but not the size, the mapped region           covers from the offset until the end of the mappable object.                     For more details regarding mapped_region           see the boost::interprocess::mapped_region           class reference.             A         Simple Example             Let's see a simple example of shared memory use. A server process creates           a shared memory object, maps it and initializes all the bytes to a value.           After that, a client process opens the shared memory, maps it, and checks           that the data is correctly initialized:            #include &lt;boost/interprocess/shared_memory_object.hpp&gt; #include &lt;boost/interprocess/mapped_region.hpp&gt; #include &lt;cstring&gt; #include &lt;cstdlib&gt; #include &lt;string&gt;  int main(int argc, char *argv[]) {    using namespace boost::interprocess;     if(argc == 1){  //Parent process       //Remove shared memory on construction and destruction       struct shm_remove       {          shm_remove() { shared_memory_object::remove("MySharedMemory"); }          ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }       } remover;        //Create a shared memory object.       shared_memory_object shm (create_only, "MySharedMemory", read_write);        //Set size       shm.truncate(1000);        //Map the whole shared memory in this process       mapped_region region(shm, read_write);        //Write all the memory to 1       std::memset(region.get_address(), 1, region.get_size());        //Launch child process       std::string s(argv[0]); s += " child ";       if(0 != std::system(s.c_str()))          return 1;    }    else{       //Open already created shared memory object.       shared_memory_object shm (open_only, "MySharedMemory", read_only);        //Map the whole shared memory in this process       mapped_region region(shm, read_only);        //Check that memory was initialized to 1       char *mem = static_cast&lt;char*&gt;(region.get_address());       for(std::size_t i = 0; i &lt; region.get_size(); ++i)          if(*mem++ != 1)             return 1;   //Error checking memory    }    return 0; }               Emulation         for systems without shared memory objects             Boost.Interprocess provides portable shared           memory in terms of POSIX semantics. Some operating systems don't support           shared memory as defined by POSIX:                          Windows operating systems provide shared memory using memory backed               by the paging file but the lifetime semantics are different from the               ones defined by POSIX (see Native               windows shared memory section for more information).                             Some UNIX systems don't fully support POSIX shared memory objects at               all.                          In those platforms, shared memory is emulated with mapped files created           in a "boost_interprocess" folder created in a temporary files           directory. In Windows platforms, if "Common AppData" key is present           in the registry, "boost_interprocess" folder is created in that           directory (in XP usually "C:\Documents and Settings\All Users\Application           Data" and in Vista "C:\ProgramData"). For Windows platforms           without that registry key and Unix systems, shared memory is created in           the system temporary files directory ("/tmp" or similar).                     Because of this emulation, shared memory has filesystem lifetime in some           of those systems.             Removing         shared memory             shared_memory_object           provides a static remove           function to remove a shared memory objects.                     This function can fail if the shared memory           objects does not exist or it's opened by another process. Note that this           function is similar to the standard C int           remove(const char *path) function. In UNIX systems, shared_memory_object::remove calls shm_unlink:                          The function will remove the name of the shared memory object named               by the string pointed to by name.                             If one or more references to the shared memory object exist when is               unlinked, the name will be removed before the function returns, but               the removal of the memory object contents will be postponed until all               open and map references to the shared memory object have been removed.                             Even if the object continues to exist after the last function call,               reuse of the name will subsequently cause the creation of a boost::interprocess::shared_memory_object               instance to behave as if no shared memory object of this name exists               (that is, trying to open an object with that name will fail and an               object of the same name can be created again).                          In Windows operating systems, current version supports an usually acceptable           emulation of the UNIX unlink behaviour: the file is renamed with a random           name and marked as to be deleted when the last open handle is           closed.             Anonymous         shared memory for UNIX systems             Creating a shared memory segment and mapping it can be a bit tedious when           several processes are involved. When processes are related via fork()           operating system call in UNIX systems a simpler method is available using           anonymous shared memory.                     This feature has been implemented in UNIX systems mapping the device \dev\zero           or just using the MAP_ANONYMOUS           in a POSIX conformant mmap           system call.                     This feature is wrapped in Boost.Interprocess           using the anonymous_shared_memory() function, which returns a mapped_region object holding an anonymous           shared memory segment that can be shared by related processes.                     Here is an example:            #include &lt;boost/interprocess/anonymous_shared_memory.hpp&gt; #include &lt;boost/interprocess/mapped_region.hpp&gt; #include &lt;iostream&gt; #include &lt;cstring&gt;  int main () {    using namespace boost::interprocess;    try{       //Create an anonymous shared memory segment with size 1000       mapped_region region(anonymous_shared_memory(1000));        //Write all the memory to 1       std::memset(region.get_address(), 1, region.get_size());        //The segment is unmapped when "region" goes out of scope    }    catch(interprocess_exception &amp;ex){       std::cout &lt;&lt; ex.what() &lt;&lt; std::endl;       return 1;    }    return 0; }                       Once the segment is created, a fork() call can be used so that region is used to communicate two related           processes.             Native         windows shared memory             Windows operating system also offers shared memory, but the lifetime of           this shared memory is very different to kernel or filesystem lifetime.           The shared memory is created backed by the pagefile and it's automatically           destroyed when the last process attached to the shared memory is destroyed.                     Because of this reason, there is no effective way to simulate kernel or           filesystem persistence using native windows shared memory and Boost.Interprocess emulates shared memory using           memory mapped files. This assures portability between POSIX and Windows           operating systems.                     However, accessing native windows shared memory is a common request of           Boost.Interprocess users because they           want to access to shared memory created with other process that don't use           Boost.Interprocess. In order to manage           the native windows shared memory Boost.Interprocess           offers the windows_shared_memory           class.                     Windows shared memory creation is a bit different from portable shared           memory creation: the size of the segment must be specified when creating           the object and can't be specified through truncate           like with the shared memory object. Take in care that when the last process           attached to a shared memory is destroyed the shared           memory is destroyed so there is no persistency           with native windows shared memory.                     Sharing memory between services and user applications is also different.           To share memory between services and user applications the name of the           shared memory must start with the global namespace prefix "Global\\". This global namespace           enables processes on multiple client sessions to communicate with a service           application. The server component can create the shared memory in the global           namespace. Then a client session can use the "Global" prefix           to open that memory.                     The creation of a shared memory object in the global namespace from a session           other than session zero is a privileged operation.                     Let's repeat the same example presented for the portable shared memory           object: A server process creates a shared memory object, maps it and initializes           all the bytes to a value. After that, a client process opens the shared           memory, maps it, and checks that the data is correctly initialized. Take           in care that if the server exits before the client           connects to the shared memory the client connection will fail,           because the shared memory segment is destroyed when no proces is attached           to the memory.                     This is the server process:            #include &lt;boost/interprocess/windows_shared_memory.hpp&gt; #include &lt;boost/interprocess/mapped_region.hpp&gt; #include &lt;cstring&gt; #include &lt;cstdlib&gt; #include &lt;string&gt;  int main(int argc, char *argv[]) {    using namespace boost::interprocess;     if(argc == 1){  //Parent process       //Create a native windows shared memory object.       windows_shared_memory shm (create_only, "MySharedMemory", read_write, 1000);        //Map the whole shared memory in this process       mapped_region region(shm, read_write);        //Write all the memory to 1       std::memset(region.get_address(), 1, region.get_size());        //Launch child process       std::string s(argv[0]); s += " child ";       if(0 != std::system(s.c_str()))          return 1;       //windows_shared_memory is destroyed when the last attached process dies...    }    else{       //Open already created shared memory object.       windows_shared_memory shm (open_only, "MySharedMemory", read_only);        //Map the whole shared memory in this process       mapped_region region(shm, read_only);        //Check that memory was initialized to 1       char *mem = static_cast&lt;char*&gt;(region.get_address());       for(std::size_t i = 0; i &lt; region.get_size(); ++i)          if(*mem++ != 1)             return 1;   //Error checking memory       return 0;    }    return 0; }                       As we can see, native windows shared memory needs synchronization to make           sure that the shared memory won't be destroyed before the client is launched.             XSI         shared memory             In many UNIX systems, the OS offers another shared memory memory mechanism,           XSI (X/Open System Interfaces) shared memory segments, also known as "System           V" shared memory. This shared memory mechanism is quite popular and           portable, and it's not based in file-mapping semantics, but it uses special           functions (shmget, shmat, shmdt,           shmctl...).                     Unlike POSIX shared memory segments, XSI shared memory segments are not           identified by names but by 'keys' usually created with ftok.           XSI shared memory segments have kernel lifetime and must be explicitly           removed. XSI shared memory does not support copy-on-write and partial shared           memory mapping but it supports anonymous shared memory.                     Boost.Interprocess offers simple (xsi_shared_memory)           and managed (managed_xsi_shared_memory)           shared memory classes to ease the use of XSI shared memory. It also wraps           key creation with the simple xsi_key           class.                     Let's repeat the same example presented for the portable shared memory           object: A server process creates a shared memory object, maps it and initializes           all the bytes to a value. After that, a client process opens the shared           memory, maps it, and checks that the data is correctly initialized.                     This is the server process:            #include &lt;boost/interprocess/xsi_shared_memory.hpp&gt; #include &lt;boost/interprocess/mapped_region.hpp&gt; #include &lt;cstring&gt; #include &lt;cstdlib&gt; #include &lt;string&gt;  using namespace boost::interprocess;  void remove_old_shared_memory(const xsi_key &amp;key) {    try{       xsi_shared_memory xsi(open_only, key);       xsi_shared_memory::remove(xsi.get_shmid());    }    catch(interprocess_exception &amp;e){       if(e.get_error_code() != not_found_error)          throw;    } }  int main(int argc, char *argv[]) {    if(argc == 1){  //Parent process       //Build XSI key (ftok based)       xsi_key key(argv[0], 1);        remove_old_shared_memory(key);        //Create a shared memory object.       xsi_shared_memory shm (create_only, key, 1000);        //Remove shared memory on destruction       struct shm_remove       {          int shmid_;          shm_remove(int shmid) : shmid_(shmid){}          ~shm_remove(){ xsi_shared_memory::remove(shmid_); }       } remover(shm.get_shmid());        //Map the whole shared memory in this process       mapped_region region(shm, read_write);        //Write all the memory to 1       std::memset(region.get_address(), 1, region.get_size());        //Launch child process       std::string s(argv[0]); s += " child ";       if(0 != std::system(s.c_str()))          return 1;    }    else{       //Build XSI key (ftok based)       xsi_key key(argv[0], 1);        //Create a shared memory object.       xsi_shared_memory shm (open_only, key);        //Map the whole shared memory in this process       mapped_region region(shm, read_only);        //Check that memory was initialized to 1       char *mem = static_cast&lt;char*&gt;(region.get_address());       for(std::size_t i = 0; i &lt; region.get_size(); ++i)          if(*mem++ != 1)             return 1;   //Error checking memory    }    return 0; }                Memory       Mapped Files   What         is a memory mapped file? Using         mapped files Header Creating         a file mapping Mapping         File's Contents In Memory A         Simple Example    What         is a memory mapped file?             File mapping is the association of a file's contents with a portion of           the address space of a process. The system creates a file mapping to associate           the file and the address space of the process. A mapped region is the portion           of address space that the process uses to access the file's contents. A           single file mapping can have several mapped regions, so that the user can           associate parts of the file with the address space of the process without           mapping the entire file in the address space, since the file can be bigger           than the whole address space of the process (a 9GB DVD image file in a           usual 32 bit systems). Processes read from and write to the file using           pointers, just like with dynamic memory. File mapping has the following           advantages:                          Uniform resource use. Files and memory can be treated using the same               functions.                             Automatic file data synchronization and cache from the OS.                             Reuse of C++ utilities (STL containers, algorithms) in files.                             Shared memory between two or more applications.                             Allows efficient work with a large files, without mapping the whole               file into memory                             If several processes use the same file mapping to create mapped regions               of a file, each process' views contain identical copies of the file               on disk.                          File mapping is not only used for interprocess communication, it can be           used also to simplify file usage, so the user does not need to use file-management           functions to write the file. The user just writes data to the process memory,           and the operating systems dumps the data to the file.                     When two processes map the same file in memory, the memory that one process           writes is seen by another process, so memory mapped files can be used as           an interprocess communication mechanism. We can say that memory-mapped           files offer the same interprocess communication services as shared memory           with the addition of filesystem persistence. However, as the operating           system has to synchronize the file contents with the memory contents, memory-mapped           files are not as fast as shared memory.             Using         mapped files             To use memory-mapped files, we have to perform 2 basic steps:                          Create a mappable object that represent an already created file of               the filesystem. This object will be used to create multiple mapped               regions of the the file.                             Associate the whole file or parts of the file with the address space               of the calling process. The operating system looks for a big enough               memory address range in the calling process' address space and marks               that address range as an special range. Changes in that address range               are automatically seen by other process that also have mapped the same               file and those changes are also transferred to the disk automatically.                          Once the two steps have been successfully completed, the process can start           writing to and reading from the address space to send to and receive data           from other processes and synchronize the file's contents with the changes           made to the mapped region. Now, let's see how can we do this using Boost.Interprocess:             Header             To manage mapped files, you just need to include the following header:          #include &lt;boost/interprocess/file_mapping.hpp&gt;     Creating         a file mapping             First, we have to link a file's contents with the process' address space.           To do this, we have to create a mappable object that represents that file.           This is achieved in Boost.Interprocess           creating a file_mapping           object:          using boost::interprocess; file_mapping m_file    ("/usr/home/file"       //filename    ,read_write             //read-write mode    );             Now we can use the newly created object to create mapped regions. For more           details regarding this class see the boost::interprocess::file_mapping           class reference.             Mapping         File's Contents In Memory             After creating a file mapping, a process just has to map the shared memory           in the process' address space. The user can map the whole shared memory           or just part of it. The mapping process is done using the mapped_region class. as we have said           before The class represents a memory region that has been mapped from a           shared memory or from other devices that have also mapping capabilities:          using boost::interprocess; std::size_t FileSize = ...  //Map the second half of the file mapped_region region    ( m_file                   //Memory-mappable object    , read_write               //Access mode    , FileSize/2               //Offset from the beginning of shm    , FileSize-FileSize/2      //Length of the region    );  //Get the address of the region region.get_address();  //Get the size of the region region.get_size();             The user can specify the offset from the file where the mapped region should           start and the size of the mapped region. If no offset or size is specified,           the whole file is mapped. If the offset is specified, but not the size,           the mapped region covers from the offset until the end of the file.                     If several processes map the same file, and a process modifies a memory           range from a mapped region that is also mapped by other process, the changes           are inmedially visible to other processes. However, the file contents on           disk are not updated immediately, since that would hurt performance (writing           to disk is several times slower than writing to memory). If the user wants           to make sure that file's contents have been updated, it can flush a range           from the view to disk. When the function returns, the flushing process           has startd but there is not guarantee that all data has been written to           disk:          //Flush the whole region region.flush();  //Flush from an offset until the end of the region region.flush(offset);  //Flush a memory range starting on an offset region.flush(offset, size);             Remember that the offset is not an offset           on the file, but an offset in the mapped region. If a region covers the           second half of a file and flushes the whole region, only the half of the           file is guaranteed to have been flushed.                     For more details regarding mapped_region           see the boost::interprocess::mapped_region           class reference.             A         Simple Example             Let's reproduce the same example described in the shared memory section,           using memory mapped files. A server process creates a shared memory segment,           maps it and initializes all the bytes to a value. After that, a client           process opens the shared memory, maps it, and checks that the data is correctly           initialized::            #include &lt;boost/interprocess/file_mapping.hpp&gt; #include &lt;boost/interprocess/mapped_region.hpp&gt; #include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;string&gt; #include &lt;vector&gt; #include &lt;cstring&gt; #include &lt;cstddef&gt; #include &lt;cstdlib&gt;  int main(int argc, char *argv[]) {    using namespace boost::interprocess;     //Define file names    const char *FileName  = "file.bin";    const std::size_t FileSize = 10000;     if(argc == 1){ //Parent process executes this       {  //Create a file          file_mapping::remove(FileName);          std::filebuf fbuf;          fbuf.open(FileName, std::ios_base::in | std::ios_base::out                               | std::ios_base::trunc | std::ios_base::binary);          //Set the size          fbuf.pubseekoff(FileSize-1, std::ios_base::beg);          fbuf.sputc(0);       }        //Remove on exit       struct file_remove       {          file_remove(const char *FileName)             : FileName_(FileName) {}          ~file_remove(){ file_mapping::remove(FileName_); }          const char *FileName_;       } remover(FileName);        //Create a file mapping       file_mapping m_file(FileName, read_write);        //Map the whole file with read-write permissions in this process       mapped_region region(m_file, read_write);        //Get the address of the mapped region       void * addr       = region.get_address();       std::size_t size  = region.get_size();        //Write all the memory to 1       std::memset(addr, 1, size);        //Launch child process       std::string s(argv[0]); s += " child ";       if(0 != std::system(s.c_str()))          return 1;    }    else{  //Child process executes this       {  //Open the file mapping and map it as read-only          file_mapping m_file(FileName, read_only);           mapped_region region(m_file, read_only);           //Get the address of the mapped region          void * addr       = region.get_address();          std::size_t size  = region.get_size();           //Check that memory was initialized to 1          const char *mem = static_cast&lt;char*&gt;(addr);          for(std::size_t i = 0; i &lt; size; ++i)             if(*mem++ != 1)                return 1;   //Error checking memory       }       {  //Now test it reading the file          std::filebuf fbuf;          fbuf.open(FileName, std::ios_base::in | std::ios_base::binary);           //Read it to memory          std::vector&lt;char&gt; vect(FileSize, 0);          fbuf.sgetn(&amp;vect[0], std::streamsize(vect.size()));           //Check that memory was initialized to 1          const char *mem = static_cast&lt;char*&gt;(&amp;vect[0]);          for(std::size_t i = 0; i &lt; FileSize; ++i)             if(*mem++ != 1)                return 1;   //Error checking memory       }    }     return 0; }                More       About Mapped Regions   One         Class To Rule Them All Mapping         Address In Several Processes Fixed         Address Mapping Mapping         Offset And Address Limitations    One         Class To Rule Them All             As we have seen, both shared_memory_object           and file_mapping objects           can be used to create mapped_region           objects. A mapped region created from a shared memory object or a file           mapping are the same class and this has many advantages.                     One can, for example, mix in STL containers mapped regions from shared           memory and memory mapped files. Libraries that only depend on mapped regions           can be used to work with shared memory or memory mapped files without recompiling           them.             Mapping         Address In Several Processes             In the example we have seen, the file or shared memory contents are mapped           to the address space of the process, but the address was chosen by the           operating system.                     If several processes map the same file/shared memory, the mapping address           will be surely different in each process. Since each process might have           used its address space in a different way (allocation of more or less dynamic           memory, for example), there is no guarantee that the file/shared memory           is going to be mapped in the same address.                     If two processes map the same object in different addresses, this invalidates           the use of pointers in that memory, since the pointer (which is an absolute           address) would only make sense for the process that wrote it. The solution           for this is to use offsets (distance) between objects instead of pointers:           If two objects are placed in the same shared memory segment by one process,           the address of each object will be different           in another process but the distance between them           (in bytes) will be the same.                     So the first advice when mapping shared memory and memory mapped files           is to avoid using raw pointers, unless you know what you are doing. Use           offsets between data or relative pointers to obtain pointer functionality           when an object placed in a mapped region wants to point to an object placed           in the same mapped region. Boost.Interprocess           offers a smart pointer called boost::interprocess::offset_ptr           that can be safely placed in shared memory and that can be used to point           to another object placed in the same shared memory / memory mapped file.             Fixed         Address Mapping             The use of relative pointers is less efficient than using raw pointers,           so if a user can succeed mapping the same file or shared memory object           in the same address in two processes, using raw pointers can be a good           idea.                     To map an object in a fixed address, the user can specify that address           in the mapped region's           constructor:          mapped_region region ( shm                         //Map shared memory                      , read_write                  //Map it as read-write                      , 0                           //Map from offset 0                      , 0                           //Map until the end                      , (void*)0x3F000000           //Map it exactly there                      );             However, the user can't map the region in any address, even if the address           is not being used. The offset parameter that marks the start of the mapping           region is also limited. These limitations are explained in the next section.             Mapping         Offset And Address Limitations             As mentioned, the user can't map the memory mappable object at any address           and it can specify the offset of the mappable object that is equivalent           to the start of the mapping region to an arbitrary value. Most operating           systems limit the mapping address and the offset of the mappable object           to a multiple of a value called page size.           This is due to the fact that the operating system           performs mapping operations over whole pages.                     If fixed mapping address is used, offset and address           parameters should be multiples of that value. This value is, typically,           4KB or 8KB for 32 bit operating systems.          //These might fail because the offset is not a multiple of the page size //and we are using fixed address mapping mapped_region region1( shm                   //Map shared memory                      , read_write            //Map it as read-write                      , 1                     //Map from offset 1                      , 1                     //Map 1 byte                      , (void*)0x3F000000     //Aligned mapping address                      );  //These might fail because the address is not a multiple of the page size mapped_region region2( shm                   //Map shared memory                      , read_write            //Map it as read-write                      , 0                     //Map from offset 0                      , 1                     //Map 1 byte                      , (void*)0x3F000001     //Not aligned mapping address                      );             Since the operating system performs mapping operations over whole pages,           specifying a mapping size or offset           that are not multiple of the page size will waste more resources than necessary.           If the user specifies the following 1 byte mapping:          //Map one byte of the shared memory object. //A whole memory page will be used for this. mapped_region region ( shm                    //Map shared memory                      , read_write             //Map it as read-write                      , 0                      //Map from offset 0                      , 1                      //Map 1 byte                      );             The operating system will reserve a whole page that will not be reused           by any other mapping so we are going to waste (page           size - 1) bytes. If we want to use efficiently operating system           resources, we should create regions whose size is a multiple of page size bytes. If the user specifies the following           two mapped regions for a file with which has 2*page_size           bytes:          //Map the first quarter of the file //This will use a whole page mapped_region region1( shm                //Map shared memory                      , read_write         //Map it as read-write                      , 0                  //Map from offset 0                      , page_size/2        //Map page_size/2 bytes                      );  //Map the rest of the file //This will use a 2 pages mapped_region region2( shm                //Map shared memory                      , read_write         //Map it as read-write                      , page_size/2        //Map from offset 0                      , 3*page_size/2      //Map the rest of the shared memory                      );             In this example, a half of the page is wasted in the first mapping and           another half is wasted in the second because the offset is not a multiple           of the page size. The mapping with the minimum resource usage would be           to map whole pages:          //Map the whole first half: uses 1 page mapped_region region1( shm                //Map shared memory                      , read_write         //Map it as read-write                      , 0                  //Map from offset 0                      , page_size          //Map a full page_size                      );  //Map the second half: uses 1 page mapped_region region2( shm                //Map shared memory                      , read_write         //Map it as read-write                      , page_size          //Map from offset 0                      , page_size          //Map the rest                      );             How can we obtain the page size? The           mapped_region class has           a static function that returns that value:          //Obtain the page size of the system std::size_t page_size = mapped_region::get_page_size();             The operating system might also limit the number of mapped memory regions           per process or per system.              Limitations       When Constructing Objects In Mapped Regions   Offset         pointers instead of raw pointers References         forbidden Virtuality         forbidden Be         careful with static class members           When two processes create a mapped region of the same mappable object, two         processes can communicate writing and reading that memory. A process could         construct a C++ object in that memory so that the second process can use         it. However, a mapped region shared by multiple processes, can't hold any         C++ object, because not every class is ready to be a process-shared object,         specially, if the mapped region is mapped in different address in each process.          Offset         pointers instead of raw pointers             When placing objects in a mapped region and mapping that region in different           address in every process, raw pointers are a problem since they are only           valid for the process that placed them there. To solve this, Boost.Interprocess offers a special smart pointer           that can be used instead of a raw pointer. So user classes containing raw           pointers (or Boost smart pointers, that internally own a raw pointer) can't           be safely placed in a process shared mapped region. These pointers must           be replaced with offset pointers, and these pointers must point only to           objects placed in the same mapped region if you want to use these shared           objects from different processes.                     Of course, a pointer placed in a mapped region shared between processes           should only point to an object of that mapped region. Otherwise, the pointer           would point to an address that it's only valid one process and other processes           may crash when accessing to that address.             References         forbidden             References suffer from the same problem as pointers (mainly because they           are implemented as pointers). However, it is not possible to create a fully           workable smart reference currently in C++ (for example, operator           .() can't be overloaded). Because           of this, if the user wants to put an object in shared memory, the object           can't have any (smart or not) reference as a member.                     References will only work if the mapped region is mapped in the same base           address in all processes sharing a memory segment. Like pointers, a reference           placed in a mapped region should only point to an object of that mapped           region.             Virtuality         forbidden             The virtual table pointer and the virtual table are in the address space           of the process that constructs the object, so if we place a class with           a virtual function or virtual base class, the virtual pointer placed in           shared memory will be invalid for other processes and they will crash.                     This problem is very difficult to solve, since each process needs a different           virtual table pointer and the object that contains that pointer is shared           across many processes. Even if we map the mapped region in the same address           in every process, the virtual table can be in a different address in every           process. To enable virtual functions for objects shared between processes,           deep compiler changes are needed and virtual functions would suffer a performance           hit. That's why Boost.Interprocess does           not have any plan to support virtual function and virtual inheritance in           mapped regions shared between processes.             Be         careful with static class members             Static members of classes are global objects shared by all instances of           the class. Because of this, static members are implemented as global variables           in processes.                     When constructing a class with static members, each process has its own           copy of the static member, so updating a static member in one process does           not change the value of the static member the another process. So be careful           with these classes. Static members are not dangerous if they are just constant           variables initialized when the process starts, but they don't change at           all (for example, when used like enums) and their value is the same for           all processes.               Copyright &#169; 2005-2012 Ion Gaztanaga         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3215weight: 5
tittle: Acknowledgements, notes and links
url :https://www.boost.org/doc/libs/1_53_0/doc/html/interprocess/acknowledgements_notes.html
content:    Acknowledgements, notes and links           Home Libraries People FAQ More        Acknowledgements,     notes and links   Notes Thanks       to... Release       Notes Books       and interesting links Future       improvements...    Notes   Notes         for Windows users Notes         for Linux users    Notes         for Windows users   COM           Initialization Shared           memory emulation folder    COM           Initialization               Boost.Interprocess uses the Windows             COM library to implement some features and initializes it with concurrency             model COINIT_APARTMENTTHREADED.             If the COM library was already initialized by the calling thread for             another concurrency model, Boost.Interprocess             handles this gracefully and uses COM calls for the already initialized             model. If for some reason, you want Boost.Interprocess             to initialize the COM library with another model, define the macro BOOST_INTERPROCESS_WINDOWS_COINIT_MODEL             before including Boost.Interprocess             to one of these values:                              COINIT_APARTMENTTHREADED_BIPC                                 COINIT_MULTITHREADED_BIPC                                 COINIT_DISABLE_OLE1DDE_BIPC                                 COINIT_SPEED_OVER_MEMORY_BIPC                    Shared           memory emulation folder               Shared memory (shared_memory_object)             is implemented in windows using memory mapped files, placed in a directory             in the shared documents folder (SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders\Common AppData).             This directory name is the last bootup time (obtained via COM calls),             so that each bootup shared memory is created in a new folder obtaining             kernel persistence shared memory.                         Unfortunately, due to COM implementation related errors, in Boost 1.48             &amp; Boost 1.49 the bootup-time folder was dumped and files were directly             created in shared documents folder, reverting to filesystem persistence             shared memory. Boost 1.50 fixed those issues and recovered bootup time             directory and kernel persistence. If you need to reproduce Boost 1.48             &amp; Boost 1.49 behaviour to communicate with applications compiled             with that version, comment #define             BOOST_INTERPROCESS_HAS_KERNEL_BOOTTIME             directive in the Windows configuration part of boost/interprocess/detail/workaround.hpp.                Notes         for Linux users  Overcommit   Overcommit               The committed address space is the total amount of virtual memory (swap             or physical memory/RAM) that the kernel might have to supply if all applications             decide to access all of the memory they've requested from the kernel.             By default, Linux allows processes to commit more virtual memory than             available in the system. If that memory is not accessed, no physical             memory + swap is actually used.                         The reason for this behaviour is that Linux tries to optimize memory             usage on forked processes; fork() creates a full copy of the process             space, but with overcommitted memory, in this new forked instance only             pages which have been written to actually need to be allocated by the             kernel. If applications access more memory than available, then the kernel             must free memory in the hard way: the OOM (Out Of Memory)-killer picks             some processes to kill in order to recover memory.                         Boost.Interprocess has no way to change             this behaviour and users might suffer the OOM-killer when accessing shared             memory. According to the Kernel             documentation, the Linux kernel supports several overcommit modes.             If you need non-kill guarantees in your application, you should change             this overcommit behaviour.                 Thanks       to...  People   People             Many people have contributed with ideas and revisions, so this is the place           to thank them:                          Thanks to all people who have shown interest in the library and have               downloaded and tested the snapshots.                             Thanks to Francis Andre and Anders Hybertz for their ideas and suggestions.               Many of them are not implemented yet but I hope to include them when               library gets some stability.                             Thanks to Matt Doyle, Steve               LoBasso, Glenn Schrader,               Hiang Swee Chiang, Phil               Endecott, Rene Rivera,               Harold Pirtle, Paul               Ryan, Shumin Wu, Michal Wozniak, Peter               Johnson, Alex Ott, Shane Guillory, Steven               Wooding and Kim Barrett               for their bug fixes and library testing.                             Thanks to Martin Adrian who suggested               the use of Interprocess framework for user defined buffers.                             Thanks to Synge Todo for his boostbook-doxygen               patch to improve Interprocess documentation.                             Thanks to Olaf Krzikalla for his Intrusive               library. I have taken some ideas to improve red black tree implementation               from his library.                             Thanks to Daniel James for his unordered_map/set               family and his help with allocators. His great unordered implementation               has been a reference to design exception safe containers.                             Thanks to Howard Hinnant for his amazing               help, specially explaining allocator swapping, move semantics and for               developing upgradable mutex and lock transfer features.                             Thanks to Pavel Vozenilek for his               continuous review process, suggestions, code and help. He is the major               supporter of Interprocess library. The library has grown with his many               and great advices.                             And finally, thank you to all Boosters. Long               live to C++!                   Release       Notes   Boost         1.53 Release Boost         1.52 Release Boost         1.51 Release Boost         1.50 Release Boost         1.49 Release Boost         1.48 Release Boost         1.46 Release Boost         1.45 Release Boost         1.41 Release Boost         1.40 Release Boost         1.39 Release Boost         1.38 Release Boost         1.37 Release Boost         1.36 Release Boost         1.35 Release    Boost         1.53 Release                  Fixed GCC -Wshadow warnings.                             Experimental multiple allocation interface improved and changed again.               Still unstable.                             Replaced deprecated BOOST_NO_XXXX with newer BOOST_NO_CXX11_XXX macros.                             ABI breaking: changed node pool allocators               internals for improved efficiency.                             Fixed bug #7795.                  Boost         1.52 Release                  Added shrink_by and               advise functions in               mapped_region.                             ABI breaking: Reimplemented message_queue with a circular buffer               index (the old behavior used an ordered array, leading to excessive               copies). This should greatly increase performance but breaks ABI. Old               behaviour/ABI can be used undefining macro BOOST_INTERPROCESS_MSG_QUEUE_CIRCULAR_INDEX               in boost/interprocess/detail/workaround.hpp                             Improved message_queue               insertion time avoiding priority search for common cases (both array               and circular buffer configurations).                             Implemented interproces_sharable_mutex               and interproces_condition_any.                             Improved offset_ptr               performance.                             Added integer overflow checks.                  Boost         1.51 Release                  Synchronous and asynchronous flushing for mapped_region::flush.                             Source &amp; ABI breaking: Removed               get_offset method from               mapped_region as it               has no practical utility and m_offset               member was not for anything else.                             Source &amp; ABI breaking: Removed               flush from managed_shared_memory. as it is unspecified               according to POSIX: "The               effect of msync() on a shared memory object or a typed memory object               is unspecified" .                             Fixed bug #7152,                  Boost         1.50 Release                  Fixed bugs #3750,               #6727,               #6648,                             Shared memory in windows has again kernel persistence: kernel bootstamp               and WMI has received some fixes and optimizations. This causes incompatibility               with Boost 1.48 and 1.49 but the user can comment #define               BOOST_INTERPROCESS_HAS_KERNEL_BOOTTIME               in the windows configuration part to get Boost 1.48 &amp; Boost 1.49               behaviour.                  Boost         1.49 Release                  Fixed bugs #6531,               #6412,               #6398,               #6340,               #6319,               #6287,               #6265,               #6233,               #6147,               #6134,               #6058,               #6054,               #5772,               #5738,               #5622,               #5552,               #5518,               #4655,               #4452,               #4383,               #4297.                             Fixed timed functions in mutex implementations to fulfill POSIX requirements:               Under no circumstance shall the function fail with a timeout               if the mutex can be locked immediately. The validity of the abs_timeout               parameter need not be checked if the mutex can be locked immediately.                  Boost         1.48 Release                  Fixed bugs #2796,               #4031,               #4251,               #4452,               #4895,               #5077,               #5120,               #5123,               #5230,               #5197,               #5287,               #5294,               #5306,               #5308,               #5392,               #5409,                             Added support to customize offset_ptr and allow creating custom managed               segments that might be shared between 32 and 64 bit processes.                             Shared memory in windows has again filesystem lifetime: kernel bootstamp               and WMI use to get a reliable timestamp was causing a lot of trouble.                  Boost         1.46 Release                 Fixed bugs #4979,               #4907,               #4895                 Boost         1.45 Release                  Fixed bugs #1080,               #3284,               #3439,               #3448,               #3582,               #3682,               #3829,               #3846,               #3914,               #3947,               #3950,               #3951,               #3985,               #4010,               #4417,               #4019,               #4039,               #4218,               #4230,               #4250,               #4297,               #4350,               #4352,               #4426,               #4516,               #4524,               #4557,               #4606,               #4685,               #4694.                             Added support for standard rvalue reference move semantics (tested               on GCC 4.5 and VC10).                             Permissions can be detailed for interprocess named resources.                             mapped_region::flush initiates disk flushing but               does not guarantee it's completed when returns, since it is not portable.                             FreeBSD and MacOS now use posix semaphores to implement named semaphores               and mutex.                  Boost         1.41 Release                  Support for POSIX shared memory in Mac OS.                             ABI breaking: Generic semaphore and named_semaphore               now implemented more efficiently with atomic operations.                             More robust file opening in Windows platforms with active Anti-virus               software.                  Boost         1.40 Release                  Windows shared memory is created in Shared Documents folder so that               it can be shared between services and processes                             Fixed bugs #2967,               #2973,               #2992,               #3138,               #3166,               #3205.                  Boost         1.39 Release                  Added experimental stable_vector               container.                             shared_memory_object::remove               has now POSIX unlink               semantics and file_mapping::remove               was added to obtain POSIX unlink               semantics with mapped files.                             Shared memory in windows has now kernel lifetime instead of filesystem               lifetime: shared memory will disappear when the system reboots.                             Updated move semantics.                             Fixed bugs #2722,               #2729,               #2766,               #1390,               #2589,                  Boost         1.38 Release                  Updated documentation to show rvalue-references funcions instead of               emulation functions.                             More non-copyable classes are now movable.                             Move-constructor and assignments now leave moved object in default-constructed               state instead of just swapping contents.                             Several bugfixes ( #2391,               #2431,               #1390,               #2570,               #2528.                  Boost         1.37 Release                  Containers can be used now in recursive types.                             Added BOOST_INTERPROCESS_FORCE_GENERIC_EMULATION               macro option to force the use of generic emulation code for process-shared               synchronization primitives instead of native POSIX functions.                             Added placement insertion members to containers                             boost::posix_time::pos_inf value is now handled portably               for timed functions.                             Update some function parameters from iterator               to const_iterator in               containers to keep up with the draft of the next standard.                             Documentation fixes.                  Boost         1.36 Release                  Added anonymous shared memory for UNIX systems.                             Fixed erroneous void return               types from flat_map::erase() functions.                             Fixed missing move semantics on managed memory classes.                             Added copy_on_write and open_read_only options for shared memory and               mapped file managed classes.                             ABI breaking: Added to mapped_region the mode used to create               it.                             Corrected instantiation errors in void allocators.                             shared_ptr is movable               and supports aliasing.                  Boost         1.35 Release                  Added auxiliary utilities to ease the definition and construction of               shared_ptr,               weak_ptr               and unique_ptr.               Added explanations and examples of these smart pointers in the documentation.                             Optimized vector:                                     1) Now works with raw pointers as much as possible when using                     allocators defining pointer                     as an smart pointer. This increases performance and improves                     compilation times.                                         2) A bit of metaprogramming to avoid using move_iterator when                     the type has trivial copy constructor or assignment and improve                     performance.                                         3) Changed custom algorithms with standard ones to take advantage                     of optimized standard algorithms.                                         4) Removed unused code.                                                 ABI breaking: Containers don't derive               from allocators, to avoid problems with allocators that might define               virtual functions with the same names as container member functions.               That would convert container functions in virtual functions and might               disallow some of them if the returned type does not lead to a covariant               return. Allocators are now stored as base classes of internal structs.                             Implemented named_mutex               and named_semaphore               with POSIX named semaphores in systems supporting that option. named_condition               has been accordingly changed to support interoperability with named_mutex.                             Reduced template bloat for node and adaptive allocators extracting               node implementation to a class that only depends on the memory algorithm,               instead of the segment manager + node size + node number...                             Fixed bug in mapped_region               in UNIX when mapping address was provided but the region was mapped               in another address.                             Added aligned_allocate               and allocate_many functions               to managed memory segments.                             Improved documentation about managed memory segments.                             Boost.Interprocess containers are               now documented in the Reference section.                             Correction of typos and documentation errors.                             Added get_instance_name,               get_instance_length               and get_instance_type               functions to managed memory segments.                             Corrected suboptimal buffer expansion bug in rbtree_best_fit.                             Added iteration of named and unique objects in a segment manager.                             Fixed leak in vector.                             Added support for Solaris.                             Optimized segment_manager               to avoid code bloat associated with templated instantiations.                             Fixed bug for UNIX: No slash ('/') was being added as the first character               for shared memory names, leading to errors in some UNIX systems.                             Fixed bug in VC-8.0: Broken function inlining in core offset_ptr functions.                             Code examples changed to use new BoostBook code import features.                             Added aligned memory allocation function to memory algorithms.                             Fixed bug in deque::clear() and deque::erase(), they were declared private.                             Fixed bug in deque::erase(). Thanks to Steve LoBasso.                             Fixed bug in atomic_dec32(). Thanks to Glenn Schrader.                             Improved (multi)map/(multi)set constructors taking iterators. Now those               have linear time if the iterator range is already sorted.                             ABI breaking: (multi)map/(multi)set               now reduce their node size. The color bit is embedded in the parent               pointer. Now, the size of a node is the size of 3 pointers in most               systems. This optimization is activated for raw and offset_ptr               pointers.                             (multi)map/(multi)set now reuse memory from old nodes in the assignment               operator.                             ABI breaking: Implemented node-containers               based on intrusive containers. This saves code size, since many instantiations               share the same algorithms.                             Corrected code to be compilable with Visual C++ 8.0.                             Added function to zero free memory in memory algorithms and the segment               manager. This function is useful for security reasons and to improve               compression ratios for files created with managed_mapped_file.                             Added support for intrusive index types in managed memory segments.               Intrusive indexes save extra memory allocations to allocate the index               since with just one allocation, we allocate room for the value, the               name and the hook to insert the object in the index.                             Created new index type: iset_index.               It's an index based on an intrusive set (rb-tree).                             Created new index type: iunordered_set_index.               It's an index based on a pseudo-intrusive unordered set (hash table).                             ABI breaking: The intrusive index               iset_index is now the default index               type.                             Optimized vector to take advantage of boost::has_trivial_destructor.               This optimization avoids calling destructors of elements that have               a trivial destructor.                             Optimized vector to take advantage of has_trivial_destructor_after_move               trait. This optimization avoids calling destructors of elements that               have a trivial destructor if the element has been moved (which is the               case of many movable types). This trick was provided by Howard Hinnant.                             Added security check to avoid integer overflow bug in allocators and               named construction functions.                             Added alignment checks to forward and backwards expansion functions.                             Fixed bug in atomic functions for PPC.                             Fixed race-condition error when creating and opening a managed segment.                             Added adaptive pools.                             Source breaking: Changed node allocators'               template parameter order to make them easier to use.                             Added support for native windows shared memory.                             Added more tests.                             Corrected the presence of private functions in the reference section.                             Added function (deallocate_free_chunks()) to manually deallocate completely               free chunks from node allocators.                             Implemented N1780 proposal to LWG issue 233: Insertion hints               in associative containers in interprocess multiset               and multimap               classes.                             Source breaking: A shared memory object               is now used including shared_memory_object.hpp               header instead of shared               memory.hpp.                             ABI breaking: Changed global mutex               when initializing managed shared memory and memory mapped files. This               change tries to minimize deadlocks.                             Source breaking: Changed shared memory,               memory mapped files and mapped region's open mode to a single mode_t type.                             Added extra WIN32_LEAN_AND_MEAN before including DateTime headers to               avoid socket redefinition errors when using Interprocess and Asio in               windows.                             ABI breaking: mapped_region               constructor no longer requires classes derived from memory_mappable,               but classes must fulfill the MemoryMappable concept.                             Added in-place reallocation capabilities to basic_string.                             ABI breaking: Reimplemented and optimized               small string optimization. The narrow string class has zero byte overhead               with an internal 11 byte buffer in 32 systems!                             Added move semantics to containers. Improves performance when using               containers of containers.                             ABI breaking: End nodes of node containers               (list, slist, map/set) are now embedded in the containers instead of               allocated using the allocator. This allows no-throw move-constructors               and improves performance.                             ABI breaking: slist               and list containers now have constant-time               size() function. The size of the container is               added as a member.                   Books       and interesting links   Books Links           Some useful references about the C++ programming language, C++ internals,         shared memory, allocators and containers used to design Boost.Interprocess.          Books                  Great book about multithreading, and POSIX: "Programming               with Posix Threads", David               R. Butenhof                             The UNIX inter-process bible: "UNIX               Network Programming, Volume 2: Interprocess Communications",               W. Richard Stevens                             Current STL allocator issues: "Effective               STL", Scott Meyers                             My C++ bible: "Thinking in C++,               Volume 1 &amp; 2", Bruce               Eckel and Chuck Allison                             The book every C++ programmer should read: "Inside               the C++ Object Model", Stanley               B. Lippman                             A must-read: "ISO/IEC TR 18015:               Technical Report on C++ Performance", ISO WG21-SC22 members.                  Links                  A framework to put the STL in shared memory: "A               C++ Standard Allocator for the Standard Template Library"               .                             Instantiating C++ objects in shared memory: "Using               objects in shared memory for C++ application" .                             A shared memory allocator and relative pointer: "Taming               Shared Memory" .                   Future       improvements...   Win32         synchronization is too basic Use         of wide character names on Boost.Interprocess basic resources Security         attributes Future         inter-process communications           There are some Interprocess features that I would like to implement and some         Boost.Interprocess code that can be much         better. Let's see some ideas:          Win32         synchronization is too basic             Win32 version of shared mutexes and shared conditions are based on "spin           and wait" atomic instructions. This leads to poor performance and           does not manage any issues like priority inversions. We would need very           serious help from threading experts on this. And I'm not sure that this           can be achieved in user-level software. Posix based implementations use           PTHREAD_PROCESS_SHARED attribute to place mutexes in shared memory, so           there are no such problems. I'm not aware of any implementation that simulates           PTHREAD_PROCESS_SHARED attribute for Win32. We should be able to construct           these primitives in memory mapped files, so that we can get filesystem           persistence just like with POSIX primitives.             Use         of wide character names on Boost.Interprocess basic resources             Currently Interprocess only allows char           based names for basic named objects. However, several operating systems           use wchar_t names for resources (mapped           files, for example). In the future Interprocess should try to present a           portable narrow/wide char interface. To do this, it would be useful to           have a boost wstring &lt;-&gt; string conversion utilities to translate           resource names (escaping needed characters that can conflict with OS names)           in a portable way. It would be interesting also the use of boost::filesystem           paths to avoid operating system specific issues.             Security         attributes             Boost.Interprocess does not define security           attributes for shared memory and synchronization objects. Standard C++           also ignores security attributes with files so adding security attributes           would require some serious work.             Future         inter-process communications             Boost.Interprocess offers a process-shared           message queue based on Boost.Interprocess           primitives like mutexes and conditions. I would want to develop more mechanisms,           like stream-oriented named fifo so that we can use it with a iostream-interface           wrapper (we can imitate Unix pipes).                     C++ needs more complex mechanisms and it would be nice to have a stream           and datagram oriented PF_UNIX-like mechanism in C++. And for very fast           inter-process remote calls Solaris doors is an interesting alternative           to implement for C++. But the work to implement PF_UNIX-like sockets and           doors would be huge (and it might be difficult in a user-level library).           Any network expert volunteer?               Copyright &#169; 2005-2012 Ion Gaztanaga         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3216weight: 1
tittle: Architecture and internals
url :https://www.boost.org/doc/libs/1_53_0/doc/html/interprocess/architecture.html
content:    Architecture and internals           Home Libraries People FAQ More        Architecture and internals   Basic guidelines From       the memory algorithm to the managed segment Allocators       and containers Performance of       Boost.Interprocess    Basic guidelines           When building Boost.Interprocess architecture,         I took some basic guidelines that can be summarized by these points:                      Boost.Interprocess should be portable             at least in UNIX and Windows systems. That means unifying not only interfaces             but also behaviour. This is why Boost.Interprocess             has chosen kernel or filesystem persistence for shared memory and named             synchronization mechanisms. Process persistence for shared memory is             also desirable but it's difficult to achieve in UNIX systems.                         Boost.Interprocess inter-process synchronization             primitives should be equal to thread synchronization primitives. Boost.Interprocess aims to have an interface compatible             with the C++ standard thread API.                         Boost.Interprocess architecture should             be modular, customizable but efficient. That's why Boost.Interprocess             is based on templates and memory algorithms, index types, mutex types             and other classes are templatizable.                         Boost.Interprocess architecture should             allow the same concurrency as thread based programming. Different mutual             exclusion levels are defined so that a process can concurrently allocate             raw memory when expanding a shared memory vector while another process             can be safely searching a named object.                         Boost.Interprocess containers know nothing             about Boost.Interprocess. All specific             behaviour is contained in the STL-like allocators. That allows STL vendors             to slightly modify (or better said, generalize) their standard container             implementations and obtain a fully std::allocator and boost::interprocess::allocator             compatible container. This also make Boost.Interprocess             containers compatible with standard algorithms.                      Boost.Interprocess is built above 3 basic         classes: a memory algorithm, a segment manager and a managed         memory segment:           From       the memory algorithm to the managed segment   The         memory algorithm The         segment manager Boost.Interprocess         managed memory segments    The         memory algorithm             The memory algorithm is an object that           is placed in the first bytes of a shared memory/memory mapped file segment.           The memory algorithm can return portions           of that segment to users marking them as used and the user can return those           portions to the memory algorithm so that           the memory algorithm mark them as free           again. There is an exception though: some bytes beyond the end of the memory           algorithm object, are reserved and can't be used for this dynamic allocation.           This "reserved" zone will be used to place other additional objects           in a well-known place.                     To sum up, a memory algorithm has the           same mission as malloc/free of standard C library, but it just can return           portions of the segment where it is placed. The layout of a memory segment           would be:          Layout of the memory segment:  ____________ __________ ____________________________________________ |            |          |                                            | |   memory   | reserved |  The memory algorithm will return portions | | algorithm  |          |  of the rest of the segment.               | |____________|__________|____________________________________________|             The memory algorithm takes care of memory           synchronizations, just like malloc/free guarantees that two threads can           call malloc/free at the same time. This is usually achieved placing a process-shared           mutex as a member of the memory algorithm. Take in care that the memory           algorithm knows nothing about the segment           (if it is shared memory, a shared memory file, etc.). For the memory algorithm           the segment is just a fixed size memory buffer.                     The memory algorithm is also a configuration           point for the rest of the Boost.Interprocess           framework since it defines two basic types as member typedefs:          typedef /*implementation dependent*/ void_pointer; typedef /*implementation dependent*/ mutex_family;             The void_pointer typedef           defines the pointer type that will be used in the Boost.Interprocess           framework (segment manager, allocators, containers). If the memory algorithm           is ready to be placed in a shared memory/mapped file mapped in different           base addresses, this pointer type will be defined as offset_ptr&lt;void&gt; or a similar relative pointer. If the           memory algorithm will be used just with           fixed address mapping, void_pointer           can be defined as void*.                     The rest of the interface of a Boost.Interprocess           memory algorithm is described in Writing           a new shared memory allocation algorithm section. As memory algorithm           examples, you can see the implementations simple_seq_fit           or rbtree_best_fit           classes.             The         segment manager             The segment manager, is an object also           placed in the first bytes of the managed memory segment (shared memory,           memory mapped file), that offers more sophisticated services built above           the memory algorithm. How can both the segment manager and memory algorithm be           placed in the beginning of the segment? That's because the segment manager           owns the memory algorithm: The truth is           that the memory algorithm is embedded           in the segment manager:          The layout of managed memory segment:  _______ _________________ |       |         |       | | some  | memory  | other |&lt;- The memory algorithm considers |members|algorithm|members|   "other members" as reserved memory, so |_______|_________|_______|   it does not use it for dynamic allocation. |_________________________|____________________________________________ |                         |                                            | |    segment manager      |  The memory algorithm will return portions | |                         |  of the rest of the segment.               | |_________________________|____________________________________________|             The segment manager initializes the memory           algorithm and tells the memory manager that it should not use the memory           where the rest of the segment manager's           member are placed for dynamic allocations. The other members of the segment manager are a recursive           mutex (defined by the memory algorithm's mutex_family::recursive_mutex           typedef member), and two indexes (maps):           one to implement named allocations, and another one to implement "unique           instance" allocations.                          The first index is a map with a pointer to a c-string (the name of               the named object) as a key and a structure with information of the               dynamically allocated object (the most important being the address               and the size of the object).                             The second index is used to implement "unique instances"               and is basically the same as the first index, but the name of the object               comes from a typeid(T).name()               operation.                          The memory needed to store [name pointer, object information] pairs in           the index is allocated also via the memory algorithm,           so we can tell that internal indexes are just like ordinary user objects           built in the segment. The rest of the memory to store the name of the object,           the object itself, and meta-data for destruction/deallocation is allocated           using the memory algorithm in a single           allocate()           call.                     As seen, the segment manager knows nothing about shared memory/memory mapped files.           The segment manager itself does not allocate           portions of the segment, it just asks the memory           algorithm to allocate the needed memory from the rest of the           segment. The segment manager is a class           built above the memory algorithm that offers named object construction,           unique instance constructions, and many other services.                     The segment manager is implemented in           Boost.Interprocess by the segment_manager           class.          template&lt;class CharType         ,class MemoryAlgorithm         ,template&lt;class IndexConfig&gt; class IndexType&gt; class segment_manager;             As seen, the segment manager is quite generic: we can specify the character           type to be used to identify named objects, we can specify the memory algorithm           that will control dynamically the portions of the memory segment, and we           can specify also the index type that will store the [name pointer, object           information] mapping. We can construct our own index types as explained           in Building           custom indexes section.             Boost.Interprocess         managed memory segments             The Boost.Interprocess managed memory           segments that construct the shared memory/memory mapped file, place there           the segment manager and forward the user requests to the segment manager.           For example, basic_managed_shared_memory           is a Boost.Interprocess managed memory           segment that works with shared memory. basic_managed_mapped_file           works with memory mapped files, etc...                     Basically, the interface of a Boost.Interprocess           managed memory segment is the same as the segment           manager but it also offers functions to "open", "create",           or "open or create" shared memory/memory-mapped files segments           and initialize all needed resources. Managed memory segment classes are           not built in shared memory or memory mapped files, they are normal C++           classes that store a pointer to the segment manager (which is built in           shared memory or memory mapped files).                     Apart from this, managed memory segments offer specific functions: managed_mapped_file offers functions           to flush memory contents to the file, managed_heap_memory           offers functions to expand the memory, etc...                     Most of the functions of Boost.Interprocess           managed memory segments can be shared between all managed memory segments,           since many times they just forward the functions to the segment manager.           Because of this, in Boost.Interprocess           all managed memory segments derive from a common class that implements           memory-independent (shared memory, memory mapped files) functions: boost::interprocess::ipcdetail::basic_managed_memory_impl                     Deriving from this class, Boost.Interprocess           implements several managed memory classes, for different memory backends:                          basic_managed_shared_memory               (for shared memory).                             basic_managed_mapped_file               (for memory mapped files).                             basic_managed_heap_memory               (for heap allocated memory).                             basic_managed_external_buffer               (for user provided external buffer).                   Allocators       and containers   Boost.Interprocess         allocators Implementation         of Boost.Interprocess segregated storage         pools Implementation         of Boost.Interprocess adaptive pools Boost.Interprocess         containers    Boost.Interprocess         allocators             The Boost.Interprocess STL-like allocators           are fairly simple and follow the usual C++ allocator approach. Normally,           allocators for STL containers are based above new/delete operators and           above those, they implement pools, arenas and other allocation tricks.                     In Boost.Interprocess allocators, the           approach is similar, but all allocators are based on the segment           manager. The segment manager is the only one that provides from           simple memory allocation to named object creations. Boost.Interprocess           allocators always store a pointer to the segment manager, so that they           can obtain memory from the segment or share a common pool between allocators.                     As you can imagine, the member pointers of the allocator are not a raw           pointers, but pointer types defined by the segment_manager::void_pointer           type. Apart from this, the pointer           typedef of Boost.Interprocess allocators           is also of the same type of segment_manager::void_pointer.                     This means that if our allocation algorithm defines void_pointer           as offset_ptr&lt;void&gt;,           boost::interprocess::allocator&lt;T&gt;           will store an offset_ptr&lt;segment_manager&gt; to point to the segment manager and           the boost::interprocess::allocator&lt;T&gt;::pointer type will be offset_ptr&lt;T&gt;. This way, Boost.Interprocess           allocators can be placed in the memory segment managed by the segment manager,           that is, shared memory, memory mapped files, etc...             Implementation         of Boost.Interprocess segregated storage         pools             Segregated storage pools are simple and follow the classic segregated storage           algorithm.                          The pool allocates chunks of memory using the segment manager's raw               memory allocation functions.                             The chunk contains a pointer to form a singly linked list of chunks.               The pool will contain a pointer to the first chunk.                             The rest of the memory of the chunk is divided in nodes of the requested               size and no memory is used as payload for each node. Since the memory               of a free node is not used that memory is used to place a pointer to               form a singly linked list of free nodes. The pool has a pointer to               the first free node.                             Allocating a node is just taking the first free node from the list.               If the list is empty, a new chunk is allocated, linked in the list               of chunks and the new free nodes are linked in the free node list.                             Deallocation returns the node to the free node list.                             When the pool is destroyed, the list of chunks is traversed and memory               is returned to the segment manager.                          The pool is implemented by the private_node_pool           and shared_node_pool classes.             Implementation         of Boost.Interprocess adaptive pools             Adaptive pools are a variation of segregated lists but they have a more           complicated approach:                          Instead of using raw allocation, the pool allocates aligned               chunks of memory using the segment manager. This is an essential               feature since a node can reach its chunk information applying a simple               mask to its address.                             The chunks contains pointers to form a doubly linked list of chunks               and an additional pointer to create a singly linked list of free nodes               placed on that chunk. So unlike the segregated storage algorithm, the               free list of nodes is implemented per chunk.                             The pool maintains the chunks in increasing order of free nodes. This               improves locality and minimizes the dispersion of node allocations               across the chunks facilitating the creation of totally free chunks.                             The pool has a pointer to the chunk with the minimum (but not zero)               free nodes. This chunk is called the "active" chunk.                             Allocating a node is just returning the first free node of the "active"               chunk. The list of chunks is reordered according to the free nodes               count. The pointer to the "active" pool is updated if necessary.                             If the pool runs out of nodes, a new chunk is allocated, and pushed               back in the list of chunks. The pointer to the "active" pool               is updated if necessary.                             Deallocation returns the node to the free node list of its chunk and               updates the "active" pool accordingly.                             If the number of totally free chunks exceeds the limit, chunks are               returned to the segment manager.                             When the pool is destroyed, the list of chunks is traversed and memory               is returned to the segment manager.                          The adaptive pool is implemented by the private_adaptive_node_pool           and adaptive_node_pool classes.             Boost.Interprocess         containers             Boost.Interprocess containers are standard           conforming counterparts of STL containers in boost::interprocess           namespace, but with these little details:                          Boost.Interprocess STL containers               don't assume that memory allocated with an allocator can be deallocated               with other allocator of the same type. They always compare allocators               with operator==()               to know if this is possible.                             The pointers of the internal structures of the Boost.Interprocess               containers are of the same type the pointer               type defined by the allocator of the container. This allows placing               containers in managed memory segments mapped in different base addresses.                   Performance of       Boost.Interprocess   Performance         of raw memory allocations Performance         of named allocations           This section tries to explain the performance characteristics of Boost.Interprocess, so that you can optimize Boost.Interprocess usage if you need more performance.          Performance         of raw memory allocations             You can have two types of raw memory allocations with Boost.Interprocess           classes:                          Explicit: The user calls allocate()               and deallocate()               functions of managed_shared_memory/managed_mapped_file... managed memory               segments. This call is translated to a MemoryAlgorithm::allocate() function, which means that you will               need just the time that the memory algorithm associated with the managed               memory segment needs to allocate data.                             Implicit: For example, you are using               boost::interprocess::allocator&lt;...&gt;               with Boost.Interprocess containers.               This allocator calls the same MemoryAlgorithm::allocate() function than the explicit method,               every time a vector/string has to               reallocate its buffer or every time               you insert an object in a node container.                          If you see that memory allocation is a bottleneck in your application,           you have these alternatives:                          If you use map/set associative containers, try using flat_map family instead of the map               family if you mainly do searches and the insertion/removal is mainly               done in an initialization phase. The overhead is now when the ordered               vector has to reallocate its storage and move data. You can also call               the reserve()               method of these containers when you know beforehand how much data you               will insert. However in these containers iterators are invalidated               in insertions so this substitution is only effective in some applications.                             Use a Boost.Interprocess pooled allocator               for node containers, because pooled allocators call allocate() only when the pool runs out of nodes.               This is pretty efficient (much more than the current default general-purpose               algorithm) and this can save a lot of memory. See Segregated               storage node allocators and Adaptive               node allocators for more information.                             Write your own memory algorithm. If you have experience with memory               allocation algorithms and you think another algorithm is better suited               than the default one for your application, you can specify it in all               Boost.Interprocess managed memory               segments. See the section Writing               a new shared memory allocation algorithm to know how to do this.               If you think its better than the default one for general-purpose applications,               be polite and donate it to Boost.Interprocess               to make it default!                  Performance         of named allocations             Boost.Interprocess allows the same parallelism           as two threads writing to a common structure, except when the user creates/searches           named/unique objects. The steps when creating a named object are these:                          Lock a recursive mutex (so that you can make named allocations inside               the constructor of the object to be created).                             Try to insert the [name pointer, object information] in the name/object               index. This lookup has to assure that the name has not been used before.               This is achieved calling insert() function in the index. So the time               this requires is dependent on the index type (ordered vector, tree,               hash...). This can require a call to the memory algorithm allocation               function if the index has to be reallocated, it's a node allocator,               uses pooled allocations...                             Allocate a single buffer to hold the name of the object, the object               itself, and meta-data for destruction (number of objects, etc...).                             Call the constructors of the object being created. If it's an array,               one construtor per array element.                             Unlock the recursive mutex.                          The steps when destroying a named object using the name of the object (destroy&lt;T&gt;(name))           are these:                          Lock a recursive mutex .                             Search in the index the entry associated to that name. Copy that information               and erase the index entry. This is done using find(const key_type &amp;)               and erase(iterator)               members of the index. This can require element reordering if the index               is a balanced tree, an ordered vector...                             Call the destructor of the object (many if it's an array).                             Deallocate the memory buffer containing the name, metadata and the               object itself using the allocation algorithm.                             Unlock the recursive mutex.                          The steps when destroying a named object using the pointer of the object           (destroy_ptr(T *ptr)) are these:                          Lock a recursive mutex .                             Depending on the index type, this can be different:                                     If the index is a node index, (marked with boost::interprocess::is_node_index                     specialization): Take the iterator stored near the object and                     call erase(iterator).                     This can require element reordering if the index is a balanced                     tree, an ordered vector...                                         If it's not an node index: Take the name stored near the object                     and erase the index entry calling `erase(const key &amp;). This                     can require element reordering if the index is a balanced tree,                     an ordered vector...                                                 Call the destructor of the object (many if it's an array).                             Deallocate the memory buffer containing the name, metadata and the               object itself using the allocation algorithm.                             Unlock the recursive mutex.                          If you see that the performance is not good enough you have these alternatives:                          Maybe the problem is that the lock time is too big and it hurts parallelism.               Try to reduce the number of named objects in the global index and if               your application serves several clients try to build a new managed               memory segment for each one instead of using a common one.                             Use another Boost.Interprocess index               type if you feel the default one is not fast enough. If you are not               still satisfied, write your own index type. See Building               custom indexes for this.                             Destruction via pointer is at least as fast as using the name of the               object and can be faster (in node containers, for example). So if your               problem is that you make at lot of named destructions, try to use the               pointer. If the index is a node index you can save some time.                    Copyright &#169; 2005-2012 Ion Gaztanaga         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3217weight: 2
tittle: Managed Memory Segments
url :https://www.boost.org/doc/libs/1_53_0/doc/html/interprocess/managed_memory_segments.html
content:    Managed Memory Segments           Home Libraries People FAQ More        Managed Memory Segments   Making       Interprocess Data Communication Easy Managed       Shared Memory Managed       Mapped File Managed       Memory Segment Features Managed       Memory Segment Advanced Features Managed       Heap Memory And Managed External Buffer    Making       Interprocess Data Communication Easy   Introduction Declaration         of managed memory segment classes    Introduction             As we have seen, Boost.Interprocess offers           some basic classes to create shared memory objects and file mappings and           map those mappable classes to the process' address space.                     However, managing those memory segments is not not easy for non-trivial           tasks. A mapped region is a fixed-length memory buffer and creating and           destroying objects of any type dynamically, requires a lot of work, since           it would require programming a memory management algorithm to allocate           portions of that segment. Many times, we also want to associate names to           objects created in shared memory, so all the processes can find the object           using the name.                     Boost.Interprocess offers 4 managed memory           segment classes:                          To manage a shared memory mapped region (basic_managed_shared_memory               class).                             To manage a memory mapped file (basic_managed_mapped_file).                             To manage a heap allocated (operator               new) memory buffer (basic_managed_heap_memory class).                             To manage a user provided fixed size buffer (basic_managed_external_buffer               class).                          The first two classes manage memory segments that can be shared between           processes. The third is useful to create complex data-bases to be sent           though other mechanisms like message queues to other processes. The fourth           class can manage any fixed size memory buffer. The first two classes will           be explained in the next two sections. basic_managed_heap_memory           and basic_managed_external_buffer will           be explained later.                     The most important services of a managed memory segment are:                          Dynamic allocation of portions of a memory the segment.                             Construction of C++ objects in the memory segment. These objects can               be anonymous or we can associate a name to them.                             Searching capabilities for named objects.                             Customization of many features: memory allocation algorithm, index               types or character types.                             Atomic constructions and destructions so that if the segment is shared               between two processes it's impossible to create two objects associated               with the same name, simplifying synchronization.                  Declaration         of managed memory segment classes             All Boost.Interprocess managed memory           segment classes are templatized classes that can be customized by the user:          template       &lt;          class CharType,          class MemoryAlgorithm,          template&lt;class IndexConfig&gt; class IndexType       &gt; class basic_managed_shared_memory / basic_managed_mapped_file /       basic_managed_heap_memory   / basic_external_buffer;             These classes can be customized with the following template parameters:                          CharType is the type of the character               that will be used to identify the created named objects (for example,               char or wchar_t)                             MemoryAlgorithm is the memory algorithm               used to allocate portions of the segment (for example, rbtree_best_fit               ). The internal typedefs of the memory algorithm also define:                                     The synchronization type (MemoryAlgorithm::mutex_family)                     to be used in all allocation operations. This allows the use                     of user-defined mutexes or avoiding internal locking (maybe code                     will be externally synchronized by the user).                                         The Pointer type (MemoryAlgorithm::void_pointer)                     to be used by the memory allocation algorithm or additional helper                     structures (like a map to maintain object/name associations).                     All STL compatible allocators and containers to be used with                     this managed memory segment will use this pointer type. The pointer                     type will define if the managed memory segment can be mapped                     between several processes. For example, if void_pointer                     is offset_ptr&lt;void&gt; we will be able to map the                     managed segment in different base addresses in each process.                     If void_pointer                     is void*                     only fixed address mapping could be used.                                         See Writing                     a new memory allocation algorithm for more details about                     memory algorithms.                                                 IndexType is the type of index that               will be used to store the name-object association (for example, a map,               a hash-map, or an ordered vector).                          This way, we can use char           or wchar_t strings to identify           created C++ objects in the memory segment, we can plug new shared memory           allocation algorithms, and use the index type that is best suited to our           needs.              Managed       Shared Memory   Common         Managed Shared Memory Classes Constructing         Managed Shared Memory Using         native windows shared memory Using         XSI (system V) shared memory    Common         Managed Shared Memory Classes             As seen, basic_managed_shared_memory offers           a great variety of customization. But for the average user, a common, default           shared memory named object creation is needed. Because of this, Boost.Interprocess defines the most common managed           shared memory specializations:          //!Defines a managed shared memory with c-strings as keys for named objects, //!the default memory algorithm (with process-shared mutexes, //!and offset_ptr as internal pointers) as memory allocation algorithm //!and the default index type as the index. //!This class allows the shared memory to be mapped in different base //!in different processes typedef    basic_managed_shared_memory&lt;char                               ,/*Default memory algorithm defining offset_ptr&lt;void&gt; as void_pointer*/                               ,/*Default index type*/&gt;    managed_shared_memory;  //!Defines a managed shared memory with wide strings as keys for named objects, //!the default memory algorithm (with process-shared mutexes, //!and offset_ptr as internal pointers) as memory allocation algorithm //!and the default index type as the index. //!This class allows the shared memory to be mapped in different base //!in different processes typedef    basic_managed_shared_memory&lt;wchar_t                               ,/*Default memory algorithm defining offset_ptr&lt;void&gt; as void_pointer*/                               ,/*Default index type*/&gt;    wmanaged_shared_memory;             managed_shared_memory allocates           objects in shared memory associated with a c-string and wmanaged_shared_memory           allocates objects in shared memory associated with a wchar_t null terminated           string. Both define the pointer type as offset_ptr&lt;void&gt; so they can be used to map the shared           memory at different base addresses in different processes.                     If the user wants to map the shared memory in the same address in all processes           and want to use raw pointers internally instead of offset pointers, Boost.Interprocess defines the following types:          //!Defines a managed shared memory with c-strings as keys for named objects, //!the default memory algorithm (with process-shared mutexes, //!and offset_ptr as internal pointers) as memory allocation algorithm //!and the default index type as the index. //!This class allows the shared memory to be mapped in different base //!in different processes*/ typedef basic_managed_shared_memory    &lt;char    ,/*Default memory algorithm defining void * as void_pointer*/    ,/*Default index type*/&gt; fixed_managed_shared_memory;  //!Defines a managed shared memory with wide strings as keys for named objects, //!the default memory algorithm (with process-shared mutexes, //!and offset_ptr as internal pointers) as memory allocation algorithm //!and the default index type as the index. //!This class allows the shared memory to be mapped in different base //!in different processes typedef basic_managed_shared_memory    &lt;wchar_t    ,/*Default memory algorithm defining void * as void_pointer*/    ,/*Default index type*/&gt; wfixed_managed_shared_memory;     Constructing         Managed Shared Memory             Managed shared memory is an advanced class that combines a shared memory           object and a mapped region that covers all the shared memory object. That           means that when we create a new managed           shared memory:                          A new shared memory object is created.                             The whole shared memory object is mapped in the process' address space.                             Some helper objects are constructed (name-object index, internal synchronization               objects, internal variables...) in the mapped region to implement managed               memory segment features.                          When we open a managed shared memory                          A shared memory object is opened.                             The whole shared memory object is mapped in the process' address space.                          To use a managed shared memory, you must include the following header:          #include &lt;boost/interprocess/managed_shared_memory.hpp&gt;  //1.  Creates a new shared memory object //    called "MySharedMemory". //2.  Maps the whole object to this //    process' address space. //3.  Constructs some objects in shared memory //    to implement managed features. //!!  If anything fails, throws interprocess_exception // managed_shared_memory segment      ( create_only                                    , "MySharedMemory" //Shared memory object name                                    , 65536);          //Shared memory object size in bytes  //1.  Opens a shared memory object //    called "MySharedMemory". //2.  Maps the whole object to this //    process' address space. //3.  Obtains pointers to constructed internal objects //    to implement managed features. //!!  If anything fails, throws interprocess_exception // managed_shared_memory segment      (open_only,       "MySharedMemory");//Shared memory object name  //1.  If the segment was previously created //    equivalent to "open_only" (size is ignored). //2.  Otherwise, equivalent to "create_only" //!!  If anything fails, throws interprocess_exception // managed_shared_memory segment      ( open_or_create                                    , "MySharedMemory" //Shared memory object name                                    , 65536);          //Shared memory object size in bytes             When the managed_shared_memory           object is destroyed, the shared memory object is automatically unmapped,           and all the resources are freed. To remove the shared memory object from           the system you must use the shared_memory_object::remove           function. Shared memory object removing might fail if any process still           has the shared memory object mapped.                     The user can also map the managed shared memory in a fixed address. This           option is essential when using using fixed_managed_shared_memory.           To do this, just add the mapping address as an extra parameter:          fixed_managed_shared_memory segment      (open_only      ,"MyFixedAddressSharedMemory" //Shared memory object name    ,(void*)0x30000000            //Mapping address     Using         native windows shared memory             Windows users might also want to use native windows shared memory instead           of the portable shared_memory_object           managed memory. This is achieved through the basic_managed_windows_shared_memory           class. To use it just include:          #include &lt;boost/interprocess/managed_windows_shared_memory.hpp&gt;             This class has the same interface as basic_managed_shared_memory           but uses native windows shared memory. Note that this managed class has           the same lifetime issues as the windows shared memory: when the last process           attached to the windows shared memory is detached from the memory (or ends/crashes)           the memory is destroyed. So there is no persistence support for windows           shared memory.                     To communicate between system services and user applications using managed_windows_shared_memory, please           read the explanations given in chapter Native           windows shared memory.             Using         XSI (system V) shared memory             Unix users might also want to use XSI (system V) instead of the portable           shared_memory_object           managed memory. This is achieved through the basic_managed_xsi_shared_memory           class. To use it just include:          #include &lt;boost/interprocess/managed_xsi_shared_memory.hpp&gt;             This class has nearly the same interface as basic_managed_shared_memory           but uses XSI shared memory as backend.                    For more information about managed XSI shared memory capabilities, see basic_managed_xsi_shared_memory         class reference.           Managed       Mapped File   Common         Managed Mapped Files Constructing         Managed Mapped Files    Common         Managed Mapped Files             As seen, basic_managed_mapped_file offers           a great variety of customization. But for the average user, a common, default           shared memory named object creation is needed. Because of this, Boost.Interprocess defines the most common managed           mapped file specializations:          //Named object creation managed memory segment //All objects are constructed in the memory-mapped file //   Names are c-strings, //   Default memory management algorithm(rbtree_best_fit with no mutexes) //   Name-object mappings are stored in the default index type (flat_map) typedef basic_managed_mapped_file &lt;    char,    rbtree_best_fit&lt;mutex_family, offset_ptr&lt;void&gt; &gt;,    flat_map_index    &gt;  managed_mapped_file;  //Named object creation managed memory segment //All objects are constructed in the memory-mapped file //   Names are wide-strings, //   Default memory management algorithm(rbtree_best_fit with no mutexes) //   Name-object mappings are stored in the default index type (flat_map) typedef basic_managed_mapped_file&lt;    wchar_t,    rbtree_best_fit&lt;mutex_family, offset_ptr&lt;void&gt; &gt;,    flat_map_index    &gt;  wmanaged_mapped_file;             managed_mapped_file allocates           objects in a memory mapped files associated with a c-string and wmanaged_mapped_file allocates objects           in a memory mapped file associated with a wchar_t null terminated string.           Both define the pointer type as offset_ptr&lt;void&gt; so they can be used to map the file           at different base addresses in different processes.             Constructing         Managed Mapped Files             Managed mapped file is an advanced class that combines a file and a mapped           region that covers all the file. That means that when we create           a new managed mapped file:                          A new file is created.                             The whole file is mapped in the process' address space.                             Some helper objects are constructed (name-object index, internal synchronization               objects, internal variables...) in the mapped region to implement managed               memory segment features.                          When we open a managed mapped file                          A file is opened.                             The whole file is mapped in the process' address space.                          To use a managed mapped file, you must include the following header:          #include &lt;boost/interprocess/managed_mapped_file.hpp&gt;  //1.  Creates a new file //    called "MyMappedFile". //2.  Maps the whole file to this //    process' address space. //3.  Constructs some objects in the memory mapped //    file to implement managed features. //!!  If anything fails, throws interprocess_exception // managed_mapped_file mfile      (create_only,      "MyMappedFile",   //Mapped file name      65536);           //Mapped file size  //1.  Opens a file //    called "MyMappedFile". //2.  Maps the whole file to this //    process' address space. //3.  Obtains pointers to constructed internal objects //    to implement managed features. //!!  If anything fails, throws interprocess_exception // managed_mapped_file mfile      (open_only,      "MyMappedFile");  //Mapped file name[c++]  //1.  If the file was previously created //    equivalent to "open_only". //2.  Otherwise, equivalent to "open_only" (size is ignored) // //!!  If anything fails, throws interprocess_exception // managed_mapped_file mfile      (open_or_create,      "MyMappedFile",   //Mapped file name      65536);           //Mapped file size             When the managed_mapped_file           object is destroyed, the file is automatically unmapped, and all the resources           are freed. To remove the file from the filesystem you could use standard           C std::remove or Boost.Filesystem's           remove()           functions, but file removing might fail if any process still has the file           mapped in memory or the file is open by any process.                     To obtain a more portable behaviour, use file_mapping::remove(const char *)           operation, which will remove the file even if it's being mapped. However,           removal will fail in some OS systems if the file (eg. by C++ file streams)           and no delete share permission was granted to the file. But in most common           cases file_mapping::remove is portable enough.                    For more information about managed mapped file capabilities, see basic_managed_mapped_file         class reference.           Managed       Memory Segment Features   Allocating         fragments of a managed memory segment Obtaining         handles to identify data Object         construction function family Anonymous         instance construction Unique         instance construction Synchronization         guarantees Index         types for name/object mappings Segment         Manager Obtaining         information about a constructed object Executing         an object function atomically           The following features are common to all managed memory segment classes,         but we will use managed shared memory in our examples. We can do the same         with memory mapped files or other managed memory segment classes.          Allocating         fragments of a managed memory segment             If a basic raw-byte allocation is needed from a managed memory segment,           (for example, a managed shared memory), to implement top-level interprocess           communications, this class offers allocate           and deallocate functions. The allocation           function comes with throwing and no throwing versions. Throwing version           throws boost::interprocess::bad_alloc (which derives from std::bad_alloc) if there is no more memory           and the non-throwing version returns 0 pointer.            #include &lt;boost/interprocess/managed_shared_memory.hpp&gt;  int main() {    using namespace boost::interprocess;     //Remove shared memory on construction and destruction    struct shm_remove    {       shm_remove() { shared_memory_object::remove("MySharedMemory"); }       ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }    } remover;     //Managed memory segment that allocates portions of a shared memory    //segment with the default management algorithm    managed_shared_memory managed_shm(create_only,"MySharedMemory", 65536);     //Allocate 100 bytes of memory from segment, throwing version    void *ptr = managed_shm.allocate(100);     //Deallocate it    managed_shm.deallocate(ptr);     //Non throwing version    ptr = managed_shm.allocate(100, std::nothrow);     //Deallocate it    managed_shm.deallocate(ptr);    return 0; }               Obtaining         handles to identify data             The class also offers conversions between absolute addresses that belong           to a managed memory segment and a handle that can be passed using any interprocess           mechanism. That handle can be transformed again to an absolute address           using a managed memory segment that also contains that object. Handles           can be used as keys between processes to identify allocated portions of           a managed memory segment or objects constructed in the managed segment.          //Process A obtains the offset of the address managed_shared_memory::handle handle =    segment.get_handle_from_address(processA_address);  //Process A sends this address using any mechanism to process B  //Process B obtains the handle and transforms it again to an address managed_shared_memory::handle handle = ... void * processB_address = segment.get_address_from_handle(handle);     Object         construction function family             When constructing objects in a managed memory segment (managed shared memory,           managed mapped files...) associated with a name, the user has a varied           object construction family to "construct" or to "construct           if not found". Boost.Interprocess           can construct a single object or an array of objects. The array can be           constructed with the same parameters for all objects or we can define each           parameter from a list of iterators:          //!Allocates and constructs an object of type MyType (throwing version) MyType *ptr = managed_memory_segment.construct&lt;MyType&gt;("Name") (par1, par2...);  //!Allocates and constructs an array of objects of type MyType (throwing version) //!Each object receives the same parameters (par1, par2, ...) MyType *ptr = managed_memory_segment.construct&lt;MyType&gt;("Name")[count](par1, par2...);  //!Tries to find a previously created object. If not present, allocates //!and constructs an object of type MyType (throwing version) MyType *ptr = managed_memory_segment.find_or_construct&lt;MyType&gt;("Name") (par1, par2...);  //!Tries to find a previously created object. If not present, allocates and //!constructs an array of objects of type MyType (throwing version). Each object //!receives the same parameters (par1, par2, ...) MyType *ptr = managed_memory_segment.find_or_construct&lt;MyType&gt;("Name")[count](par1, par2...);  //!Allocates and constructs an array of objects of type MyType (throwing version) //!Each object receives parameters returned with the expression (*it1++, *it2++,... ) MyType *ptr = managed_memory_segment.construct_it&lt;MyType&gt;("Name")[count](it1, it2...);  //!Tries to find a previously created object. If not present, allocates and constructs //!an array of objects of type MyType (throwing version).  Each object receives //!parameters returned with the expression (*it1++, *it2++,... ) MyType *ptr = managed_memory_segment.find_or_construct_it&lt;MyType&gt;("Name")[count](it1, it2...);  //!Tries to find a previously created object. Returns a pointer to the object and the //!count (if it is not an array, returns 1). If not present, the returned pointer is 0 std::pair&lt;MyType *,std::size_t&gt; ret = managed_memory_segment.find&lt;MyType&gt;("Name");  //!Destroys the created object, returns false if not present bool destroyed = managed_memory_segment.destroy&lt;MyType&gt;("Name");  //!Destroys the created object via pointer managed_memory_segment.destroy_ptr(ptr);             All these functions have a non-throwing version, that is invoked with an           additional parameter std::nothrow. For example, for simple object construction:          //!Allocates and constructs an object of type MyType (no throwing version) MyType *ptr = managed_memory_segment.construct&lt;MyType&gt;("Name", std::nothrow) (par1, par2...);     Anonymous         instance construction             Sometimes, the user doesn't want to create class objects associated with           a name. For this purpose, Boost.Interprocess           can create anonymous objects in a managed memory segment. All named object           construction functions are available to construct anonymous objects. To           allocate an anonymous objects, the user must use "boost::interprocess::anonymous_instance"           name instead of a normal name:          MyType *ptr = managed_memory_segment.construct&lt;MyType&gt;(anonymous_instance) (par1, par2...);  //Other construct variants can also be used (including non-throwing ones) ...  //We can only destroy the anonymous object via pointer managed_memory_segment.destroy_ptr(ptr);             Find functions have no sense here, since anonymous objects have no name.           We can only destroy the anonymous object via pointer.             Unique         instance construction             Sometimes, the user wants to emulate a singleton in a managed memory segment.           Obviously, as the managed memory segment is constructed at run-time, the           user must construct and destroy this object explicitly. But how can the           user be sure that the object is the only object of its type in the managed           memory segment? This can be emulated using a named object and checking           if it is present before trying to create one, but all processes must agree           in the object's name, that can also conflict with other existing names.                     To solve this, Boost.Interprocess offers           a "unique object" creation in a managed memory segment. Only           one instance of a class can be created in a managed memory segment using           this "unique object" service (you can create more named objects           of this class, though) so it makes easier the emulation of singleton-like           objects across processes, for example, to design pooled, shared memory           allocators. The object can be searched using the type of the class as a           key.          // Construct MyType *ptr = managed_memory_segment.construct&lt;MyType&gt;(unique_instance) (par1, par2...);  // Find it std::pair&lt;MyType *,std::size_t&gt; ret = managed_memory_segment.find&lt;MyType&gt;(unique_instance);  // Destroy it managed_memory_segment.destroy&lt;MyType&gt;(unique_instance);  // Other construct and find variants can also be used (including non-throwing ones) //...  // We can also destroy the unique object via pointer MyType *ptr = managed_memory_segment.construct&lt;MyType&gt;(unique_instance) (par1, par2...); managed_shared_memory.destroy_ptr(ptr);             The find function obtains a pointer to the only object of type T that can           be created using this "unique instance" mechanism.             Synchronization         guarantees             One of the features of named/unique allocations/searches/destructions is           that they are atomic. Named allocations           use the recursive synchronization scheme defined by the internal mutex_family typedef defined of the memory           allocation algorithm template parameter (MemoryAlgorithm).           That is, the mutex type used to synchronize named/unique allocations is           defined by the MemoryAlgorithm::mutex_family::recursive_mutex_type           type. For shared memory, and memory mapped file based managed segments           this recursive mutex is defined as interprocess_recursive_mutex.                     If two processes can call:          MyType *ptr = managed_shared_memory.find_or_construct&lt;MyType&gt;("Name")[count](par1, par2...);             at the same time, but only one process will create the object and the other           will obtain a pointer to the created object.                     Raw allocation using allocate() can be called also safely while executing           named/anonymous/unique allocations, just like when programming a multithreaded           application inserting an object in a mutex-protected map does not block           other threads from calling new[] while the map thread is searching the           place where it has to insert the new object. The synchronization does happen           once the map finds the correct place and it has to allocate raw memory           to construct the new value.                     This means that if we are creating or searching for a lot of named objects,           we only block creation/searches from other processes but we don't block           another process if that process is inserting elements in a shared memory           vector.             Index         types for name/object mappings             As seen, managed memory segments, when creating named objects, store the           name/object association in an index. The index is a map with the name of           the object as a key and a pointer to the object as the mapped type. The           default specializations, managed_shared_memory           and wmanaged_shared_memory, use flat_map_index as the index type.                     Each index has its own characteristics, like search-time, insertion time,           deletion time, memory use, and memory allocation patterns. Boost.Interprocess           offers 3 index types right now:                          boost::interprocess::flat_map_index flat_map_index:               Based on boost::interprocess::flat_map, an ordered vector similar to               Loki library's AssocVector class, offers great search time and minimum               memory use. But the vector must be reallocated when is full, so all               data must be copied to the new buffer. Ideal when insertions are mainly               in initialization time and in run-time we just need searches.                             boost::interprocess::map_index map_index:               Based on boost::interprocess::map, a managed memory ready version of               std::map. Since it's a node based container, it has no reallocations,               the tree must be just rebalanced sometimes. Offers equilibrated insertion/deletion/search               times with more overhead per node comparing to boost::interprocess::flat_map_index.               Ideal when searches/insertions/deletions are in random order.                             boost::interprocess::null_index null_index:               This index is for people using a managed memory segment just for raw               memory buffer allocations and they don't make use of named/unique allocations.               This class is just empty and saves some space and compilation time.               If you try to use named object creation with a managed memory segment               using this index, you will get a compilation error.                          As an example, if we want to define new managed shared memory class using           boost::interprocess::map as the index           type we just must specify [boost::interprocess::map_index map_index] as           a template parameter:          //This managed memory segment can allocate objects with: // -&gt; a wchar_t string as key // -&gt; boost::interprocess::rbtree_best_fit with process-shared mutexes //       as memory allocation algorithm. // -&gt; boost::interprocess::map&lt;...&gt; as the index to store name/object mappings // typedef boost::interprocess::basic_managed_shared_memory          &lt;  wchar_t          ,  boost::interprocess::rbtree_best_fit&lt;boost::interprocess::mutex_family, offset_ptr&lt;void&gt; &gt;          ,  boost::interprocess::map_index          &gt;  my_managed_shared_memory;             Boost.Interprocess plans to offer an           unordered_map based index as soon as this           container is included in Boost. If these indexes are not enough for you,           you can define your own index type. To know how to do this, go to Building           custom indexes section.             Segment         Manager             All Boost.Interprocess managed memory           segment classes construct in their respective memory segments (shared memory,           memory mapped files, heap memory...) some structures to implement the memory           management algorithm, named allocations, synchronization objects... All           these objects are encapsulated in a single object called segment           manager. A managed memory mapped file and a managed shared memory           use the same segment manager to implement           all managed memory segment features, due to the fact that a segment           manager is a class that manages a fixed size memory buffer.           Since both shared memory or memory mapped files are accessed though a mapped           region, and a mapped region is a fixed size memory buffer, a single segment manager class can manage several managed           memory segment types.                     Some Boost.Interprocess classes require           a pointer to the segment manager in their constructors, and the segment           manager can be obtained from any managed memory segment using get_segment_manager member:          managed_shared_memory::segment_manager *seg_manager =    managed_shm.get_segment_manager();     Obtaining         information about a constructed object             Once an object is constructed using construct&lt;&gt; function family, the programmer           can obtain information about the object using a pointer to the object.           The programmer can obtain the following information:                          Name of the object: If it's a named instance, the name used in the               construction function is returned, otherwise 0 is returned.                             Length of the object: Returns the number of elements of the object               (1 if it's a single value, &gt;=1 if it's an array).                             The type of construction: Whether the object was constructed using               a named, unique or anonymous construction.                          Here is an example showing this functionality:            #include &lt;boost/interprocess/managed_shared_memory.hpp&gt; #include &lt;cassert&gt; #include &lt;cstring&gt;  class my_class {    //... };  int main() {    using namespace boost::interprocess;     //Remove shared memory on construction and destruction    struct shm_remove    {       shm_remove() { shared_memory_object::remove("MySharedMemory"); }       ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }    } remover;     managed_shared_memory managed_shm(create_only, "MySharedMemory", 10000*sizeof(std::size_t));     //Construct objects    my_class *named_object  = managed_shm.construct&lt;my_class&gt;("Object name")[1]();    my_class *unique_object = managed_shm.construct&lt;my_class&gt;(unique_instance)[2]();    my_class *anon_object   = managed_shm.construct&lt;my_class&gt;(anonymous_instance)[3]();     //Now test "get_instance_name" function.    assert(0 == std::strcmp(managed_shared_memory::get_instance_name(named_object), "Object name"));    assert(0 == managed_shared_memory::get_instance_name(unique_object));    assert(0 == managed_shared_memory::get_instance_name(anon_object));     //Now test "get_instance_type" function.    assert(named_type     == managed_shared_memory::get_instance_type(named_object));    assert(unique_type    == managed_shared_memory::get_instance_type(unique_object));    assert(anonymous_type == managed_shared_memory::get_instance_type(anon_object));     //Now test "get_instance_length" function.    assert(1 == managed_shared_memory::get_instance_length(named_object));    assert(2 == managed_shared_memory::get_instance_length(unique_object));    assert(3 == managed_shared_memory::get_instance_length(anon_object));     managed_shm.destroy_ptr(named_object);    managed_shm.destroy_ptr(unique_object);    managed_shm.destroy_ptr(anon_object);    return 0; }               Executing         an object function atomically             Sometimes the programmer must execute some code, and needs to execute it           with the guarantee that no other process or thread will create or destroy           any named, unique or anonymous object while executing the functor. A user           might want to create several named objects and initialize them, but those           objects should be available for the rest of processes at once.                     To achieve this, the programmer can use the atomic_func() function offered by managed classes:          //This object function will create several named objects create_several_objects_func func(/**/);  //While executing the function, no other process will be //able to create or destroy objects managed_memory.atomic_func(func);             Note that atomic_func does           not prevent other processes from allocating raw memory or executing member           functions for already constructed objects (e.g.: another process might           be pushing elements into a vector placed in the segment). The atomic function           only blocks named, unique and anonymous creation, search and destruction           (concurrent calls to construct&lt;&gt;, find&lt;&gt;, find_or_construct&lt;&gt;, destroy&lt;&gt;...) from other processes.              Managed       Memory Segment Advanced Features   Obtaining         information about the managed segment Growing         managed segments Advanced         index functions Allocating         aligned memory portions Multiple         allocation functions Expand         in place memory allocation Opening         managed shared memory and mapped files with Copy On Write or Read Only modes    Obtaining         information about the managed segment             These functions are available to obtain information about the managed memory           segments:                     Obtain the size of the memory segment:          managed_shm.get_size();             Obtain the number of free bytes of the segment:          managed_shm.get_free_memory();             Clear to zero the free memory:          managed_shm.zero_free_memory();             Know if all memory has been deallocated, false otherwise:          managed_shm.all_memory_deallocated();             Test internal structures of the managed segment. Returns true if no errors           are detected:          managed_shm.check_sanity();             Obtain the number of named and unique objects allocated in the segment:          managed_shm.get_num_named_objects(); managed_shm.get_num_unique_objects();     Growing         managed segments             Once a managed segment is created the managed segment can't be grown. The           limitation is not easily solvable: every process attached to the managed           segment would need to be stopped, notified of the new size, they would           need to remap the managed segment and continue working. Nearly impossible           to achieve with a user-level library without the help of the operating           system kernel.                     On the other hand, Boost.Interprocess           offers off-line segment growing. What does this mean? That the segment           can be grown if no process has mapped the managed segment. If the application           can find a moment where no process is attached it can grow or shrink to           fit the managed segment.                     Here we have an example showing how to grow and shrink to fit managed_shared_memory:            #include &lt;boost/interprocess/managed_shared_memory.hpp&gt; #include &lt;boost/interprocess/managed_mapped_file.hpp&gt; #include &lt;cassert&gt;  class MyClass {    //... };  int main() {    using namespace boost::interprocess;    //Remove shared memory on construction and destruction    struct shm_remove    {       shm_remove() { shared_memory_object::remove("MySharedMemory"); }       ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }    } remover;     {       //Create a managed shared memory       managed_shared_memory shm(create_only, "MySharedMemory", 1000);        //Check size       assert(shm.get_size() == 1000);       //Construct a named object       MyClass *myclass = shm.construct&lt;MyClass&gt;("MyClass")();       //The managed segment is unmapped here    }    {       //Now that the segment is not mapped grow it adding extra 500 bytes       managed_shared_memory::grow("MySharedMemory", 500);        //Map it again       managed_shared_memory shm(open_only, "MySharedMemory");       //Check size       assert(shm.get_size() == 1500);       //Check "MyClass" is still there       MyClass *myclass = shm.find&lt;MyClass&gt;("MyClass").first;       assert(myclass != 0);       //The managed segment is unmapped here    }    {       //Now minimize the size of the segment       managed_shared_memory::shrink_to_fit("MySharedMemory");        //Map it again       managed_shared_memory shm(open_only, "MySharedMemory");       //Check size       assert(shm.get_size() &lt; 1000);       //Check "MyClass" is still there       MyClass *myclass = shm.find&lt;MyClass&gt;("MyClass").first;       assert(myclass != 0);       //The managed segment is unmapped here    }    return 0; }                       managed_mapped_file           also offers a similar function to grow or shrink_to_fit the managed file.           Please, remember that no process should be modifying           the file/shared memory while the growing/shrinking process is performed.           Otherwise, the managed segment will be corrupted.             Advanced         index functions             As mentioned, the managed segment stores the information about named and           unique objects in two indexes. Depending on the type of those indexes,           the index must reallocate some auxiliary structures when new named or unique           allocations are made. For some indexes, if the user knows how many named           or unique objects are going to be created it's possible to preallocate           some structures to obtain much better performance. (If the index is an           ordered vector it can preallocate memory to avoid reallocations. If the           index is a hash structure it can preallocate the bucket array).                     The following functions reserve memory to make the subsequent allocation           of named or unique objects more efficient. These functions are only useful           for pseudo-intrusive or non-node indexes (like flat_map_index,           iunordered_set_index).           These functions have no effect with the default index (iset_index)           or other indexes (map_index):          managed_shm.reserve_named_objects(1000); managed_shm.reserve_unique_objects(1000);  managed_shm.reserve_named_objects(1000); managed_shm.reserve_unique_objects(1000);             Managed memory segments also offer the possibility to iterate through constructed           named and unique objects for debugging purposes. Caution:           this iteration is not thread-safe so the user should make sure           that no other thread is manipulating named or unique indexes (creating,           erasing, reserving...) in the segment. Other operations not involving indexes           can be concurrently executed (raw memory allocation/deallocations, for           example).                     The following functions return constant iterators to the range of named           and unique objects stored in the managed segment. Depending on the index           type, iterators might be invalidated after a named or unique creation/erasure/reserve           operation:          typedef managed_shared_memory::const_named_iterator const_named_it; const_named_it named_beg = managed_shm.named_begin(); const_named_it named_end = managed_shm.named_end();  typedef managed_shared_memory::const_unique_iterator const_unique_it; const_unique_it unique_beg = managed_shm.unique_begin(); const_unique_it unique_end = managed_shm.unique_end();  for(; named_beg != named_end; ++named_beg){    //A pointer to the name of the named object    const managed_shared_memory::char_type *name = named_beg-&gt;name();    //The length of the name    std::size_t name_len = named_beg-&gt;name_length();    //A constant void pointer to the named object    const void *value = named_beg-&gt;value(); }  for(; unique_beg != unique_end; ++unique_beg){    //The typeid(T).name() of the unique object    const char *typeid_name = unique_beg-&gt;name();    //The length of the name    std::size_t name_len = unique_beg-&gt;name_length();    //A constant void pointer to the unique object    const void *value = unique_beg-&gt;value(); }     Allocating         aligned memory portions             Sometimes it's interesting to be able to allocate aligned fragments of           memory because of some hardware or software restrictions. Sometimes, having           aligned memory is a feature that can be used to improve several memory           algorithms.                     This allocation is similar to the previously shown raw memory allocation           but it takes an additional parameter specifying the alignment. There is           a restriction for the alignment: the alignment must           be power of two.                     If a user wants to allocate many aligned blocks (for example aligned to           128 bytes), the size that minimizes the memory waste is a value that's           is nearly a multiple of that alignment (for example 2*128 - some bytes).           The reason for this is that every memory allocation usually needs some           additional metadata in the first bytes of the allocated buffer. If the           user can know the value of "some bytes" and if the first bytes           of a free block of memory are used to fulfill the aligned allocation, the           rest of the block can be left also aligned and ready for the next aligned           allocation. Note that requesting a size multiple           of the alignment is not optimal because lefts the next block           of memory unaligned due to the needed metadata.                     Once the programmer knows the size of the payload of every memory allocation,           he can request a size that will be optimal to allocate aligned chunks of           memory maximizing both the size of the request and           the possibilities of future aligned allocations. This information is stored           in the PayloadPerAllocation constant of managed memory segments.                     Here is a small example showing how aligned allocation is used:            #include &lt;boost/interprocess/managed_shared_memory.hpp&gt; #include &lt;cassert&gt;  int main() {    using namespace boost::interprocess;     //Remove shared memory on construction and destruction    struct shm_remove    {       shm_remove() { shared_memory_object::remove("MySharedMemory"); }       ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }    } remover;     //Managed memory segment that allocates portions of a shared memory    //segment with the default management algorithm    managed_shared_memory managed_shm(create_only, "MySharedMemory", 65536);     const std::size_t Alignment = 128;     //Allocate 100 bytes aligned to Alignment from segment, throwing version    void *ptr = managed_shm.allocate_aligned(100, Alignment);     //Check alignment    assert((static_cast&lt;char*&gt;(ptr)-static_cast&lt;char*&gt;(0)) % Alignment == 0);     //Deallocate it    managed_shm.deallocate(ptr);     //Non throwing version    ptr = managed_shm.allocate_aligned(100, Alignment, std::nothrow);     //Check alignment    assert((static_cast&lt;char*&gt;(ptr)-static_cast&lt;char*&gt;(0)) % Alignment == 0);     //Deallocate it    managed_shm.deallocate(ptr);     //If we want to efficiently allocate aligned blocks of memory    //use managed_shared_memory::PayloadPerAllocation value    assert(Alignment &gt; managed_shared_memory::PayloadPerAllocation);     //This allocation will maximize the size of the aligned memory    //and will increase the possibility of finding more aligned memory    ptr = managed_shm.allocate_aligned       (3*Alignment - managed_shared_memory::PayloadPerAllocation, Alignment);     //Check alignment    assert((static_cast&lt;char*&gt;(ptr)-static_cast&lt;char*&gt;(0)) % Alignment == 0);     //Deallocate it    managed_shm.deallocate(ptr);     return 0; }               Multiple         allocation functions     Caution               This feature is experimental, interface and ABI are unstable                        If an application needs to allocate a lot of memory buffers but it needs           to deallocate them independently, the application is normally forced to           loop calling allocate().           Managed memory segments offer an alternative function to pack several allocations           in a single call obtaining memory buffers that:                          are packed contiguously in memory (which improves locality)                             can be independently deallocated.                          This allocation method is much faster than calling allocate() in a loop. The downside is that the segment           must provide a contiguous memory segment big enough to hold all the allocations.           Managed memory segments offer this functionality through allocate_many()           functions. There are 2 types of allocate_many           functions:                          Allocation of N buffers of memory with the same size.                             Allocation ot N buffers of memory, each one of different size.               //!Allocates n_elements of elem_bytes bytes.  //!Throws bad_alloc on failure. chain.size() is not increased on failure. void allocate_many(size_type elem_bytes, size_type n_elements, multiallocation_chain &amp;chain);  //!Allocates n_elements, each one of element_lengths[i]*sizeof_element bytes. //!Throws bad_alloc on failure. chain.size() is not increased on failure. void allocate_many(const size_type *element_lengths, size_type n_elements, size_type sizeof_element, multiallocation_chain &amp;chain);  //!Allocates n_elements of elem_bytes bytes.  //!Non-throwing version. chain.size() is not increased on failure. void allocate_many(std::nothrow_t, size_type elem_bytes, size_type n_elements, multiallocation_chain &amp;chain);  //!Allocates n_elements, each one of //!element_lengths[i]*sizeof_element bytes. //!Non-throwing version. chain.size() is not increased on failure. void allocate_many(std::nothrow_t, const size_type *elem_sizes, size_type n_elements, size_type sizeof_element, multiallocation_chain &amp;chain);  //!Deallocates all elements contained in chain. //!Never throws. void deallocate_many(multiallocation_chain &amp;chain);             Here is a small example showing all this functionality:            #include &lt;boost/interprocess/managed_shared_memory.hpp&gt; #include &lt;boost/interprocess/detail/move.hpp&gt; //boost::move #include &lt;cassert&gt;//assert #include &lt;cstring&gt;//std::memset #include &lt;new&gt;    //std::nothrow #include &lt;vector&gt; //std::vector  int main() {    using namespace boost::interprocess;    typedef managed_shared_memory::multiallocation_chain multiallocation_chain;     //Remove shared memory on construction and destruction    struct shm_remove    {       shm_remove() { shared_memory_object::remove("MySharedMemory"); }       ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }    } remover;     managed_shared_memory managed_shm(create_only,"MySharedMemory", 65536);     //Allocate 16 elements of 100 bytes in a single call. Non-throwing version.    multiallocation_chain chain;    managed_shm.allocate_many(std::nothrow, 100, 16, chain);     //Check if the memory allocation was successful    if(chain.empty()) return 1;     //Allocated buffers    std::vector&lt;void*&gt; allocated_buffers;     //Initialize our data    while(!chain.empty()){       void *buf = chain.pop_front();       allocated_buffers.push_back(buf);       //The iterator must be incremented before overwriting memory       //because otherwise, the iterator is invalidated.       std::memset(buf, 0, 100);    }     //Now deallocate    while(!allocated_buffers.empty()){       managed_shm.deallocate(allocated_buffers.back());       allocated_buffers.pop_back();    }     //Allocate 10 buffers of different sizes in a single call. Throwing version    managed_shared_memory::size_type sizes[10];    for(std::size_t i = 0; i &lt; 10; ++i)       sizes[i] = i*3;     managed_shm.allocate_many(sizes, 10, 1, chain);    managed_shm.deallocate_many(chain);    return 0; }                       Allocating N buffers of the same size improves the performance of pools           and node containers (for example STL-like lists): when inserting a range           of forward iterators in a STL-like list, the insertion function can detect           the number of needed elements and allocate in a single call. The nodes           still can be deallocated.                     Allocating N buffers of different sizes can be used to speed up allocation           in cases where several objects must always be allocated at the same time           but deallocated at different times. For example, a class might perform           several initial allocations (some header data for a network packet, for           example) in its constructor but also allocations of buffers that might           be reallocated in the future (the data to be sent through the network).           Instead of allocating all the data independently, the constructor might           use allocate_many()           to speed up the initialization, but it still can deallocate and expand           the memory of the variable size element.                     In general, allocate_many           is useful with large values of N. Overuse of allocate_many           can increase the effective memory usage, because it can't reuse existing           non-contiguous memory fragments that might be available for some of the           elements.             Expand         in place memory allocation             When programming some data structures such as vectors, memory reallocation           becomes an important tool to improve performance. Managed memory segments           offer an advanced reallocation function that offers:                          Forward expansion: An allocated buffer can be expanded so that the               end of the buffer is moved further. New data can be written between               the old end and the new end.                             Backwards expansion: An allocated buffer can be expanded so that the               beginning of the buffer is moved backwards. New data can be written               between the new beginning and the old beginning.                             Shrinking: An allocated buffer can be shrunk so that the end of the               buffer is moved backwards. The memory between the new end and the old               end can be reused for future allocations.                          The expansion can be combined with the allocation of a new buffer if the           expansion fails obtaining a function with "expand, if fails allocate           a new buffer" semantics.                     Apart from this features, the function always returns the real size of           the allocated buffer, because many times, due to alignment issues the allocated           buffer a bit bigger than the requested size. Thus, the programmer can maximize           the memory use using allocation_command.                     Here is the declaration of the function:          enum boost::interprocess::allocation_type {    //Bitwise OR (|) combinable values    boost::interprocess::allocate_new        = ...,    boost::interprocess::expand_fwd          = ...,    boost::interprocess::expand_bwd          = ...,    boost::interprocess::shrink_in_place     = ...,    boost::interprocess::nothrow_allocation  = ... };   template&lt;class T&gt; std::pair&lt;T *, bool&gt;    allocation_command( boost::interprocess::allocation_type command                      , std::size_t limit_size                      , std::size_t preferred_size                      , std::size_t &amp;received_size                      , T *reuse_ptr = 0);             Preconditions for the function:                          If the parameter command contains the value boost::interprocess::shrink_in_place               it can't contain any of these values: boost::interprocess::expand_fwd,               boost::interprocess::expand_bwd.                             If the parameter command contains boost::interprocess::expand_fwd               or boost::interprocess::expand_bwd, the parameter reuse_ptr must be non-null and returned               by a previous allocation function.                             If the parameter command contains the value boost::interprocess::shrink_in_place,               the parameter limit_size               must be equal or greater than the parameter preferred_size.                             If the parameter command               contains any of these values: boost::interprocess::expand_fwd               or boost::interprocess::expand_bwd, the parameter limit_size must be equal or less               than the parameter preferred_size.                          Which are the effects of this function:                          If the parameter command contains the value boost::interprocess::shrink_in_place,               the function will try to reduce the size of the memory block referenced               by pointer reuse_ptr               to the value preferred_size               moving only the end of the block. If it's not possible, it will try               to reduce the size of the memory block as much as possible as long               as this results in size(p) &lt;= limit_size. Success is reported only               if this results in preferred_size               &lt;= size(p) and size(p) &lt;= limit_size.                             If the parameter command               only contains the value boost::interprocess::expand_fwd               (with optional additional boost::interprocess::nothrow_allocation),               the allocator will try to increase the size of the memory block referenced               by pointer reuse moving only the end of the block to the value preferred_size. If it's not possible,               it will try to increase the size of the memory block as much as possible               as long as this results in size(p) &gt;= limit_size. Success is reported only               if this results in limit_size               &lt;= size(p).                             If the parameter command               only contains the value boost::interprocess::expand_bwd               (with optional additional boost::interprocess::nothrow_allocation),               the allocator will try to increase the size of the memory block referenced               by pointer reuse_ptr               only moving the start of the block to a returned new position new_ptr. If it's not possible, it               will try to move the start of the block as much as possible as long               as this results in size(new_ptr) &gt;= limit_size. Success is reported only               if this results in limit_size               &lt;= size(new_ptr).                             If the parameter command               only contains the value boost::interprocess::allocate_new               (with optional additional boost::interprocess::nothrow_allocation),               the allocator will try to allocate memory for preferred_size               objects. If it's not possible it will try to allocate memory for at               least limit_size objects.                             If the parameter command               only contains a combination of boost::interprocess::expand_fwd               and boost::interprocess::allocate_new, (with optional additional               boost::interprocess::nothrow_allocation) the allocator               will try first the forward expansion. If this fails, it would try a               new allocation.                             If the parameter command               only contains a combination of boost::interprocess::expand_bwd               and boost::interprocess::allocate_new (with optional additional               boost::interprocess::nothrow_allocation), the allocator               will try first to obtain preferred_size               objects using both methods if necessary. If this fails, it will try               to obtain limit_size               objects using both methods if necessary.                             If the parameter command               only contains a combination of boost::interprocess::expand_fwd               and boost::interprocess::expand_bwd (with optional additional               boost::interprocess::nothrow_allocation), the allocator               will try first forward expansion. If this fails it will try to obtain               preferred_size objects using backwards expansion or a combination of               forward and backwards expansion. If this fails, it will try to obtain               limit_size objects               using both methods if necessary.                             If the parameter command               only contains a combination of allocation_new, boost::interprocess::expand_fwd               and boost::interprocess::expand_bwd, (with optional additional               boost::interprocess::nothrow_allocation) the allocator               will try first forward expansion. If this fails it will try to obtain               preferred_size objects using new allocation, backwards expansion or               a combination of forward and backwards expansion. If this fails, it               will try to obtain limit_size               objects using the same methods.                             The allocator always writes the size or the expanded/allocated/shrunk               memory block in received_size.               On failure the allocator writes in received_size               a possibly successful limit_size               parameter for a new call.                          Throws an exception if two conditions are met:                          The allocator is unable to allocate/expand/shrink the memory or there               is an error in preconditions                             The parameter command does not contain boost::interprocess::nothrow_allocation.                          This function returns:                          The address of the allocated memory or the new address of the expanded               memory as the first member of the pair. If the parameter command contains               boost::interprocess::nothrow_allocation the first member               will be 0 if the allocation/expansion fails or there is an error in               preconditions.                             The second member of the pair will be false if the memory has been               allocated, true if the memory has been expanded. If the first member               is 0, the second member has an undefined value.                          Notes:                          If the user chooses char               as template argument the returned buffer will be suitably aligned to               hold any type.                             If the user chooses char               as template argument and a backwards expansion is performed, although               properly aligned, the returned buffer might not be suitable because               the distance between the new beginning and the old beginning might               not multiple of the type the user wants to construct, since due to               internal restrictions the expansion can be slightly bigger than the               requested bytes. When performing backwards expansion,               if you have already constructed objects in the old buffer, make sure               to specify correctly the type.                          Here is a small example that shows the use of allocation_command:            #include &lt;boost/interprocess/managed_shared_memory.hpp&gt; #include &lt;cassert&gt;  int main() {    using namespace boost::interprocess;     //Remove shared memory on construction and destruction    struct shm_remove    {       shm_remove() { shared_memory_object::remove("MySharedMemory"); }       ~shm_remove(){ shared_memory_object::remove("MySharedMemory"); }    } remover;     //Managed memory segment that allocates portions of a shared memory    //segment with the default management algorithm    managed_shared_memory managed_shm(create_only, "MySharedMemory", 10000*sizeof(std::size_t));     //Allocate at least 100 bytes, 1000 bytes if possible    managed_shared_memory::size_type min_size = 100, preferred_size = 1000;    managed_shared_memory::size_type received_size;    std::size_t *ptr = managed_shm.allocation_command&lt;std::size_t&gt;       (boost::interprocess::allocate_new, min_size, preferred_size, received_size).first;     //Received size must be bigger than min_size    assert(received_size &gt;= min_size);     //Get free memory    managed_shared_memory::size_type free_memory_after_allocation = managed_shm.get_free_memory();     //Now write the data    for(std::size_t i = 0; i &lt; received_size; ++i) ptr[i] = i;     //Now try to triplicate the buffer. We won't admit an expansion    //lower to the double of the original buffer.    //This "should" be successful since no other class is allocating    //memory from the segment    managed_shared_memory::size_type expanded_size;    std::pair&lt;std::size_t *, bool&gt; ret = managed_shm.allocation_command       (boost::interprocess::expand_fwd, received_size*2, received_size*3, expanded_size, ptr);     //Check invariants    assert(ret.second == true);    assert(ret.first == ptr);    assert(expanded_size &gt;= received_size*2);     //Get free memory and compare    managed_shared_memory::size_type free_memory_after_expansion = managed_shm.get_free_memory();    assert(free_memory_after_expansion &lt; free_memory_after_allocation);     //Write new values    for(std::size_t i = received_size; i &lt; expanded_size; ++i)  ptr[i] = i;     //Try to shrink approximately to min_size, but the new size    //should be smaller than min_size*2.    //This "should" be successful since no other class is allocating    //memory from the segment    managed_shared_memory::size_type shrunk_size;    ret = managed_shm.allocation_command       (boost::interprocess::shrink_in_place, min_size*2, min_size, shrunk_size, ptr);     //Check invariants    assert(ret.second == true);    assert(ret.first == ptr);    assert(shrunk_size &lt;= min_size*2);    assert(shrunk_size &gt;= min_size);     //Get free memory and compare    managed_shared_memory::size_type free_memory_after_shrinking = managed_shm.get_free_memory();    assert(free_memory_after_shrinking &gt; free_memory_after_expansion);     //Deallocate the buffer    managed_shm.deallocate(ptr);    return 0; }                       allocation_command is a           very powerful function that can lead to important performance gains. It's           specially useful when programming vector-like data structures where the           programmer can minimize both the number of allocation requests and the           memory waste.             Opening         managed shared memory and mapped files with Copy On Write or Read Only modes             When mapping a memory segment based on shared memory or files, there is           an option to open them using open_copy_on_write           option. This option is similar to open_only           but every change the programmer does with this managed segment is kept           private to this process and is not translated to the underlying device           (shared memory or file).                     The underlying shared memory or file is opened as read-only so several           processes can share an initial managed segment and make private changes           to it. If many processes open a managed segment in copy on write mode and           not modified pages from the managed segment will be shared between all           those processes, with considerable memory savings.                     Opening managed shared memory and mapped files with open_read_only           maps the underlying device in memory with read-only           attributes. This means that any attempt to write that memory, either creating           objects or locking any mutex might result in an page-fault error (and thus,           program termination) from the OS. Read-only mode opens the underlying device           (shared memory, file...) in read-only mode and can result in considerable           memory savings if several processes just want to process a managed memory           segment without modifying it. Read-only mode operations are limited:                          Read-only mode must be used only from managed classes. If the programmer               obtains the segment manager and tries to use it directly it might result               in an access violation. The reason for this is that the segment manager               is placed in the underlying device and does not nothing about the mode               it's been mapped in memory.                             Only const member functions from managed segments should be used.                             Additionally, the find&lt;&gt; member function avoids using               internal locks and can be used to look for named and unique objects.                          Here is an example that shows the use of these two open modes:            #include &lt;boost/interprocess/managed_mapped_file.hpp&gt; #include &lt;fstream&gt; //std::fstream #include &lt;iterator&gt;//std::distance   int main() {    using namespace boost::interprocess;     //Define file names    const char *ManagedFile  = "MyManagedFile";    const char *ManagedFile2 = "MyManagedFile2";     //Try to erase any previous managed segment with the same name    file_mapping::remove(ManagedFile);    file_mapping::remove(ManagedFile2);    remove_file_on_destroy destroyer1(ManagedFile);    remove_file_on_destroy destroyer2(ManagedFile2);     {       //Create an named integer in a managed mapped file       managed_mapped_file managed_file(create_only, ManagedFile, 65536);       managed_file.construct&lt;int&gt;("MyInt")(0u);        //Now create a copy on write version       managed_mapped_file managed_file_cow(open_copy_on_write, ManagedFile);        //Erase the int and create a new one       if(!managed_file_cow.destroy&lt;int&gt;("MyInt"))          throw int(0);       managed_file_cow.construct&lt;int&gt;("MyInt2");        //Check changes       if(managed_file_cow.find&lt;int&gt;("MyInt").first &amp;&amp; !managed_file_cow.find&lt;int&gt;("MyInt2").first)          throw int(0);        //Check the original is intact       if(!managed_file.find&lt;int&gt;("MyInt").first &amp;&amp; managed_file.find&lt;int&gt;("MyInt2").first)          throw int(0);        {  //Dump the modified copy on write segment to a file          std::fstream file(ManagedFile2, std::ios_base::out | std::ios_base::binary);          if(!file)             throw int(0); 		 file.write(static_cast&lt;const char *&gt;(managed_file_cow.get_address()), (std::streamsize)managed_file_cow.get_size());       }        //Now open the modified file and test changes       managed_mapped_file managed_file_cow2(open_only, ManagedFile2);       if(managed_file_cow2.find&lt;int&gt;("MyInt").first &amp;&amp; !managed_file_cow2.find&lt;int&gt;("MyInt2").first)          throw int(0);    }    {       //Now create a read-only version       managed_mapped_file managed_file_ro(open_read_only, ManagedFile);        //Check the original is intact       if(!managed_file_ro.find&lt;int&gt;("MyInt").first &amp;&amp; managed_file_ro.find&lt;int&gt;("MyInt2").first)          throw int(0);        //Check the number of named objects using the iterators       if(std::distance(managed_file_ro.named_begin(),  managed_file_ro.named_end())  != 1 &amp;&amp;          std::distance(managed_file_ro.unique_begin(), managed_file_ro.unique_end()) != 0 )          throw int(0);    }    return 0; }                Managed       Heap Memory And Managed External Buffer   Managed         External Buffer: Constructing all Boost.Interprocess objects in a user provided         buffer Managed         Heap Memory: Boost.Interprocess machinery in heap memory Differences         between managed memory segments Example:         Serializing a database through the message queue           Boost.Interprocess offers managed shared         memory between processes using managed_shared_memory         or managed_mapped_file. Two         processes just map the same the memory mappable resource and read from and         write to that object.                 Many times, we don't want to use that shared memory approach and we prefer         to send serialized data through network, local socket or message queues.         Serialization can be done through Boost.Serialization         or similar library. However, if two processes share the same ABI (application         binary interface), we could use the same object and container construction         capabilities of managed_shared_memory         or managed_heap_memory to         build all the information in a single buffer that will be sent, for example,         though message queues. The receiver would just copy the data to a local buffer,         and it could read or modify it directly without deserializing the data .         This approach can be much more efficient that a complex serialization mechanism.                 Applications for Boost.Interprocess services         using non-shared memory buffers:                      Create and use STL compatible containers and allocators, in systems where             dynamic memory is not recommendable.                         Build complex, easily serializable databases in a single buffer:                                 To share data between threads                                     To save and load information from/to files.                                           Duplicate information (containers, allocators, etc...) just copying the             contents of one buffer to another one.                         Send complex information and objects/databases using serial/inter-process/network             communications.                      To help with this management, Boost.Interprocess         provides two useful classes, basic_managed_heap_memory         and basic_managed_external_buffer:          Managed         External Buffer: Constructing all Boost.Interprocess objects in a user provided         buffer             Sometimes, the user wants to create simple objects, STL compatible containers,           STL compatible strings and more, all in a single buffer. This buffer could           be a big static buffer, a memory-mapped auxiliary device or any other user           buffer.                     This would allow an easy serialization and we-ll just need to copy the           buffer to duplicate all the objects created in the original buffer, including           complex objects like maps, lists.... Boost.Interprocess           offers managed memory segment classes to handle user provided buffers that           allow the same functionality as shared memory classes:          //Named object creation managed memory segment //All objects are constructed in a user provided buffer template &lt;             class CharType,             class MemoryAlgorithm,             template&lt;class IndexConfig&gt; class IndexType          &gt; class basic_managed_external_buffer;  //Named object creation managed memory segment //All objects are constructed in a user provided buffer //   Names are c-strings, //   Default memory management algorithm //    (rbtree_best_fit with no mutexes and relative pointers) //   Name-object mappings are stored in the default index type (flat_map) typedef basic_managed_external_buffer &lt;    char,    rbtree_best_fit&lt;null_mutex_family, offset_ptr&lt;void&gt; &gt;,    flat_map_index    &gt;  managed_external_buffer;  //Named object creation managed memory segment //All objects are constructed in a user provided buffer //   Names are wide-strings, //   Default memory management algorithm //    (rbtree_best_fit with no mutexes and relative pointers) //   Name-object mappings are stored in the default index type (flat_map) typedef basic_managed_external_buffer&lt;    wchar_t,    rbtree_best_fit&lt;null_mutex_family, offset_ptr&lt;void&gt; &gt;,    flat_map_index    &gt;  wmanaged_external_buffer;             To use a managed external buffer, you must include the following header:          #include &lt;boost/interprocess/managed_external_buffer.hpp&gt;             Let's see an example of the use of managed_external_buffer:            #include &lt;boost/interprocess/managed_external_buffer.hpp&gt; #include &lt;boost/interprocess/allocators/allocator.hpp&gt; #include &lt;boost/interprocess/containers/list.hpp&gt; #include &lt;cstring&gt; #include &lt;boost/aligned_storage.hpp&gt;  int main() {    using namespace boost::interprocess;     //Create the static memory who will store all objects    const int memsize = 65536;     static boost::aligned_storage&lt;memsize&gt;::type static_buffer;     //This managed memory will construct objects associated with    //a wide string in the static buffer    wmanaged_external_buffer objects_in_static_memory       (create_only, &amp;static_buffer, memsize);     //We optimize resources to create 100 named objects in the static buffer    objects_in_static_memory.reserve_named_objects(100);     //Alias an integer node allocator type    //This allocator will allocate memory inside the static buffer    typedef allocator&lt;int, wmanaged_external_buffer::segment_manager&gt;       allocator_t;     //Alias a STL compatible list to be constructed in the static buffer    typedef list&lt;int, allocator_t&gt;    MyBufferList;     //The list must be initialized with the allocator    //All objects created with objects_in_static_memory will    //be stored in the static_buffer!    MyBufferList *list = objects_in_static_memory.construct&lt;MyBufferList&gt;(L"MyList")                            (objects_in_static_memory.get_segment_manager());    //Since the allocation algorithm from wmanaged_external_buffer uses relative    //pointers and all the pointers constructed int the static memory point    //to objects in the same segment,  we can create another static buffer    //from the first one and duplicate all the data.    static boost::aligned_storage&lt;memsize&gt;::type static_buffer2;    std::memcpy(&amp;static_buffer2, &amp;static_buffer, memsize);     //Now open the duplicated managed memory passing the memory as argument    wmanaged_external_buffer objects_in_static_memory2       (open_only, &amp;static_buffer2, memsize);     //Check that "MyList" has been duplicated in the second buffer    if(!objects_in_static_memory2.find&lt;MyBufferList&gt;(L"MyList").first)       return 1;     //Destroy the lists from the static buffers    objects_in_static_memory.destroy&lt;MyBufferList&gt;(L"MyList");    objects_in_static_memory2.destroy&lt;MyBufferList&gt;(L"MyList");    return 0; }                       Boost.Interprocess STL compatible allocators           can also be used to place STL compatible containers in the user segment.                     basic_managed_external_buffer           can be also useful to build small databases for embedded systems limiting           the size of the used memory to a predefined memory chunk, instead of letting           the database fragment the heap memory.             Managed         Heap Memory: Boost.Interprocess machinery in heap memory             The use of heap memory (new/delete) to obtain a buffer where the user wants           to store all his data is very common, so Boost.Interprocess           provides some specialized classes that work exclusively with heap memory.                     These are the classes:          //Named object creation managed memory segment //All objects are constructed in a single buffer allocated via new[] template &lt;             class CharType,             class MemoryAlgorithm,             template&lt;class IndexConfig&gt; class IndexType          &gt; class basic_managed_heap_memory;  //Named object creation managed memory segment //All objects are constructed in a single buffer allocated via new[] //   Names are c-strings, //   Default memory management algorithm //    (rbtree_best_fit with no mutexes and relative pointers) //   Name-object mappings are stored in the default index type (flat_map) typedef basic_managed_heap_memory &lt;    char,    rbtree_best_fit&lt;null_mutex_family&gt;,    flat_map_index    &gt;  managed_heap_memory;  //Named object creation managed memory segment //All objects are constructed in a single buffer allocated via new[] //   Names are wide-strings, //   Default memory management algorithm //    (rbtree_best_fit with no mutexes and relative pointers) //   Name-object mappings are stored in the default index type (flat_map) typedef basic_managed_heap_memory&lt;    wchar_t,    rbtree_best_fit&lt;null_mutex_family&gt;,    flat_map_index    &gt;  wmanaged_heap_memory;             To use a managed heap memory, you must include the following header:          #include &lt;boost/interprocess/managed_heap_memory.hpp&gt;             The use is exactly the same as basic_managed_external_buffer,           except that memory is created by the managed memory segment itself using           dynamic (new/delete) memory.                     basic_managed_heap_memory also offers           a grow(std::size_t extra_bytes) function that tries to resize internal           heap memory so that we have room for more objects. But be           careful, if memory is reallocated, the old buffer will be copied           into the new one so all the objects will be binary-copied to the new buffer.           To be able to use this function, all pointers constructed in the heap buffer           that point to objects in the heap buffer must be relative pointers (for           example offset_ptr). Otherwise,           the result is undefined. Here is an example:            #include &lt;boost/interprocess/containers/list.hpp&gt; #include &lt;boost/interprocess/managed_heap_memory.hpp&gt; #include &lt;boost/interprocess/allocators/allocator.hpp&gt; #include &lt;cstddef&gt;  using namespace boost::interprocess; typedef list&lt;int, allocator&lt;int, managed_heap_memory::segment_manager&gt; &gt;    MyList;  int main () {    //We will create a buffer of 1000 bytes to store a list    managed_heap_memory heap_memory(1000);     MyList * mylist = heap_memory.construct&lt;MyList&gt;("MyList")                         (heap_memory.get_segment_manager());     //Obtain handle, that identifies the list in the buffer    managed_heap_memory::handle_t list_handle = heap_memory.get_handle_from_address(mylist);     //Fill list until there is no more memory in the buffer    try{       while(1) {          mylist-&gt;insert(mylist-&gt;begin(), 0);       }    }    catch(const bad_alloc &amp;){       //memory is full    }    //Let's obtain the size of the list    MyList::size_type old_size = mylist-&gt;size();     //To make the list bigger, let's increase the heap buffer    //in 1000 bytes more.    heap_memory.grow(1000);     //If memory has been reallocated, the old pointer is invalid, so    //use previously obtained handle to find the new pointer.    mylist = static_cast&lt;MyList *&gt;                (heap_memory.get_address_from_handle(list_handle));     //Fill list until there is no more memory in the buffer    try{       while(1) {          mylist-&gt;insert(mylist-&gt;begin(), 0);       }    }    catch(const bad_alloc &amp;){       //memory is full    }     //Let's obtain the new size of the list    MyList::size_type new_size = mylist-&gt;size();     assert(new_size &gt; old_size);     //Destroy list    heap_memory.destroy_ptr(mylist);     return 0; }               Differences         between managed memory segments             All managed memory segments have similar capabilities (memory allocation           inside the memory segment, named object construction...), but there are           some remarkable differences between managed_shared_memory,           managed_mapped_file and managed_heap_memory,           managed_external_file.                          Default specializations of managed shared memory and mapped file use               process-shared mutexes. Heap memory and external buffer have no internal               synchronization by default. The cause is that the first two are thought               to be shared between processes (although memory mapped files could               be used just to obtain a persistent object data-base for a process)               whereas the last two are thought to be used inside one process to construct               a serialized named object data-base that can be sent though serial               interprocess communications (like message queues, localhost network...).                             The first two create a system-global object (a shared memory object               or a file) shared by several processes, whereas the last two are objects               that don't create system-wide resources.                  Example:         Serializing a database through the message queue             To see the utility of managed heap memory and managed external buffer classes,           the following example shows how a message queue can be used to serialize           a whole database constructed in a memory buffer using Boost.Interprocess,           send the database through a message queue and duplicated in another buffer:            //This test creates a in memory data-base using Interprocess machinery and //serializes it through a message queue. Then rebuilds the data-base in //another buffer and checks it against the original data-base bool test_serialize_db() {    //Typedef data to create a Interprocess map    typedef std::pair&lt;const std::size_t, std::size_t&gt; MyPair;    typedef std::less&lt;std::size_t&gt;   MyLess;    typedef node_allocator&lt;MyPair, managed_external_buffer::segment_manager&gt;       node_allocator_t;    typedef map&lt;std::size_t,                std::size_t,                std::less&lt;std::size_t&gt;,                node_allocator_t&gt;                MyMap;     //Some constants    const std::size_t BufferSize  = 65536;    const std::size_t MaxMsgSize  = 100;     //Allocate a memory buffer to hold the destiny database using vector&lt;char&gt;    std::vector&lt;char&gt; buffer_destiny(BufferSize, 0);     message_queue::remove(test::get_process_id_name());    {       //Create the message-queues       message_queue mq1(create_only, test::get_process_id_name(), 1, MaxMsgSize);        //Open previously created message-queue simulating other process       message_queue mq2(open_only, test::get_process_id_name());        //A managed heap memory to create the origin database       managed_heap_memory db_origin(buffer_destiny.size());        //Construct the map in the first buffer       MyMap *map1 = db_origin.construct&lt;MyMap&gt;("MyMap")                                        (MyLess(),                                        db_origin.get_segment_manager());       if(!map1)          return false;        //Fill map1 until is full       try{          std::size_t i = 0;          while(1){             (*map1)[i] = i;             ++i;          }       }       catch(boost::interprocess::bad_alloc &amp;){}        //Data control data sending through the message queue       std::size_t sent = 0;       message_queue::size_type recvd = 0;       message_queue::size_type total_recvd = 0;       unsigned int priority;        //Send whole first buffer through the mq1, read it       //through mq2 to the second buffer       while(1){          //Send a fragment of buffer1 through mq1 		 std::size_t bytes_to_send = MaxMsgSize &lt; (db_origin.get_size() - sent) ?                                        MaxMsgSize : (db_origin.get_size() - sent);          mq1.send( &amp;static_cast&lt;char*&gt;(db_origin.get_address())[sent]                , bytes_to_send                , 0);          sent += bytes_to_send;          //Receive the fragment through mq2 to buffer_destiny 		 mq2.receive( &amp;buffer_destiny[total_recvd] 		          , BufferSize - recvd                   , recvd                   , priority);          total_recvd += recvd;           //Check if we have received all the buffer          if(total_recvd == BufferSize){             break;          }       }        //The buffer will contain a copy of the original database       //so let's interpret the buffer with managed_external_buffer       managed_external_buffer db_destiny(open_only, &amp;buffer_destiny[0], BufferSize);        //Let's find the map       std::pair&lt;MyMap *, managed_external_buffer::size_type&gt; ret = db_destiny.find&lt;MyMap&gt;("MyMap");       MyMap *map2 = ret.first;        //Check if we have found it       if(!map2){          return false;       }        //Check if it is a single variable (not an array)       if(ret.second != 1){          return false;       }        //Now let's compare size       if(map1-&gt;size() != map2-&gt;size()){          return false;       }        //Now let's compare all db values 	  MyMap::size_type num_elements = map1-&gt;size(); 	  for(std::size_t i = 0; i &lt; num_elements; ++i){          if((*map1)[i] != (*map2)[i]){             return false;          }       }        //Destroy maps from db-s       db_origin.destroy_ptr(map1);       db_destiny.destroy_ptr(map2);    }    message_queue::remove(test::get_process_id_name());    return true; }                 Copyright &#169; 2005-2012 Ion Gaztanaga         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 3247weight: 2
tittle: Language
url :https://www.boost.org/doc/libs/1_53_0/doc/html/jam/language.html
content:    Language           Home Libraries People FAQ More        Language   Lexical Features Targets Rules Flow-of-Control Variables Modules         BJam has an interpreted, procedural language. Statements       in bjam are rule (procedure) definitions, rule invocations,       flow-of-control structures, variable assignments, and sundry language support.        Lexical Features           BJam treats its input files as whitespace-separated tokens,         with two exceptions: double quotes (") can enclose whitespace to embed         it into a token, and everything between the matching curly braces ({}) in         the definition of a rule action is treated as a single string. A backslash         (\) can escape a double quote, or any single whitespace character.                 BJam requires whitespace (blanks, tabs, or newlines) to         surround all tokens, including the colon (:) and semicolon (;) tokens.                 BJam keywords (an mentioned in this document) are reserved         and generally must be quoted with double quotes (") to be used as arbitrary         tokens, such as variable or target names.                 Comments start with the # character and extend until the         end of line.           Targets  Binding Detection          The essential bjam data entity is a target. Build targets         are files to be updated. Source targets are the files used in updating built         targets. Built targets and source targets are collectively referred to as         file targets, and frequently built targets are source targets for other built         targets. Pseudotargets are symbols which represent dependencies on other         targets, but which are not themselves associated with any real file.                 A file target's identifier is generally the file's name, which can be absolutely         rooted, relative to the directory of bjam's invocation,         or simply local (no directory). Most often it is the last case, and the actual         file path is bound using the $(SEARCH) and $(LOCATE)         special variables. See SEARCH         and LOCATE Variables below. A local filename is optionally qualified         with grist, a string value used to assure uniqueness. A file target with         an identifier of the form file(member) is a library         member (usually an ar(1) archive on Unix).          Binding Detection             Whenever a target is bound to a location in the filesystem, Boost Jam will           look for a variable called BINDRULE (first "on"           the target being bound, then in the global module). If non-empty, =$(BINDRULE[1])=           names a rule which is called with the name of the target and the path it           is being bound to. The signature of the rule named by =$(BINDRULE[1])=           should match the following:          rule bind-rule ( target : path )             This facility is useful for correct header file scanning, since many compilers           will search for #include           files first in the directory containing the file doing the #include directive. $(BINDRULE)           can be used to make a record of that directory.              Rules   Action Modifiers Argument lists Built-in Rules           The basic bjam language entity is called a rule. A rule         is defined in two parts: the procedure and the actions. The procedure is         a body of jam statements to be run when the rule is invoked; the actions         are the OS shell commands to execute when updating the built targets of the         rule.                 Rules can return values, which can be expanded into a list with "[         rule args ... ]". A rule's         value is the value of its last statement, though only the following statements         have values: 'if' (value of the leg chosen), 'switch' (value of the case         chosen), set (value of the resulting variable), and 'return' (value of its         arguments). Note that 'return' doesn't actually cause a return, i.e., is         a no-op unless it is the last statement of the last block executed within         rule body.                 The bjam statements for defining and invoking rules are         as follows:                 Define a rule's procedure, replacing any previous definition.        rule rulename { statements }           Define a rule's updating actions, replacing any previous definition.        actions [ modifiers ] rulename { commands }           Invoke a rule.        rulename field1 : field2 : ... : fieldN ;           Invoke a rule under the influence of target's specific variables..        on target rulename field1 : field2 : ... : fieldN ;           Used as an argument, expands to the return value of the rule invoked.        [ rulename field1 : field2 : ... : fieldN ] [ on target rulename field1 : field2 : ... : fieldN ]           A rule is invoked with values in field1 through fieldN.         They may be referenced in the procedure's statements as $(1)         through $(N) (9 max), and the first         two only may be referenced in the action's commands         as $(1) and $(2). $(&lt;)         and $(&gt;) are synonymous with $(1)         and $(2).                 Rules fall into two categories: updating rules (with actions), and pure procedure         rules (without actions). Updating rules treat arguments $(1)         and $(2) as built targets and sources, respectively, while         pure procedure rules can take arbitrary arguments.                 When an updating rule is invoked, its updating actions are added to those         associated with its built targets ($(1)) before the rule's         procedure is run. Later, to build the targets in the updating phase, commands         are passed to the OS command shell, with $(1) and $(2)         replaced by bound versions of the target names. See Binding above.                 Rule invocation may be indirected through a variable:        $(var) field1 : field2 : ... : fieldN ;  on target $(var) field1 : field2 : ... : fieldN ;  [ $(var) field1 : field2 : ... : fieldN ] [ on target $(var) field1 : field2 : ... : fieldN ]           The variable's value names the rule (or rules) to be invoked. A rule is invoked         for each element in the list of $(var)'s         values. The fields field1 : field2         : ... are passed as arguments for each invokation.         For the [ ... ] forms, the return value is the concatenation of the return         values for all of the invocations.          Action Modifiers             The following action modifiers are understood:             actions bind vars                  $(vars) will be replaced                 with bound values.                actions existing                  $(&gt;) includes only source targets currently                 existing.                actions ignore                  The return status of the commands is ignored.                actions piecemeal                  commands are repeatedly invoked with a subset of $(&gt;)                 small enough to fit in the command buffer on this OS.                actions quietly                  The action is not echoed to the standard output.                actions together                  The $(&gt;) from multiple invocations of the same                 action on the same built target are glommed together.                actions updated                  $(&gt;) includes only source targets themselves                 marked for updating.                     Argument lists             You can describe the arguments accepted by a rule, and refer to them by           name within the rule. For example, the following prints "I'm sorry,           Dave" to the console:          rule report ( pronoun index ? : state : names + ) {     local he.suffix she.suffix it.suffix = s ;     local I.suffix = m ;     local they.suffix you.suffix = re ;     ECHO $(pronoun)'$($(pronoun).suffix) $(state), $(names[$(index)]) ; } report I 2 : sorry : Joe Dave Pete ;             Each name in a list of formal arguments (separated by ":"           in the rule declaration) is bound to a single element of the corresponding           actual argument unless followed by one of these modifiers:                                                        Symbol                                                                             Semantics of preceding symbol                                                                                ?                                                                             optional                                                                               *                                                                             Bind to zero or more unbound elements of the actual argument.                     When * appears where an argument name is expected,                     any number of additional arguments are accepted. This feature                     can be used to implement "varargs" rules.                                                                               +                                                                             Bind to one or more unbound elements of the actual argument.                                                   The actual and formal arguments are checked for inconsistencies, which           cause Jam to exit with an error code:          ### argument error # rule report ( pronoun index ?  : state  : names + ) # called with: ( I 2 foo  : sorry  : Joe Dave Pete ) # extra argument foo ### argument error # rule report ( pronoun index ?  : state  : names + ) # called with: ( I 2  : sorry ) # missing argument names             If you omit the list of formal arguments, all checking is bypassed as in           "classic" Jam. Argument lists drastically improve the reliability           and readability of your rules, however, and are strongly           recommended for any new Jam code you write.             Built-in Rules   Dependency           Building Modifying           Binding Utility             BJam has a growing set of built-in rules, all of which           are pure procedure rules without updating actions. They are in three groups:           the first builds the dependency graph; the second modifies it; and the           third are just utility rules.            Dependency           Building    DEPENDS               rule DEPENDS ( targets1 * : targets2 * )                 Builds a direct dependency: makes each of targets1               depend on each of targets2. Generally, targets1               will be rebuilt if targets2 are themselves rebuilt               or are newer than targets1.                 INCLUDES               rule INCLUDES ( targets1 * : targets2 * )                 Builds a sibling dependency: makes any target that depends on any of               targets1 also depend on each of targets2.               This reflects the dependencies that arise when one source file includes               another: the object built from the source file depends both on the               original and included source file, but the two sources files don't               depend on each other. For example:              DEPENDS foo.o : foo.c ; INCLUDES foo.c : foo.h ;                 "foo.o" depends on "foo.c"               and "foo.h" in this example.                  Modifying           Binding               The six rules ALWAYS, LEAVES,             NOCARE, NOTFILE, NOUPDATE,             and TEMPORARY modify the dependency graph so that             bjam treats the targets differently during its target             binding phase. See Binding above. Normally, bjam updates             a target if it is missing, if its filesystem modification time is older             than any of its dependencies (recursively), or if any of its dependencies             are being updated. This basic behavior can be changed by invoking the             following rules:              ALWAYS               rule ALWAYS ( targets * )                 Causes targets to be rebuilt regardless of whether               they are up-to-date (they must still be in the dependency graph). This               is used for the clean and uninstall targets, as they have no dependencies               and would otherwise appear never to need building. It is best applied               to targets that are also NOTFILE targets, but it               can also be used to force a real file to be updated as well.                 LEAVES               rule LEAVES ( targets * )                 Makes each of targets depend only on its leaf               sources, and not on any intermediate targets. This makes it immune               to its dependencies being updated, as the "leaf" dependencies               are those without their own dependencies and without updating actions.               This allows a target to be updated only if original source files change.                 NOCARE               rule NOCARE ( targets * )                 Causes bjam to ignore targets               that neither can be found nor have updating actions to build them.               Normally for such targets bjam issues a warning               and then skips other targets that depend on these missing targets.               The HdrRule in Jambase uses               NOCARE on the header file names found during header               file scanning, to let bjam know that the included               files may not exist. For example, if an #include               is within an #ifdef,               the included file may not actually be around.                 Warning                   For targets with build actions: if their build actions exit with                 a nonzero return code, dependent targets will still be built.                    NOTFILE               rule NOTFILE ( targets * )                 Marks targets as pseudotargets and not real files.               No timestamp is checked, and so the actions on such a target are only               executed if the target's dependencies are updated, or if the target               is also marked with ALWAYS. The default bjam               target "all" is a pseudotarget. In Jambase,               NOTFILE is used to define several addition convenient               pseudotargets.                 NOUPDATE               rule NOUPDATE ( targets * )                 Causes the timestamps on targets to be ignored.               This has two effects: first, once the target has been created it will               never be updated; second, manually updating target will not cause other               targets to be updated. In Jambase, for example,               this rule is applied to directories by the MkDir               rule, because MkDir only cares that the target directory               exists, not when it has last been updated.                 TEMPORARY               rule TEMPORARY ( targets * )                 Marks targets as temporary, allowing them to be               removed after other targets that depend upon them have been updated.               If a TEMPORARY target is missing, bjam               uses the timestamp of the target's parent. Jambase               uses TEMPORARY to mark object files that are archived               in a library after they are built, so that they can be deleted after               they are archived.                 FAIL_EXPECTED               rule FAIL_EXPECTED ( targets * )                 For handling targets whose build actions are expected to fail (e.g.               when testing that assertions or compile-time type checking work properly),               Boost Jam supplies the FAIL_EXPECTED rule in the               same style as NOCARE, et. al. During target updating,               the return code of the build actions for arguments to FAIL_EXPECTED               is inverted: if it fails, building of dependent targets continues as               though it succeeded. If it succeeds, dependent targets are skipped.                 RMOLD               rule RMOLD ( targets * )                 BJam removes any target files that may exist on               disk when the rule used to build those targets fails. However, targets               whose dependencies fail to build are not removed by default. The RMOLD               rule causes its arguments to be removed if any of their dependencies               fail to build.                 ISFILE               rule ISFILE ( targets * )                 ISFILE marks targets as required to be files. This               changes the way bjam searches for the target such               that it ignores mathes for file system items that are not file, like               directories. This makes it possible to avoid #include               "exception" matching               if one happens to have a directory named exception in the header search               path.                 Warning                   This is currently not fully implemented.                     Utility               The two rules ECHO and EXIT are             utility rules, used only in bjam's parsing phase.              ECHO               rule ECHO ( args * )                 Blurts out the message args to stdout.                 EXIT               rule EXIT ( message * : result-value ? )                 Blurts out the message to stdout and then exits               with a failure status if no result-value is given,               otherwise it exits with the given result-value.                             "Echo", "echo",               "Exit", and "exit"               are accepted as aliases for ECHO and EXIT,               since it is hard to tell that these are built-in rules and not part               of the language, like "include".                 GLOB                              The GLOB rule does filename globbing.              rule GLOB ( directories * : patterns * : downcase-opt ? )                 Using the same wildcards as for the patterns in the switch statement.               It is invoked by being used as an argument to a rule invocation inside               of "=[ ]=". For example: "FILES = [ GLOB dir1               dir2 : *.c *.h ]" sets FILES to the               list of C source and header files in dir1 and dir2.               The resulting filenames are the full pathnames, including the directory,               but the pattern is applied only to the file name without the directory.                             If downcase-opt is supplied, filenames are converted               to all-lowercase before matching against the pattern; you can use this               to do case-insensitive matching using lowercase patterns. The paths               returned will still have mixed case if the OS supplies them. On Windows               NT and Cygwin, filenames are always downcased before matching.                 MATCH                              The MATCH rule does pattern matching.              rule MATCH ( regexps + : list * )                 Matches the egrep(1) style regular expressions               regexps against the strings in list.               The result is the concatenation of matching () subexpressions               for each string in list, and for each regular               expression in regexps. Only useful within the               "=[ ]=" construct, to change the result into a list.                 BACKTRACE               rule BACKTRACE ( )                 Returns a list of quadruples: filename line               module rulename..., describing               each shallower level of the call stack. This rule can be used to generate               useful diagnostic messages from Jam rules.                 UPDATE               rule UPDATE ( targets * )                 Classic jam treats any non-option element of command line as a name               of target to be updated. This prevented more sophisticated handling               of command line. This is now enabled again but with additional changes               to the UPDATE rule to allow for the flexibility               of changing the list of targets to update. The UPDATE rule has two               effects:                                  It clears the list of targets to update, and                                     Causes the specified targets to be updated.                                  If no target was specified with the UPDATE rule,               no targets will be updated. To support changing of the update list               in more useful ways, the rule also returns the targets previously in               the update list. This makes it possible to add targets as such:              local previous-updates = [ UPDATE ] ; UPDATE $(previous-updates) a-new-target ;     W32_GETREG               rule W32_GETREG ( path : data ? )                 Defined only for win32 platform. It reads the registry of Windows.               'path' is the location of the information, and               'data' is the name of the value which we want               to get. If 'data' is omitted, the default value               of 'path' will be returned. The 'path'               value must conform to MS key path format and must be prefixed with               one of the predefined root keys. As usual,                                  'HKLM' is equivalent to 'HKEY_LOCAL_MACHINE'.                                     'HKCU' is equivalent to 'HKEY_CURRENT_USER'.                                     'HKCR' is equivalent to 'HKEY_CLASSES_ROOT'.                                  Other predefined root keys are not supported.                             Currently supported data types : 'REG_DWORD', 'REG_SZ',               'REG_EXPAND_SZ', 'REG_MULTI_SZ'.               The data with 'REG_DWORD' type will be turned into               a string, 'REG_MULTI_SZ' into a list of strings,               and for those with 'REG_EXPAND_SZ' type environment               variables in it will be replaced with their defined values. The data               with 'REG_SZ' type and other unsupported types will               be put into a string without modification. If it can't receive the               value of the data, it just return an empty list. For example,              local PSDK-location =   [ W32_GETREG HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\MicrosoftSDK\\Directories : "Install Dir" ] ;     W32_GETREGNAMES               rule W32_GETREGNAMES ( path : result-type )                 Defined only for win32 platform. It reads the registry of Windows.               'path' is the location of the information, and               'result-type' is either 'subkeys'               or 'values'. For more information on 'path'               format and constraints, please see W32_GETREG.                             Depending on 'result-type', the rule returns one               of the following:                 subkeys                      Names of all direct subkeys of 'path'.                    values                      Names of values contained in registry key given by 'path'.                     The "default" value of the key appears in the returned                     list only if its value has been set in the registry.                                     If 'result-type' is not recognized, or requested               data cannot be retrieved, the rule returns an empty list. Example:              local key = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths" ; local subkeys = [ W32_GETREGNAMES "$(key)" : subkeys ] ; for local subkey in $(subkeys) {     local values = [ W32_GETREGNAMES "$(key)\\$(subkey)" : values ] ;     for local value in $(values)     {         local data = [ W32_GETREG "$(key)\\$(subkey)" : "$(value)" ] ;         ECHO "Registry path: " $(key)\\$(subkey) ":" $(value) "=" $(data) ;     } }     SHELL               rule SHELL ( command : * )                 SHELL executes command, and               then returns the standard output of command.               SHELL only works on platforms with a popen()               function in the C library. On platforms without a working popen()               function, SHELL is implemented as a no-op. SHELL               works on Unix, MacOS X, and most Windows compilers. SHELL               is a no-op on Metrowerks compilers under Windows. There is a variable               set of allowed options as additional arguments:                 exit-status                      In addition to the output the result status of the executed command                     is returned as a second element of the result.                    no-output                      Don't capture the output of the command. Instead an empty ("")                     string value is returned in place of the output.                                     Because the Perforce/Jambase defines a SHELL rule               which hides the builtin rule, COMMAND can be used               as an alias for SHELL in such a case.                 MD5               rule MD5 ( string )                 MD5 computes the MD5 hash of the string passed as               paramater and returns it.                 SPLIT_BY_CHARACTERS               rule SPLIT_BY_CHARACTERS ( string : delimiters )                 SPLIT_BY_CHARACTERS splits the specified string               on any delimiter character present in delimiters               and returns the resulting list.                 PRECIOUS               rule PRECIOUS ( targets * )                 The PRECIOUS rule specifies that each of the targets               passed as the arguments should not be removed even if the command updating               that target fails.                 PAD               rule PAD ( string : width )                 If string is shorter than width               characters, pads it with whitespace characters on the right, and returns               the result. Otherwise, returns string unmodified.                 FILE_OPEN               rule FILE_OPEN ( filename : mode )                 The FILE_OPEN rule opens the specified file and               returns a file descriptor. The mode parameter               can be either "w" or "r". Note that at present,               only the UPDATE_NOW rule can use the resulting file               descriptor number.                 UPDATE_NOW               rule UPDATE_NOW ( targets * : log ? : ignore-minus-n ? )                 The UPDATE_NOW caused the specified targets to be               updated immediately. If update was successfull, non-empty string is               returned. The log parameter, if present, specifies               a descriptor of a file where all output from building is redirected.               If the ignore-minus-n parameter is specified,               the targets are updated even if the -n parameter               is specified on the command line.                    Flow-of-Control           BJam has several simple flow-of-control statements:        for var in list { statements }           Executes statements for each element in list,         setting the variable var to the element value.        if cond { statements } [ else { statements } ]           Does the obvious; the else clause is optional. cond         is built of:           a                true if any a element is a non-zero-length string              a = b                list a matches list b string-for-string              a != b                list a does not match list b              a &lt; b                a[i] string is less than b[i]               string, where i is first mismatched element in               lists a and b              a &lt;= b                every a string is less than or equal to its b               counterpart              a &gt; b                a[i] string is greater than b[i]               string, where i is first mismatched element              a &gt;= b                every a string is greater than or equal to its               b counterpart              a in b                true if all elements of a can be found in b,               or if a has no elements              ! cond                condition not true              cond &amp;&amp; cond                conjunction              cond || cond                disjunction              ( cond )                precedence grouping                include file ;           Causes bjam to read the named file.         The file is bound like a regular target (see Binding         above) but unlike a regular target the include file         cannot be built.                 The include file is inserted into the input stream during         the parsing phase. The primary input file and all the included file(s) are         treated as a single file; that is, jam infers no scope boundaries from included         files.        local vars [ = values ] ;           Creates new vars inside to the enclosing {}         block, obscuring any previous values they might have. The previous values         for vars are restored when the current block ends. Any rule called or file         included will see the local and not the previous value (this is sometimes         called Dynamic Scoping). The local statement may appear anywhere, even outside         of a block (in which case the previous value is restored when the input ends).         The vars are initialized to values         if present, or left uninitialized otherwise.        return values ;           Within a rule body, the return statement sets the return value for an invocation         of the rule. It does not cause the rule         to return; a rule's value is actually the value of the last statement executed,         so a return should be the last statement executed before the rule "naturally"         returns.        switch value {     case pattern1 : statements ;     case pattern2 : statements ;     ... }           The switch statement executes zero or one of the enclosed statements,         depending on which, if any, is the first case whose pattern         matches value. The pattern values         are not variable-expanded. The pattern values may include the following wildcards:           ?                match any single character              *                match zero or more characters              [chars]                match any single character in chars              [^chars]                match any single character not in chars              \x                match x (escapes the other wildcards)                while cond { statements }           Repeatedly execute statements while cond         remains true upon entry. (See the description of cond         expression syntax under if, above).           Variables   Variable Expansion Local         For Loop Variables Generated File Expansion Built-in Variables           BJam variables are lists of zero or more elements, with         each element being a string value. An undefined variable is indistinguishable         from a variable with an empty list, however, a defined variable may have         one more elements which are null strings. All variables are referenced as         $(variable).                 Variables are either global or target-specific. In the latter case, the variable         takes on the given value only during the updating of the specific target.                 A variable is defined with:        variable = elements ; variable += elements ; variable on targets = elements ; variable on targets += elements ; variable default = elements ; variable ?= elements ;           The first two forms set variable globally. The third         and forth forms set a target-specific variable. The =         operator replaces any previous elements of variable         with elements; the += operation adds         elements to variable's list of         elements. The final two forms are synonymous: they set variable         globally, but only if it was previously unset.                 Variables referenced in updating commands will be replaced with their values;         target-specific values take precedence over global values. Variables passed         as arguments ($(1) and $(2)) to actions         are replaced with their bound values; the "bind"         modifier can be used on actions to cause other variables to be replaced with         bound values. See Action Modifiers above.                 BJam variables are not re-exported to the environment         of the shell that executes the updating actions, but the updating actions         can reference bjam variables with $(variable).          Variable Expansion             During parsing, bjam performs variable expansion on           each token that is not a keyword or rule name. Such tokens with embedded           variable references are replaced with zero or more tokens. Variable references           are of the form $(v) or $(vm),           where v is the variable name, and m           are optional modifiers.                     Variable expansion in a rule's actions is similar to variable expansion           in statements, except that the action string is tokenized at whitespace           regardless of quoting.                     The result of a token after variable expansion is the product           of the components of the token, where each component is a literal substring           or a list substituting a variable reference. For example:          $(X) -&gt; a b c t$(X) -&gt; ta tb tc $(X)z -&gt; az bz cz $(X)-$(X) -&gt; a-a a-b a-c b-a b-b b-c c-a c-b c-c             The variable name and modifiers can themselves contain a variable reference,           and this partakes of the product as well:          $(X) -&gt; a b c $(Y) -&gt; 1 2 $(Z) -&gt; X Y $($(Z)) -&gt; a b c 1 2             Because of this product expansion, if any variable reference in a token           is undefined, the result of the expansion is an empty list. If any variable           element is a null string, the result propagates the non-null elements:          $(X) -&gt; a "" $(Y) -&gt; "" 1 $(Z) -&gt; -$(X)$(Y)- -&gt; -a- -a1- -- -1- -$(X)$(Z)- -&gt;             A variable element's string value can be parsed into grist and filename-related           components. Modifiers to a variable are used to select elements, select           components, and replace components. The modifiers are:             [n]                  Select element number n (starting at 1). If                 the variable contains fewer than n elements,                 the result is a zero-element list. n can be                 negative in which case the element number n                 from the last leftward is returned.                [n-m]                  Select elements number n through m.                 n and m can be negative                 in which case they refer to elements counting from the last leftward.                [n-]                  Select elements number n through the last.                 n can be negative in which case it refers to                 the element counting from the last leftward.                :B                  Select filename base.                :S                  Select (last) filename suffix.                :M                  Select archive member name.                :D                  Select directory path.                :P                  Select parent directory.                :G                  Select grist.                :U                  Replace lowercase characters with uppercase.                :L                  Replace uppercase characters with lowercase.                :T                   Converts all back-slashes ("\") to forward slashes ("/").                 For example  x = "C:\\Program Files\\Borland" ; ECHO $(x:T) ;                   prints "C:/Program Files/Borland"                 :W                   When invoking Windows-based tools from Cygwin                 it can be important to pass them true windows-style paths. The :W                 modifier, under Cygwin only, turns                 a cygwin path into a Win32 path using the cygwin_conv_to_win32_path                 function. On other platforms, the string is unchanged. For example  x = "/cygdrive/c/Program Files/Borland" ; ECHO $(x:W) ;                   prints "C:\Program Files\Borland" on                 Cygwin                 :chars                  Select the components listed in chars.                :G=grist                  Replace grist with grist.                :D=path                  Replace directory with path.                :B=base                  Replace the base part of file name with base.                :S=suf                  Replace the suffix of file name with suf.                :M=mem                  Replace the archive member name with mem.                :R=root                  Prepend root to the whole file name, if not                 already rooted.                :E=value                  Assign value to the variable if it is unset.                :J=joinval                  Concatentate list elements into single element, separated by joinval'.                             On VMS, $(var:P) is the parent directory of $(var:D).             Local         For Loop Variables             Boost Jam allows you to declare a local for loop control variable right           in the loop:          x = 1 2 3 ; y = 4 5 6 ; for local y in $(x) {     ECHO $(y) ; # prints "1", "2", or "3" } ECHO $(y) ;     # prints "4 5 6"     Generated File Expansion             During expansion of expressions bjam also looks for           subexpressions of the form @(filename:E=filecontents)           and replaces the expression with filename after creating           the given file with the contents set to filecontents.           This is useful for creating compiler response files, and other "internal"           files. The expansion works both during parsing and action execution. Hence           it is possible to create files during any of the three build phases.             Built-in Variables   SEARCH and           LOCATE HDRSCAN           and HDRRULE Semaphores Platform           Identifier Jam           Version JAMSHELL __TIMING_RULE__           and __ACTION_RULE__             This section discusses variables that have special meaning to bjam.           All of these must be defined or used in the global module -- using those           variables inside a named module will not have the desired effect. See           Modules.            SEARCH and           LOCATE               These two variables control the binding of file target names to locations             in the file system. Generally, $(SEARCH) is used to             find existing sources while $(LOCATE) is used to fix             the location for built targets.                         Rooted (absolute path) file targets are bound as is. Unrooted file target             names are also normally bound as is, and thus relative to the current             directory, but the settings of $(LOCATE) and $(SEARCH)             alter this:                              If $(LOCATE) is set then the target is bound relative                 to the first directory in $(LOCATE). Only the                 first element is used for binding.                                 If $(SEARCH) is set then the target is bound to                 the first directory in $(SEARCH) where the target                 file already exists.                                 If the $(SEARCH) search fails, the target is bound                 relative to the current directory anyhow.                              Both $(SEARCH) and $(LOCATE) should             be set target-specific and not globally. If they were set globally,             bjam would use the same paths for all file binding,             which is not likely to produce sane results. When writing your own rules,             especially ones not built upon those in Jambase, you may need to set             $(SEARCH) or $(LOCATE) directly.             Almost all of the rules defined in Jambase set $(SEARCH)             and $(LOCATE) to sensible values for sources they             are looking for and targets they create, respectively.               HDRSCAN           and HDRRULE               These two variables control header file scanning. $(HDRSCAN)             is an egrep(1) pattern, with ()'s surrounding the             file name, used to find file inclusion statements in source files. Jambase             uses $(HDRPATTERN) as the pattern for $(HDRSCAN).             $(HDRRULE) is the name of a rule to invoke with the             results of the scan: the scanned file is the target, the found files             are the sources. This is the only place where bjam             invokes a rule through a variable setting.                         Both $(HDRSCAN) and $(HDRRULE)             must be set for header file scanning to take place, and they should be             set target-specific and not globally. If they were set globally, all             files, including executables and libraries, would be scanned for header             file include statements.                         The scanning for header file inclusions is not exact, but it is at least             dynamic, so there is no need to run something like makedepend(GNU)             to create a static dependency file. The scanning mechanism errs on the             side of inclusion (i.e., it is more likely to return filenames that are             not actually used by the compiler than to miss include files) because             it can't tell if #include             lines are inside #ifdefs             or other conditional logic. In Jambase, HdrRule             applies the NOCARE rule to each header file found             during scanning so that if the file isn't present yet doesn't cause the             compilation to fail, bjam won't care.                         Also, scanning for regular expressions only works where the included             file name is literally in the source file. It can't handle languages             that allow including files using variable names (as the Jam             language itself does).               Semaphores               It is sometimes desirable to disallow parallel execution of some actions.             For example:                              Old versions of yacc use files with fixed names. So, running two                 yacc actions is dangerous.                                 One might want to perform parallel compiling, but not do parallel                 linking, because linking is i/o bound and only gets slower.                              Craig McPeeters has extended Perforce Jam to solve such problems, and             that extension was integrated in Boost.Jam.                         Any target can be assigned a semaphore, by setting             a variable called SEMAPHORE on that target. The value             of the variable is the semaphore name. It must be different from names             of any declared target, but is arbitrary otherwise.                         The semantic of semaphores is that in a group of targets which have the             same semaphore, only one can be updated at the moment, regardless of             "-j" option.               Platform           Identifier               A number of Jam built-in variables can be used to identify runtime platform:               OS                    OS identifier string                  OSPLAT                    Underlying architecture, when applicable                  MAC                    true on MAC platform                  NT                    true on NT platform                  OS2                    true on OS2 platform                  UNIX                    true on Unix platforms                  VMS                    true on VMS platform                       Jam           Version     JAMDATE                    Time and date at bjam start-up as an ISO-8601                   UTC value.                  JAMUNAME                    Ouput of uname(1) command (Unix only)                  JAMVERSION                    bjam version, currently "3.1.19"                  JAM_VERSION                    A predefined global variable with two elements indicates the version                   number of Boost Jam. Boost Jam versions start at "03"                   "00". Earlier versions of Jam                   do not automatically define JAM_VERSION.                       JAMSHELL               When bjam executes a rule's action block, it forks             and execs a shell, passing the action block as an argument to the shell.             The invocation of the shell can be controlled by $(JAMSHELL).             The default on Unix is, for example:            JAMSHELL = /bin/sh -c % ;               The % is replaced with the text of the action block.                         BJam does not directly support building in parallel             across multiple hosts, since that is heavily dependent on the local environment.             To build in parallel across multiple hosts, you need to write your own             shell that provides access to the multiple hosts. You then reset $(JAMSHELL)             to reference it.                         Just as bjam expands a % to be             the text of the rule's action block, it expands a !             to be the multi-process slot number. The slot number varies between 1             and the number of concurrent jobs permitted by the -j             flag given on the command line. Armed with this, it is possible to write             a multiple host shell. For example:            #!/bin/sh  # This sample JAMSHELL uses the SunOS on(1) command to execute a # command string with an identical environment on another host.  # Set JAMSHELL = jamshell ! % # # where jamshell is the name of this shell file. # # This version handles up to -j6; after that they get executed # locally.  case $1 in 1|4) on winken sh -c "$2";; 2|5) on blinken sh -c "$2";; 3|6) on nod sh -c "$2";; *) eval "$2";; esac     __TIMING_RULE__           and __ACTION_RULE__               The __TIMING_RULE__ and __ACTION_RULE__             can be set to the name of a rule for bjam to call             after an action completes for a target.             They both give diagnostic information about the action that completed.             For __TIMING_RULE__ the rule is called as:            rule timing-rule ( args * : target : start end user system )               And __ACTION_RULE__ is called as:            rule action-rule ( args * : target : command status start end user system : output ? )               The arguments for both are:               args                    Any values following the rule name in the __TIMING_RULE__                   or __ACTION_RULE__ are passed along here.                  target                    The bjam target that was built.                  command                    The text of the executed command in the action body.                  status                    The integer result of the executed command.                  start                    The starting timestamp of the executed command as a ISO-8601 UTC                   value.                  end                    The completion timestamp of the executed command as a ISO-8601                   UTC value.                  user                    The number of user CPU seconds the executed command spent as a                   floating point value.                  system                    The number of system CPU seconds the executed command spent as                   a floating point value.                  output                    The output of the command as a single string. The content of the                   output reflects the use of the -pX option.                       Note                 If both variables are set for a target both are called, first __TIMING_RULE__               then __ACTION_RULE__.                    Modules   Declaration Variable Scope Local Rules The RULENAMES         Rule The VARNAMES         Rule The IMPORT         Rule The EXPORT         Rule The         CALLER_MODULE Rule The         DELETE_MODULE Rule           Boost Jam introduces support for modules, which provide some rudimentary         namespace protection for rules and variables. A new keyword, "module"         was also introduced. The features described in this section are primitives,         meaning that they are meant to provide the operations needed to write Jam         rules which provide a more elegant module interface.          Declaration  module expression { ... }             Code within the { ... } executes within the module named           by evaluating expression. Rule definitions can be found in the module's           own namespace, and in the namespace of the global module as module-name.rule-name,           so within a module, other rules in that module may always be invoked without           qualification:          module my_module {     rule salute ( x ) { ECHO $(x), world ; }     rule greet ( ) { salute hello ; }     greet ; } my_module.salute goodbye ;             When an invoked rule is not found in the current module's namespace, it           is looked up in the namespace of the global module, so qualified calls           work across modules:          module your_module {     rule bedtime ( ) { my_module.salute goodnight ; } }     Variable Scope             Each module has its own set of dynamically nested variable scopes. When           execution passes from module A to module B, all the variable bindings from           A become unavailable, and are replaced by the bindings that belong to B.           This applies equally to local and global variables:          module A {     x = 1 ;     rule f ( )     {         local y = 999 ; # becomes visible again when B.f calls A.g         B.f ;     }     rule g ( )     {         ECHO $(y) ;     # prints "999"     } } module B {     y = 2 ;     rule f ( )     {         ECHO $(y) ; # always prints "2"         A.g ;     } }             The only way to access another module's variables is by entering that module:          rule peek ( module-name ? : variables + ) {     module $(module-name)     {         return $($(&gt;)) ;     } }             Note that because existing variable bindings change whenever a new module           scope is entered, argument bindings become unavailable. That explains the           use of "$(&gt;)" in the peek rule above.             Local Rules  local rule rulename...             The rule is declared locally to the current module. It is not entered in           the global module with qualification, and its name will not appear in the           result of:          [ RULENAMES module-name ]     The RULENAMES         Rule  rule RULENAMES ( module ? )             Returns a list of the names of all non-local rules in the given module.           If module is omitted, the names of all non-local rules           in the global module are returned.             The VARNAMES         Rule  rule VARNAMES ( module ? )             Returns a list of the names of all variable bindings in the given module.           If module is omitted, the names of all variable bindings           in the global module are returned.             Note               This includes any local variables in rules from the call stack which             have not returned at the time of the VARNAMES invocation.                The IMPORT         Rule             IMPORT allows rule name aliasing across modules:          rule IMPORT ( source_module ? : source_rules *             : target_module ? : target_rules * )             The IMPORT rule copies rules from the source_module           into the target_module as local rules. If either           source_module or target_module           is not supplied, it refers to the global module. source_rules           specifies which rules from the source_module to import;           target_rules specifies the names to give those rules           in target_module. If source_rules           contains a name which doesn't correspond to a rule in source_module,           or if it contains a different number of items than target_rules,           an error is issued. For example,          # import m1.rule1 into m2 as local rule m1-rule1. IMPORT m1 : rule1 : m2 : m1-rule1 ; # import all non-local rules from m1 into m2 IMPORT m1 : [ RULENAMES m1 ] : m2 : [ RULENAMES m1 ] ;     The EXPORT         Rule             EXPORT allows rule name aliasing across modules:          rule EXPORT ( module ? : rules * )             The EXPORT rule marks rules from           the source_module as non-local (and thus exportable).           If an element of rules does not name a rule in module,           an error is issued. For example,          module X {   local rule r { ECHO X.r ; } } IMPORT X : r : : r ; # error - r is local in X EXPORT X : r ; IMPORT X : r : : r ; # OK.     The         CALLER_MODULE Rule  rule CALLER_MODULE ( levels ? )             CALLER_MODULE returns the name of the module scope enclosing           the call to its caller (if levels is supplied, it is interpreted as an           integer number of additional levels of call stack to traverse to locate           the module). If the scope belongs to the global module, or if no such module           exists, returns the empty list. For example, the following prints "{Y}           {X}":          module X {     rule get-caller { return [ CALLER_MODULE ] ; }     rule get-caller's-caller { return [ CALLER_MODULE 1 ] ; }     rule call-Y { return Y.call-X2 ; } } module Y {     rule call-X { return X.get-caller ; }     rule call-X2 { return X.get-caller's-caller ; } } callers = [ X.get-caller ] [ Y.call-X ] [ X.call-Y ] ; ECHO {$(callers)} ;     The         DELETE_MODULE Rule  rule DELETE_MODULE ( module ? )             DELETE_MODULE removes all of the variable bindings and           otherwise-unreferenced rules from the given module (or the global module,           if no module is supplied), and returns their memory to the system.             Note               Though it won't affect rules that are currently executing until they             complete, DELETE_MODULE should be used with extreme             care because it will wipe out any others and all variable (including             locals in that module) immediately. Because of the way dynamic binding             works, variables which are shadowed by locals will not be destroyed,             so the results can be really unpredictable.                  Copyright &#169; 2003-2007 Rene Rivera, David Abrahams, Vladimir Prus         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
doc_id: 5317weight: 1
tittle: Class random_device
url :https://www.boost.org/doc/libs/1_53_0/doc/html/boost/random/random_device.html
content:    Class random_device           Home Libraries People FAQ More         Class random_device boost::random::random_device  Synopsis // In header: &lt;boost/random/random_device.hpp&gt;   class random_device { public:   // types   typedef unsigned int result_type;    // construct/copy/destruct   random_device();   explicit random_device(const std::string &amp;);   ~random_device();    // public static functions   static result_type min();   static result_type max();    // public member functions   double entropy() const;   unsigned int operator()();   template&lt;typename Iter&gt; void generate(Iter, Iter);    // public data members   static const bool has_fixed_range; };  Description Class  random_device models a  non-deterministic random number generator . It uses one or more implementation-defined stochastic processes to generate a sequence of uniformly distributed non-deterministic random numbers. For those environments where a non-deterministic random number generator is not available, class random_device must not be implemented. See     "Randomness Recommendations for Security", D. Eastlake, S. Crocker, J. Schiller, Network Working Group, RFC 1750, December 1994     for further discussions.      Note    Some operating systems abstract the computer hardware enough to make it difficult to non-intrusively monitor stochastic processes. However, several do provide a special device for exactly this purpose. It seems to be impossible to emulate the functionality using Standard C++ only, so users should be aware that this class may not be available on all platforms.      Implementation Note for Linux On the Linux operating system, token is interpreted as a filesystem path. It is assumed that this path denotes an operating system pseudo-device which generates a stream of non-deterministic random numbers. The pseudo-device should never signal an error or end-of-file. Otherwise, std::ios_base::failure is thrown. By default,  random_device uses the /dev/urandom pseudo-device to retrieve the random numbers. Another option would be to specify the /dev/random pseudo-device, which blocks on reads if the entropy pool has no more random bits available. Implementation Note for Windows On the Windows operating system, token is interpreted as the name of a cryptographic service provider. By default  random_device uses MS_DEF_PROV. Performance The test program nondet_random_speed.cpp measures the execution times of the random_device.hpp implementation of the above algorithms in a tight loop. The performance has been evaluated on an Intel(R) Core(TM) i7 CPU Q 840 @ 1.87GHz, 1867 Mhz with Visual C++ 2010, Microsoft Windows 7 Professional and with gcc 4.4.5, Ubuntu Linux 2.6.35-25-generic.        Platform time per invocation [microseconds]    Windows  2.9    Linux  1.7       The measurement error is estimated at +/- 1 usec.    random_device          public        construct/copy/destruct   random_device(); Constructs a random_device, optionally using the default device.    explicit random_device(const std::string &amp; token); Constructs a random_device, optionally using the given token as an access specification (for example, a URL) to some implementation-defined service for monitoring a stochastic process.   ~random_device();     random_device public static functions   static result_type min(); Returns the smallest value that the  random_device can produce.    static result_type max(); Returns the largest value that the  random_device can produce.       random_device public member functions   double entropy() const; Returns: An entropy estimate for the random numbers returned by operator(), in the range min() to log2( max()+1). A deterministic random number generator (e.g. a pseudo-random number engine) has entropy 0. Throws: Nothing.    unsigned int operator()(); Returns a random value in the range [min, max].    template&lt;typename Iter&gt; void generate(Iter begin, Iter end); Fills a range with random 32-bit values.         Copyright &#169; 2000-2005 Jens MaurerCopyright &#169; 2009, 2010 Steven Watanabe         Distributed under the Boost Software License, Version 1.0. (See accompanying         file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)                
=============================================================
